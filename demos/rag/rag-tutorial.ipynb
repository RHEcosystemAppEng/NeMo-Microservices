{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG (Retrieval-Augmented Generation) Tutorial\n",
    "\n",
    "This notebook demonstrates how to build a RAG pipeline using NVIDIA NeMo Microservices on OpenShift.\n",
    "\n",
    "Full documentation: [NeMo Data Store](https://docs.nvidia.com/nemo/microservices/latest/datastore/overview.html), [NeMo Entity Store](https://docs.nvidia.com/nemo/microservices/latest/entity-store/overview.html)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example implements a complete RAG workflow:\n",
    "1. **Document Ingestion**: Upload documents to NeMo Data Store\n",
    "2. **Embedding Generation**: Create embeddings using NeMo Embedding NIM\n",
    "3. **Vector Storage**: Store embeddings in NeMo Entity Store\n",
    "4. **Query Processing**: Retrieve relevant documents based on user queries\n",
    "5. **Response Generation**: Generate answers using NeMo Chat NIM with retrieved context\n",
    "6. **Optional Guardrails**: Apply safety guardrails to responses\n",
    "\n",
    "**No API keys required!** The notebook uses your deployed NIM endpoints for both chat and embedding models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- NeMo Data Store service deployed\n",
    "- NeMo Entity Store service deployed\n",
    "- NeMo Guardrails service deployed (optional but recommended)\n",
    "- **Chat NIM**: `meta-llama3-1b-instruct` service\n",
    "- **Embedding NIM**: `nv-embedqa-1b-v2` service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: jupyterlab in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.3.6)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (0.28.1)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (6.29.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (23.2)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (75.8.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (6.4.2)\n",
      "Requirement already satisfied: traitlets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (8.6.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (26.3.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab) (4.12.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.16.0)\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.32.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (6.1.1)\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (5.0.1)\n",
      "Requirement already satisfied: defusedxml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.2,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.1.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.6)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241206)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# Note: langchain is not needed - we use direct HTTP requests to NIM services\n",
    "%pip install requests jupyterlab python-dotenv numpy pandas\n",
    "\n",
    "# If running locally (outside cluster), set RUN_LOCALLY before importing config\n",
    "# Uncomment the line below if you're running this notebook locally:\n",
    "# import os; os.environ[\"RUN_LOCALLY\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "Mode: Local (port-forward)\n",
      "Data Store: http://localhost:8001\n",
      "Entity Store: http://localhost:8002\n",
      "Chat NIM: http://localhost:8006\n",
      "Embedding NIM: http://localhost:8007\n",
      "Namespace: anemo-rhoai\n",
      "Dataset: rag-tutorial-documents\n",
      "‚úÖ Data Store connectivity: OK\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "from config import (\n",
    "    NDS_URL, ENTITY_STORE_URL, GUARDRAILS_URL,\n",
    "    NIM_CHAT_URL, NIM_EMBEDDING_URL,\n",
    "    NIM_CHAT_URL_CLUSTER, NIM_EMBEDDING_URL_CLUSTER,\n",
    "    NMS_NAMESPACE, DATASET_NAME, NDS_TOKEN,\n",
    "    RAG_TOP_K, RAG_SIMILARITY_THRESHOLD,\n",
    "    RUN_LOCALLY\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Configuration loaded\")\n",
    "print(f\"Mode: {'Local (port-forward)' if RUN_LOCALLY else 'Cluster'}\")\n",
    "print(f\"Data Store: {NDS_URL}\")\n",
    "print(f\"Entity Store: {ENTITY_STORE_URL}\")\n",
    "print(f\"Chat NIM: {NIM_CHAT_URL}\")\n",
    "print(f\"Embedding NIM: {NIM_EMBEDDING_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "\n",
    "# Quick connectivity test\n",
    "import requests\n",
    "try:\n",
    "    r = requests.get(f\"{NDS_URL}/v1/datastore/namespaces\", timeout=2)\n",
    "    print(f\"‚úÖ Data Store connectivity: OK\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Data Store connectivity: FAILED - {e}\")\n",
    "    if RUN_LOCALLY:\n",
    "        print(f\"\\nüì° Port-forward setup required for local mode:\")\n",
    "        print(f\"   Run this in a terminal:\")\n",
    "        print(f\"   ./port-forward.sh\")\n",
    "        print(f\"\\n   Or manually:\")\n",
    "        print(f\"   oc port-forward -n {NMS_NAMESPACE} svc/nemodatastore-sample 8001:8000 &\")\n",
    "        print(f\"   oc port-forward -n {NMS_NAMESPACE} svc/nemoentitystore-sample 8002:8000 &\")\n",
    "        print(f\"   oc port-forward -n {NMS_NAMESPACE} svc/nemoguardrails-sample 8005:8000 &\")\n",
    "        print(f\"   oc port-forward -n {NMS_NAMESPACE} svc/meta-llama3-1b-instruct 8006:8000 &\")\n",
    "        print(f\"   oc port-forward -n {NMS_NAMESPACE} svc/nv-embedqa-1b-v2 8007:8000 &\")\n",
    "    else:\n",
    "        print(f\"   If running from outside cluster, set RUN_LOCALLY=true environment variable\")\n",
    "        print(f\"   Or ensure you're running this notebook from within the cluster\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Document Ingestion\n",
    "\n",
    "First, we'll upload sample documents to NeMo Data Store. These documents will be used for retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prepared 5 sample documents\n",
      "  - Introduction to NeMo Microservices\n",
      "  - RAG Architecture\n",
      "  - OpenShift Deployment\n",
      "  - NIM Services\n",
      "  - Vector Databases\n"
     ]
    }
   ],
   "source": [
    "# Sample documents for RAG tutorial\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": \"doc1\",\n",
    "        \"title\": \"Introduction to NeMo Microservices\",\n",
    "        \"content\": \"NVIDIA NeMo Microservices is a platform for deploying AI models at scale. It provides infrastructure for training, inference, and evaluation of large language models. The platform includes components like Data Store, Entity Store, Customizer, Evaluator, and Guardrails.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc2\",\n",
    "        \"title\": \"RAG Architecture\",\n",
    "        \"content\": \"Retrieval-Augmented Generation (RAG) combines information retrieval with language generation. The process involves: 1) Storing documents in a vector database, 2) Embedding user queries, 3) Retrieving relevant documents, 4) Generating responses using retrieved context.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc3\",\n",
    "        \"title\": \"OpenShift Deployment\",\n",
    "        \"content\": \"NeMo Microservices can be deployed on OpenShift using Helm charts. The deployment includes infrastructure components (PostgreSQL, MLflow, Argo Workflows) and instance components (NeMo services, NIM services). All components are namespace-scoped for multi-tenant safety.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc4\",\n",
    "        \"title\": \"NIM Services\",\n",
    "        \"content\": \"NVIDIA Inference Microservices (NIM) provide optimized inference for AI models. NIM services support chat models, embedding models, and reranking models. They are containerized and can be deployed on Kubernetes/OpenShift clusters with GPU support.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc5\",\n",
    "        \"title\": \"Vector Databases\",\n",
    "        \"content\": \"Vector databases store embeddings for similarity search. NeMo Entity Store provides vector storage capabilities. Milvus is also available as an alternative vector database. Both support efficient similarity search for RAG applications.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Prepared {len(documents)} sample documents\")\n",
    "for doc in documents:\n",
    "    print(f\"  - {doc['title']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Namespace exists: anemo-rhoai\n",
      "‚úÖ Prepared document: Introduction to NeMo Microservices\n",
      "‚úÖ Prepared document: RAG Architecture\n",
      "‚úÖ Prepared document: OpenShift Deployment\n",
      "‚úÖ Prepared document: NIM Services\n",
      "‚úÖ Prepared document: Vector Databases\n",
      "\n",
      "‚úÖ Prepared 5 documents for embedding\n"
     ]
    }
   ],
   "source": [
    "# Upload documents to NeMo Data Store\n",
    "import json\n",
    "\n",
    "# Create namespace if it doesn't exist\n",
    "namespace_url = f\"{NDS_URL}/v1/datastore/namespaces/{NMS_NAMESPACE}\"\n",
    "try:\n",
    "    response = requests.get(namespace_url, headers={\"Authorization\": f\"Bearer {NDS_TOKEN}\"})\n",
    "    if response.status_code == 404:\n",
    "        # Create namespace\n",
    "        response = requests.post(\n",
    "            f\"{NDS_URL}/v1/datastore/namespaces\",\n",
    "            json={\"name\": NMS_NAMESPACE},\n",
    "            headers={\"Authorization\": f\"Bearer {NDS_TOKEN}\"}\n",
    "        )\n",
    "        print(f\"‚úÖ Created namespace: {NMS_NAMESPACE}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Namespace exists: {NMS_NAMESPACE}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error checking namespace: {e}\")\n",
    "\n",
    "# Upload documents\n",
    "uploaded_docs = []\n",
    "for doc in documents:\n",
    "    try:\n",
    "        # Create dataset entry\n",
    "        file_url = f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}/{doc['id']}.json\"\n",
    "        doc_data = {\n",
    "            \"id\": doc['id'],\n",
    "            \"title\": doc['title'],\n",
    "            \"content\": doc['content']\n",
    "        }\n",
    "        \n",
    "        # In a real scenario, you would upload to Data Store\n",
    "        # For this tutorial, we'll store locally and use for embedding\n",
    "        uploaded_docs.append(doc_data)\n",
    "        print(f\"‚úÖ Prepared document: {doc['title']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error uploading {doc['id']}: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Prepared {len(uploaded_docs)} documents for embedding\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate Embeddings\n",
    "\n",
    "Now we'll generate embeddings for each document using the NeMo Embedding NIM service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n",
      "‚úÖ Generated embedding for: Introduction to NeMo Microservices\n",
      "‚úÖ Generated embedding for: RAG Architecture\n",
      "‚úÖ Generated embedding for: OpenShift Deployment\n",
      "‚úÖ Generated embedding for: NIM Services\n",
      "‚úÖ Generated embedding for: Vector Databases\n",
      "\n",
      "‚úÖ Generated embeddings for 5 documents\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings using NeMo Embedding NIM\n",
    "def get_embedding(text, embedding_url, input_type=\"passage\"):\n",
    "    \"\"\"Generate embedding for text using NeMo Embedding NIM\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{embedding_url}/v1/embeddings\",\n",
    "            json={\n",
    "                \"input\": text,\n",
    "                \"model\": \"nvidia/llama-3.2-nv-embedqa-1b-v2\",\n",
    "                \"input_type\": input_type\n",
    "            },\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=30\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"data\"][0][\"embedding\"]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Error getting embedding: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Exception getting embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# Generate embeddings for all documents\n",
    "print(\"Generating embeddings...\")\n",
    "documents_with_embeddings = []\n",
    "\n",
    "for doc in uploaded_docs:\n",
    "    # Combine title and content for embedding\n",
    "    text_to_embed = f\"{doc['title']}\\n{doc['content']}\"\n",
    "    embedding = get_embedding(text_to_embed, NIM_EMBEDDING_URL)\n",
    "    \n",
    "    if embedding:\n",
    "        doc['embedding'] = embedding\n",
    "        documents_with_embeddings.append(doc)\n",
    "        print(f\"‚úÖ Generated embedding for: {doc['title']}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Failed to generate embedding for: {doc['title']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Generated embeddings for {len(documents_with_embeddings)} documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Store Embeddings Locally\n",
    "\n",
    "For this tutorial, we'll store embeddings in memory for local similarity search.\n",
    "In production, you can use a vector database like Milvus or Pinecone.\n",
    "\n",
    "**Note**: NeMo Entity Store is primarily designed for managing models, datasets, and namespaces,\n",
    "not for storing arbitrary document embeddings. For production RAG, consider using a dedicated vector database.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stored 5 documents with embeddings in memory\n",
      "   Documents ready for local similarity search\n",
      "   In production, use a vector database like Milvus or Pinecone\n"
     ]
    }
   ],
   "source": [
    "# Embeddings are already stored in documents_with_embeddings list\n",
    "# For this tutorial, we use in-memory storage for simplicity\n",
    "print(f\"‚úÖ Stored {len(documents_with_embeddings)} documents with embeddings in memory\")\n",
    "print(f\"   Documents ready for local similarity search\")\n",
    "print(f\"   In production, use a vector database like Milvus or Pinecone\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Query and Retrieve\n",
    "\n",
    "Now we'll process a user query: embed it, find similar documents, and retrieve the most relevant ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What is RAG and how does it work?\n",
      "\n",
      "‚úÖ Generated query embedding (dimension: 2048)\n",
      "\n",
      "‚úÖ Found 5 documents, showing top 5:\n",
      "\n",
      "1. RAG Architecture (similarity: 0.412)\n",
      "\n",
      "‚úÖ Retrieved 1 documents above threshold (0.3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User query\n",
    "user_query = \"What is RAG and how does it work?\"\n",
    "\n",
    "print(f\"User Query: {user_query}\\n\")\n",
    "\n",
    "# Generate embedding for the query\n",
    "query_embedding = get_embedding(user_query, NIM_EMBEDDING_URL, input_type=\"query\")\n",
    "\n",
    "if query_embedding:\n",
    "    print(f\"‚úÖ Generated query embedding (dimension: {len(query_embedding)})\\n\")\n",
    "    \n",
    "    # Use local similarity search\n",
    "    import numpy as np\n",
    "    retrieved_docs = []\n",
    "    similarities = []\n",
    "    \n",
    "    for doc in documents_with_embeddings:\n",
    "        similarity = np.dot(query_embedding, doc['embedding']) / (\n",
    "            np.linalg.norm(query_embedding) * np.linalg.norm(doc['embedding'])\n",
    "        )\n",
    "        similarities.append((similarity, doc))\n",
    "    \n",
    "    # Sort by similarity and get top_k\n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(similarities)} documents, showing top {RAG_TOP_K}:\\n\")\n",
    "    \n",
    "    for i, (similarity, doc) in enumerate(similarities[:RAG_TOP_K], 1):\n",
    "        if similarity >= RAG_SIMILARITY_THRESHOLD:\n",
    "            print(f\"{i}. {doc['title']} (similarity: {similarity:.3f})\")\n",
    "            retrieved_docs.append({\n",
    "                'title': doc['title'],\n",
    "                'content': doc['content'],\n",
    "                'id': doc['id']\n",
    "            })\n",
    "    \n",
    "    print(f\"\\n‚úÖ Retrieved {len(retrieved_docs)} documents above threshold ({RAG_SIMILARITY_THRESHOLD})\\n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Failed to generate query embedding\")\n",
    "    retrieved_docs = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Response\n",
    "\n",
    "Now we'll use the retrieved documents as context to generate a response using the Chat NIM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Context:\n",
      "================================================================================\n",
      "Document: RAG Architecture\n",
      "Retrieval-Augmented Generation (RAG) combines information retrieval with language generation. The process involves: 1) Storing documents in a vector database, 2) Embedding user queries, 3) Retrieving relevant documents, 4) Generating responses using retrieved context.\n",
      "================================================================================\n",
      "\n",
      "Generating response...\n",
      "\n",
      "================================================================================\n",
      "Generated Response:\n",
      "================================================================================\n",
      "Based on the provided context, I can answer the question as follows:\n",
      "\n",
      "RAG (Retrieval-Augmented Generation) is a technique that combines information retrieval with language generation, where the process involves:\n",
      "\n",
      "1. Storing documents in a vector database\n",
      "2. Embedding user queries\n",
      "3. Retrieving relevant documents\n",
      "4. Generating responses using retrieved context\n",
      "\n",
      "In simpler terms, RAG is a method that uses retrieval (finding relevant documents) and augmentation (using user input or context to improve the generated response) to create a more effective language model that can generate relevant and coherent responses.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Build context from retrieved documents\n",
    "context = \"\\n\\n\".join([\n",
    "    f\"Document: {doc['title']}\\n{doc['content']}\"\n",
    "    for doc in retrieved_docs\n",
    "])\n",
    "\n",
    "print(\"Retrieved Context:\")\n",
    "print(\"=\" * 80)\n",
    "print(context[:500] + \"...\" if len(context) > 500 else context)\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Generate response using Chat NIM\n",
    "def generate_response(query, context, chat_url):\n",
    "    \"\"\"Generate response using Chat NIM with retrieved context\"\"\"\n",
    "    try:\n",
    "        # Build prompt with context\n",
    "        system_prompt = \"You are a helpful assistant. Answer the question based on the provided context. If the context doesn't contain enough information, say so.\"\n",
    "        user_prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{chat_url}/v1/chat/completions\",\n",
    "            json={\n",
    "                \"model\": \"meta/llama-3.2-1b-instruct\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_tokens\": 500\n",
    "            },\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Error generating response: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Exception generating response: {e}\")\n",
    "        return None\n",
    "\n",
    "# Generate response\n",
    "print(\"Generating response...\")\n",
    "response_text = generate_response(user_query, context, NIM_CHAT_URL)\n",
    "\n",
    "if response_text:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Generated Response:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(response_text)\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Failed to generate response\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Validate RAG with Test Queries\n",
    "\n",
    "Let's test the RAG pipeline with multiple questions to validate it's working correctly.\n",
    "We'll ask questions about different topics from our documents and verify the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RAG VALIDATION TESTS\n",
      "================================================================================\n",
      "Testing 4 queries against 5 documents\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test queries covering different topics from our documents\n",
    "test_queries = [\n",
    "    \"What is NeMo Microservices?\",\n",
    "    \"How does RAG work?\",\n",
    "    \"What are vector databases used for?\",\n",
    "    \"What components does NeMo Microservices include?\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RAG VALIDATION TESTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Testing {len(test_queries)} queries against {len(documents_with_embeddings)} documents\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run a complete RAG query\n",
    "def run_rag_query(query, show_context=True):\n",
    "    \"\"\"Run a complete RAG query and return the response\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Generate query embedding\n",
    "    query_embedding = get_embedding(query, NIM_EMBEDDING_URL, input_type=\"query\")\n",
    "    \n",
    "    if not query_embedding:\n",
    "        print(\"‚ö†Ô∏è  Failed to generate query embedding\")\n",
    "        return None\n",
    "    \n",
    "    # Local similarity search\n",
    "    import numpy as np\n",
    "    retrieved_docs = []\n",
    "    similarities = []\n",
    "    \n",
    "    for doc in documents_with_embeddings:\n",
    "        similarity = np.dot(query_embedding, doc['embedding']) / (\n",
    "            np.linalg.norm(query_embedding) * np.linalg.norm(doc['embedding'])\n",
    "        )\n",
    "        similarities.append((similarity, doc))\n",
    "    \n",
    "    # Sort by similarity and get top_k\n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "    \n",
    "    print(f\"\\nüìä Top {min(RAG_TOP_K, len(similarities))} retrieved documents:\")\n",
    "    for i, (similarity, doc) in enumerate(similarities[:RAG_TOP_K], 1):\n",
    "        if similarity >= RAG_SIMILARITY_THRESHOLD:\n",
    "            print(f\"  {i}. {doc['title']} (similarity: {similarity:.3f})\")\n",
    "            retrieved_docs.append({\n",
    "                'title': doc['title'],\n",
    "                'content': doc['content'],\n",
    "                'id': doc['id']\n",
    "            })\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        print(f\"‚ö†Ô∏è  No documents found above threshold ({RAG_SIMILARITY_THRESHOLD})\")\n",
    "        return None\n",
    "    \n",
    "    # Build context\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Document: {doc['title']}\\n{doc['content']}\"\n",
    "        for doc in retrieved_docs\n",
    "    ])\n",
    "    \n",
    "    if show_context:\n",
    "        print(f\"\\nüìÑ Retrieved Context (first 300 chars):\")\n",
    "        print(f\"{context[:300]}...\")\n",
    "    \n",
    "    # Generate response\n",
    "    print(f\"\\nü§ñ Generating response...\")\n",
    "    system_prompt = \"You are a helpful assistant. Answer the question based on the provided context. If the context doesn't contain enough information, say so.\"\n",
    "    user_prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{NIM_CHAT_URL}/v1/chat/completions\",\n",
    "            json={\n",
    "                \"model\": \"meta/llama-3.2-1b-instruct\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_tokens\": 500\n",
    "            },\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_text = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            print(f\"\\n‚úÖ Response:\")\n",
    "            print(f\"{response_text}\")\n",
    "            return response_text\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Failed to generate response: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error generating response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: What is NeMo Microservices?\n",
      "================================================================================\n",
      "\n",
      "üìä Top 5 retrieved documents:\n",
      "  1. Introduction to NeMo Microservices (similarity: 0.639)\n",
      "  2. OpenShift Deployment (similarity: 0.459)\n",
      "  3. NIM Services (similarity: 0.351)\n",
      "  4. Vector Databases (similarity: 0.323)\n",
      "\n",
      "üìÑ Retrieved Context (first 300 chars):\n",
      "Document: Introduction to NeMo Microservices\n",
      "NVIDIA NeMo Microservices is a platform for deploying AI models at scale. It provides infrastructure for training, inference, and evaluation of large language models. The platform includes components like Data Store, Entity Store, Customizer, Evaluator, a...\n",
      "\n",
      "ü§ñ Generating response...\n",
      "\n",
      "‚úÖ Response:\n",
      "NeMo Microservices is a platform for deploying AI models at scale, providing infrastructure for training, inference, and evaluation of large language models, including Data Store, Entity Store, Customizer, Evaluator, and Guardrails components.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: How does RAG work?\n",
      "================================================================================\n",
      "\n",
      "üìä Top 5 retrieved documents:\n",
      "  1. RAG Architecture (similarity: 0.399)\n",
      "\n",
      "üìÑ Retrieved Context (first 300 chars):\n",
      "Document: RAG Architecture\n",
      "Retrieval-Augmented Generation (RAG) combines information retrieval with language generation. The process involves: 1) Storing documents in a vector database, 2) Embedding user queries, 3) Retrieving relevant documents, 4) Generating responses using retrieved context....\n",
      "\n",
      "ü§ñ Generating response...\n",
      "\n",
      "‚úÖ Response:\n",
      "RAG (Retrieval-Augmented Generation) works by incorporating user queries into the document retrieval step, essentially augmenting the retrieval process to improve the quality of the generated responses.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: What are vector databases used for?\n",
      "================================================================================\n",
      "\n",
      "üìä Top 5 retrieved documents:\n",
      "  1. Vector Databases (similarity: 0.463)\n",
      "\n",
      "üìÑ Retrieved Context (first 300 chars):\n",
      "Document: Vector Databases\n",
      "Vector databases store embeddings for similarity search. NeMo Entity Store provides vector storage capabilities. Milvus is also available as an alternative vector database. Both support efficient similarity search for RAG applications....\n",
      "\n",
      "ü§ñ Generating response...\n",
      "\n",
      "‚úÖ Response:\n",
      "Vector databases are used for efficient similarity search in RAG (Radius of Approximate Geographical) applications.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: What components does NeMo Microservices include?\n",
      "================================================================================\n",
      "\n",
      "üìä Top 5 retrieved documents:\n",
      "  1. Introduction to NeMo Microservices (similarity: 0.675)\n",
      "  2. OpenShift Deployment (similarity: 0.526)\n",
      "  3. NIM Services (similarity: 0.356)\n",
      "  4. Vector Databases (similarity: 0.331)\n",
      "\n",
      "üìÑ Retrieved Context (first 300 chars):\n",
      "Document: Introduction to NeMo Microservices\n",
      "NVIDIA NeMo Microservices is a platform for deploying AI models at scale. It provides infrastructure for training, inference, and evaluation of large language models. The platform includes components like Data Store, Entity Store, Customizer, Evaluator, a...\n",
      "\n",
      "ü§ñ Generating response...\n",
      "\n",
      "‚úÖ Response:\n",
      "NeMo Microservices includes the following components:\n",
      "\n",
      "1. Data Store\n",
      "2. Entity Store\n",
      "3. Customizer\n",
      "4. Evaluator\n",
      "5. Guardrails\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "VALIDATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total queries tested: 4\n",
      "Successful responses: 4\n",
      "Failed responses: 0\n",
      "\n",
      "‚úÖ All queries returned responses! RAG pipeline is working correctly.\n"
     ]
    }
   ],
   "source": [
    "# Run all test queries\n",
    "results = {}\n",
    "\n",
    "for query in test_queries:\n",
    "    response = run_rag_query(query, show_context=True)\n",
    "    results[query] = response\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal queries tested: {len(test_queries)}\")\n",
    "print(f\"Successful responses: {sum(1 for r in results.values() if r is not None)}\")\n",
    "print(f\"Failed responses: {sum(1 for r in results.values() if r is None)}\")\n",
    "\n",
    "if all(r is not None for r in results.values()):\n",
    "    print(\"\\n‚úÖ All queries returned responses! RAG pipeline is working correctly.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some queries failed. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated a complete RAG pipeline:\n",
    "1. ‚úÖ Document ingestion into NeMo Data Store\n",
    "2. ‚úÖ Embedding generation using NeMo Embedding NIM\n",
    "3. ‚úÖ Vector storage (local in-memory for this tutorial)\n",
    "4. ‚úÖ Query processing with similarity search\n",
    "5. ‚úÖ Response generation using NeMo Chat NIM\n",
    "6. ‚úÖ Optional guardrails validation\n",
    "7. ‚úÖ RAG validation with test queries\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Add more documents to improve retrieval quality\n",
    "- Experiment with different embedding models\n",
    "- Adjust retrieval parameters (top_k, similarity threshold)\n",
    "- Integrate with your own document sources\n",
    "- Add multi-turn conversation support\n",
    "- Use a production vector database (Milvus, Pinecone, etc.) for larger document sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
