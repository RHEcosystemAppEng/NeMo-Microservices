{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom LLM-as-a-Judge Implementation\n",
        "\n",
        "This notebook demonstrates how to leverage Custom LLM-as-a-Judge through NeMo Evaluator Microservice.\n",
        "\n",
        "Full documentation: [NeMo Evaluator Custom Evaluation](https://docs.nvidia.com/nemo/microservices/latest/evaluate/evaluation-custom.html#evaluation-with-llm-as-a-judge)\n",
        "\n",
        "## üîí Security Setup (REQUIRED FIRST STEP)\n",
        "\n",
        "**IMPORTANT**: This notebook uses `env.donotcommit` file for sensitive configuration (tokens, API keys). \n",
        "\n",
        "**Before running this notebook:**\n",
        "1. Copy the template: `cp env.donotcommit.example env.donotcommit`\n",
        "2. Edit `env.donotcommit` and add your `NIM_SERVICE_ACCOUNT_TOKEN`\n",
        "3. The `env.donotcommit` file is git-ignored and will NOT be committed to version control\n",
        "\n",
        "**Get your service account token:**\n",
        "```bash\n",
        "oc get secret <service-account-name> -n <namespace> -o jsonpath='{.data.token}' | base64 -d\n",
        "```\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this example, we'll evaluate medical consultation summaries using:\n",
        "- **Target Model**: NIM Model Serving (meta/llama-3.2-1b-instruct) - generates summaries\n",
        "- **Judge Model**: NIM Model Serving (meta/llama-3.2-1b-instruct) - evaluates the summaries\n",
        "  - Evaluates on two metrics:\n",
        "    - **Completeness**: How well the summary captures all critical information (1-5 scale)\n",
        "    - **Correctness**: How accurate the summary is without false information (1-5 scale)\n",
        "\n",
        "**Configuration**: The notebook is pre-configured to use NIM Model Serving (your configured InferenceService) for both models. All configuration is loaded from the `env.donotcommit` file (see Security Setup above).\n",
        "\n",
        "**‚ö†Ô∏è WORKAROUND**: This notebook uses NIM Model Serving (Knative/KServe) with an **external URL** to work around a known Evaluator bug. Evaluator v25.06/v25.08 strips `/chat/completions` from cluster-internal Knative service URLs, but using an external URL (HTTPS) may bypass this issue. Configure your external URL in `env.donotcommit` via `NIM_MODEL_SERVING_URL_EXTERNAL`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Set RUN_LOCALLY=true (using localhost with port-forwards)\n",
            "Collecting git+https://github.com/meta-llama/llama-stack-client-python.git@main\n",
            "  Cloning https://github.com/meta-llama/llama-stack-client-python.git (to revision main) to /private/var/folders/54/0nyyn56s1bsd1kbwqv8fdwxr0000gn/T/pip-req-build-r6o1bsk6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/meta-llama/llama-stack-client-python.git /private/var/folders/54/0nyyn56s1bsd1kbwqv8fdwxr0000gn/T/pip-req-build-r6o1bsk6\n",
            "  Resolved https://github.com/meta-llama/llama-stack-client-python.git to commit f8eb65140836de310042c914be5ec8c26e87554a\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (4.10.0)\n",
            "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (8.1.8)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (1.9.0)\n",
            "Requirement already satisfied: fire in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (0.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (0.28.1)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (2.2.3)\n",
            "Requirement already satisfied: prompt-toolkit in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (3.0.50)\n",
            "Requirement already satisfied: pyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (25.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (2.9.2)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (2.32.3)\n",
            "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (13.9.4)\n",
            "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (1.3.1)\n",
            "Requirement already satisfied: termcolor in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (3.1.0)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->llama_stack_client==0.4.0a12) (3.10)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.4.0a12) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.4.0a12) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama_stack_client==0.4.0a12) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.4.0a12) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.4.0a12) (2.23.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a12) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a12) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a12) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a12) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama_stack_client==0.4.0a12) (1.17.0)\n",
            "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from prompt-toolkit->llama_stack_client==0.4.0a12) (0.2.13)\n",
            "Requirement already satisfied: PyYAML in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyaml->llama_stack_client==0.4.0a12) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->llama_stack_client==0.4.0a12) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->llama_stack_client==0.4.0a12) (1.26.20)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->llama_stack_client==0.4.0a12) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->llama_stack_client==0.4.0a12) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama_stack_client==0.4.0a12) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
            "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.34.4)\n",
            "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.4.1)\n",
            "Requirement already satisfied: jupyterlab in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.3.6)\n",
            "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n",
            "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.99.9)\n",
            "Requirement already satisfied: llama-stack-client in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.4.0a12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (2025.5.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (4.12.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: httpx<1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.0.4)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (6.29.5)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (5.7.2)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.15.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (75.8.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=7.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (8.6.3)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
            "Requirement already satisfied: pyzmq>=24 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (26.3.0)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: babel>=2.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.10.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (8.1.8)\n",
            "Requirement already satisfied: fire in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (0.7.0)\n",
            "Requirement already satisfied: prompt-toolkit in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (3.0.50)\n",
            "Requirement already satisfied: pyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (25.7.0)\n",
            "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (13.9.4)\n",
            "Requirement already satisfied: termcolor in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (3.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
            "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.4)\n",
            "Requirement already satisfied: comm>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.13)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.32.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
            "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (6.1.1)\n",
            "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.19.1)\n",
            "Requirement already satisfied: stack_data in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from prompt-toolkit->llama-stack-client) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.22.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.4)\n",
            "Requirement already satisfied: rfc3339-validator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (5.0.1)\n",
            "Requirement already satisfied: defusedxml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.2,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.1.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.6)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241206)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->llama-stack-client) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama-stack-client) (0.1.2)\n",
            "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION: Load Environment Variables from env.donotcommit file\n",
        "# ============================================================================\n",
        "# üîí SECURITY: Never hardcode secrets in notebooks!\n",
        "# All sensitive values (tokens, API keys) should be in env.donotcommit file\n",
        "# \n",
        "# SETUP INSTRUCTIONS:\n",
        "# 1. Copy env.donotcommit.example to env.donotcommit: cp env.donotcommit.example env.donotcommit\n",
        "# 2. Edit env.donotcommit and fill in your values (especially NIM_SERVICE_ACCOUNT_TOKEN)\n",
        "# 3. env.donotcommit is git-ignored and will NOT be committed to version control\n",
        "#\n",
        "# IMPORTANT: Run this cell FIRST before importing config!\n",
        "# If you get connection errors, restart the kernel and run cells in order.\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Load env.donotcommit file from the notebook directory\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    # Find env.donotcommit file in the same directory as this notebook\n",
        "    notebook_dir = Path().resolve()  # Current working directory (where notebook is run from)\n",
        "    env_file = notebook_dir / \"env.donotcommit\"\n",
        "    \n",
        "    if env_file.exists():\n",
        "        load_dotenv(env_file, override=False)  # override=False: don't overwrite existing env vars\n",
        "        print(f\"‚úÖ Loaded env.donotcommit file from: {env_file}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  env.donotcommit file not found at: {env_file}\")\n",
        "        print(f\"   Looking for env.donotcommit.example template...\")\n",
        "        # Check if env.donotcommit.example exists\n",
        "        env_example = notebook_dir / \"env.donotcommit.example\"\n",
        "        if env_example.exists():\n",
        "            print(f\"   ‚ÑπÔ∏è  env.donotcommit.example exists at: {env_example}\")\n",
        "            print(f\"   üìù Please copy it to env.donotcommit and fill in your values:\")\n",
        "            print(f\"      cp env.donotcommit.example env.donotcommit\")\n",
        "            print(f\"      # Then edit env.donotcommit and add your NIM_SERVICE_ACCOUNT_TOKEN\")\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è  env.donotcommit.example not found - creating template...\")\n",
        "            env_example_content = \"\"\"# NeMo Microservices Configuration\n",
        "# Copy this file to env.donotcommit and fill in your values\n",
        "# env.donotcommit is git-ignored and will NOT be committed\n",
        "\n",
        "# REQUIRED: Namespace for cluster services\n",
        "# Replace with your actual OpenShift namespace/project name\n",
        "# Find your namespace: oc projects\n",
        "NMS_NAMESPACE=your-namespace\n",
        "\n",
        "\n",
        "\n",
        "# REQUIRED: NIM Model Serving Configuration\n",
        "# Replace with your actual InferenceService name\n",
        "# Find your service: oc get inferenceservice -n <your-namespace>\n",
        "NIM_MODEL_SERVING_SERVICE=your-inferenceservice-name\n",
        "NIM_MODEL_SERVING_MODEL=meta/llama-3.2-1b-instruct\n",
        "\n",
        "# REQUIRED: External URL for NIM Model Serving (HTTPS)\n",
        "# This is the external URL from the InferenceService status\n",
        "# Find your URL: oc get inferenceservice <name> -n <namespace> -o jsonpath='{.status.url}'\n",
        "# Format: https://<service-name>-<namespace>.apps.<cluster-domain>\n",
        "NIM_MODEL_SERVING_URL_EXTERNAL=https://your-service-name-your-namespace.apps.your-cluster-domain.com\n",
        "\n",
        "# Configuration flags\n",
        "USE_NIM_MODEL_SERVING=true\n",
        "USE_EXTERNAL_URL=true\n",
        "\n",
        "# OPTIONAL: Dataset name for evaluation data\n",
        "DATASET_NAME=custom-llm-as-a-judge-eval-data\n",
        "\n",
        "# REQUIRED: NIM Service Account Token (for LlamaStack and fallback)\n",
        "# Kubernetes service account token (JWT) for authenticating with KServe InferenceService\n",
        "# Get your token: oc create token <service-account-name> -n <your-namespace> --duration=8760h\n",
        "# Example: oc create token my-model-sa -n my-namespace --duration=8760h\n",
        "# The service account name is typically: <inferenceservice-name>-sa\n",
        "# Find your service account: oc get sa -n <your-namespace> | grep model\n",
        "NIM_SERVICE_ACCOUNT_TOKEN=\n",
        "\n",
        "# OPTIONAL: API Keys (only needed if using external APIs)\n",
        "# OPENAI_API_KEY=\n",
        "# NVIDIA_API_KEY=\n",
        "# HF_TOKEN=\n",
        "\"\"\"\n",
        "            env_example.write_text(env_example_content)\n",
        "            print(f\"   ‚úÖ Created env.donotcommit.example template at: {env_example}\")\n",
        "            print(f\"   üìù Please copy it to env.donotcommit and fill in your values:\")\n",
        "            print(f\"      cp env.donotcommit.example env.donotcommit\")\n",
        "            print(f\"      # Then edit env.donotcommit and add your NIM_SERVICE_ACCOUNT_TOKEN\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  python-dotenv not installed - install with: pip install python-dotenv\")\n",
        "    print(\"   Will use system environment variables only (not recommended)\")\n",
        "\n",
        "# Clear any cached config module to force reload\n",
        "if 'config' in sys.modules:\n",
        "    del sys.modules['config']\n",
        "    print(\"‚ö†Ô∏è  Cleared cached config module - will reload with new env vars\")\n",
        "\n",
        "# Set defaults (will be overridden by env.donotcommit file if present)\n",
        "# These are fallback values - prefer setting them in env.donotcommit file\n",
        "# Note: These defaults are examples - users should set their own values in env.donotcommit\n",
        "os.environ.setdefault(\"NMS_NAMESPACE\", \"anemo-rhoai\")\n",
        "os.environ.setdefault(\"NIM_MODEL_SERVING_SERVICE\", \"anemo-rhoai-model\")\n",
        "os.environ.setdefault(\"NIM_MODEL_SERVING_MODEL\", \"meta/llama-3.2-1b-instruct\")\n",
        "os.environ.setdefault(\"NIM_MODEL_SERVING_URL_EXTERNAL\", \"https://anemo-rhoai-model-anemo-rhoai.apps.ai-dev05.kni.syseng.devcluster.openshift.com\")\n",
        "os.environ.setdefault(\"USE_NIM_MODEL_SERVING\", \"true\")\n",
        "os.environ.setdefault(\"USE_EXTERNAL_URL\", \"true\")\n",
        "os.environ.setdefault(\"DATASET_NAME\", \"custom-llm-as-a-judge-eval-data\")\n",
        "# NIM_SERVICE_ACCOUNT_TOKEN should come from env.donotcommit file, not hardcoded here\n",
        "\n",
        "# Validate required token\n",
        "if not os.environ.get(\"NIM_SERVICE_ACCOUNT_TOKEN\"):\n",
        "    print(\"\\n‚ùå ERROR: NIM_SERVICE_ACCOUNT_TOKEN is not set!\")\n",
        "    print(\"   Please set it in your env.donotcommit file:\")\n",
        "    print(\"   1. Copy env.donotcommit.example to env.donotcommit: cp env.donotcommit.example env.donotcommit\")\n",
        "    print(\"   2. Edit env.donotcommit and add: NIM_SERVICE_ACCOUNT_TOKEN=your-token-here\")\n",
        "    print(\"   3. Get token from service account:\")\n",
        "    print(\"      oc get secret <service-account-name> -n <namespace> -o jsonpath='{.data.token}' | base64 -d\")\n",
        "    raise ValueError(\"NIM_SERVICE_ACCOUNT_TOKEN is required but not set in env.donotcommit file!\")\n",
        "\n",
        "print(\"\\n‚úÖ Environment variables loaded\")\n",
        "print(f\"   NMS_NAMESPACE: {os.environ.get('NMS_NAMESPACE')}\")\n",
        "print(f\"   Mode: Cluster (Workbench/Notebook)\")\n",
        "print(f\"   NIM Model Serving: {os.environ.get('NIM_MODEL_SERVING_SERVICE')}\")\n",
        "print(f\"   External URL: {os.environ.get('NIM_MODEL_SERVING_URL_EXTERNAL')}\")\n",
        "print(f\"   Using external URL: {os.environ.get('USE_EXTERNAL_URL')} (workaround for Evaluator bug)\")\n",
        "token_set = \"‚úÖ Set\" if os.environ.get('NIM_SERVICE_ACCOUNT_TOKEN') else \"‚ùå Not set\"\n",
        "print(f\"   Service Account Token: {token_set}\")\n",
        "print(f\"\\nüí° If you see connection errors, restart the kernel and run cells in order!\")\n",
        "\n",
        "# ============================================================================\n",
        "# Install Required Packages\n",
        "# ============================================================================\n",
        "# Install llama-stack-client from GitHub main (same as llamastack demo)\n",
        "# This ensures compatibility with the latest server version\n",
        "%pip install --upgrade git+https://github.com/meta-llama/llama-stack-client-python.git@main\n",
        "\n",
        "# Install required packages\n",
        "# Note: Dependency conflicts with feast package are expected and can be ignored\n",
        "# The notebook doesn't use feast, so the conflicts won't affect functionality\n",
        "%pip install requests huggingface-hub datasets jupyterlab python-dotenv openai llama-stack-client\n",
        "\n",
        "# Suppress dependency conflict warnings (these are from feast, which we don't use)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', message='.*dependency conflicts.*')\n",
        "print(\"‚úÖ Packages installed (dependency warnings from feast can be ignored)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Configuration loaded\n",
            "Mode: Local (port-forward)\n",
            "Data Store: http://localhost:8001\n",
            "Entity Store: http://localhost:8002\n",
            "Evaluator: http://localhost:8004\n",
            "LlamaStack: http://localhost:8321\n",
            "Namespace: anemo-rhoai\n",
            "Dataset: custom-llm-as-a-judge-eval-data\n",
            "‚úÖ Data Store connectivity: OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET http://localhost:8321/ \"HTTP/1.1 404 Not Found\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LlamaStack connectivity: OK\n"
          ]
        }
      ],
      "source": [
        "# Load configuration\n",
        "# IMPORTANT: Reload config module to pick up environment variables set in previous cell\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "# Remove config from cache if it was already imported\n",
        "if 'config' in sys.modules:\n",
        "    importlib.reload(sys.modules['config'])\n",
        "\n",
        "from config import (\n",
        "    NDS_URL, ENTITY_STORE_URL, EVALUATOR_URL, NEMO_URL, LLAMASTACK_URL,\n",
        "    NMS_NAMESPACE, DATASET_NAME, NDS_TOKEN,\n",
        "    OPENAI_API_KEY, NVIDIA_API_KEY,\n",
        "    ACTIVE_NIM_SERVICE, ACTIVE_NIM_MODEL, NIM_URL_CLUSTER\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Configuration loaded\")\n",
        "print(f\"Mode: Cluster (Workbench/Notebook)\")\n",
        "print(f\"Data Store: {NDS_URL}\")\n",
        "print(f\"Entity Store: {ENTITY_STORE_URL}\")\n",
        "print(f\"Evaluator: {EVALUATOR_URL}\")\n",
        "print(f\"LlamaStack: {LLAMASTACK_URL}\")\n",
        "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"NIM Model Serving: {ACTIVE_NIM_SERVICE} ({ACTIVE_NIM_MODEL})\")\n",
        "print(f\"NIM URL: {NIM_URL_CLUSTER}\")\n",
        "\n",
        "# Quick connectivity test\n",
        "import requests\n",
        "try:\n",
        "    r = requests.get(f\"{NDS_URL}/v1/datastore/namespaces\", timeout=5)\n",
        "    print(f\"‚úÖ Data Store connectivity: OK\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Data Store connectivity: FAILED - {e}\")\n",
        "    print(f\"   Ensure you're running this notebook from within a Workbench/Notebook in the cluster\")\n",
        "    print(f\"   Verify services are running:\")\n",
        "    print(f\"   oc get pods -n {NMS_NAMESPACE} | grep -E '(datastore|entitystore|evaluator)'\")\n",
        "    print(f\"   Check service endpoints:\")\n",
        "    print(f\"   oc get svc -n {NMS_NAMESPACE} | grep -E '(datastore|entitystore|evaluator)'\")\n",
        "\n",
        "# Initialize LlamaStack client\n",
        "try:\n",
        "    from llama_stack_client import LlamaStackClient\n",
        "    import logging\n",
        "    \n",
        "    # Suppress httpx INFO logs (404 on root endpoint is expected)\n",
        "    logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
        "    \n",
        "    client = LlamaStackClient(base_url=LLAMASTACK_URL)\n",
        "    # Test connectivity\n",
        "    # Note: 404 on root endpoint is expected - it just means the service is reachable\n",
        "    try:\n",
        "        server_info = client._client.get(\"/\")\n",
        "        print(f\"‚úÖ LlamaStack connectivity: OK\")\n",
        "        try:\n",
        "            client_version = client._client._version\n",
        "            print(f\"   LlamaStack client version: {client_version}\")\n",
        "        except:\n",
        "            pass\n",
        "    except Exception as e:\n",
        "        # 404 is OK - it means service is reachable but root endpoint doesn't exist\n",
        "        if \"404\" in str(e) or \"Not Found\" in str(e):\n",
        "            print(f\"‚úÖ LlamaStack connectivity: OK (service reachable)\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  LlamaStack connectivity: FAILED - {e}\")\n",
        "            print(f\"   Make sure LlamaStack is deployed: oc get pods -n {NMS_NAMESPACE} | grep llamastack\")\n",
        "            client = None\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  LlamaStack client not available - install with: %pip install --upgrade git+https://github.com/meta-llama/llama-stack-client-python.git@main\")\n",
        "    print(\"   Continuing without LlamaStack integration...\")\n",
        "    client = None\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  LlamaStack initialization failed: {e}\")\n",
        "    print(\"   Continuing without LlamaStack integration...\")\n",
        "    client = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Set Up Namespaces\n",
        "\n",
        "Create namespaces in both Entity Store and Data Store.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Entity Store namespace created/verified: anemo-rhoai\n",
            "‚úÖ Data Store namespace created/verified: anemo-rhoai\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def create_namespaces(entity_host, ds_host, namespace):\n",
        "    \"\"\"Create namespace in both Entity Store and Data Store.\"\"\"\n",
        "    # Create namespace in Entity Store\n",
        "    entity_store_url = f\"{entity_host}/v1/namespaces\"\n",
        "    resp = requests.post(entity_store_url, json={\"id\": namespace})\n",
        "    assert resp.status_code in (200, 201, 409, 422), \\\n",
        "        f\"Unexpected response from Entity Store: {resp.status_code} - {resp.text}\"\n",
        "    print(f\"‚úÖ Entity Store namespace created/verified: {namespace}\")\n",
        "\n",
        "    # Create namespace in Data Store\n",
        "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
        "    resp = requests.post(nds_url, data={\"namespace\": namespace})\n",
        "    assert resp.status_code in (200, 201, 409, 422), \\\n",
        "        f\"Unexpected response from Data Store: {resp.status_code} - {resp.text}\"\n",
        "    print(f\"‚úÖ Data Store namespace created/verified: {namespace}\")\n",
        "\n",
        "create_namespaces(entity_host=ENTITY_STORE_URL, ds_host=NDS_URL, namespace=NMS_NAMESPACE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Upload Dataset to Data Store\n",
        "\n",
        "Upload the medical consultation data to the Data Store.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository ID: anemo-rhoai/custom-llm-as-a-judge-eval-data\n",
            "‚ÑπÔ∏è  Namespace check: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'anemo-rhoai/.namespace-init'.\n",
            "‚úÖ Repository created: anemo-rhoai/custom-llm-as-a-judge-eval-data\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\"\n",
        "print(f\"Repository ID: {repo_id}\")\n",
        "\n",
        "# Create HfApi client pointing to NeMo Data Store\n",
        "hf_api = HfApi(endpoint=f\"{NDS_URL}/v1/hf\", token=NDS_TOKEN if NDS_TOKEN != \"token\" else None)\n",
        "\n",
        "# IMPORTANT: Ensure namespace exists in Gitea before creating repository\n",
        "# Data Store's Gitea backend needs the namespace directory to exist,\n",
        "# otherwise it defaults to \"default\" namespace. Creating a temporary\n",
        "# repository first ensures the namespace is created in Gitea.\n",
        "temp_repo_id = f\"{NMS_NAMESPACE}/.namespace-init\"\n",
        "try:\n",
        "    # Create temporary repo to ensure namespace exists in Gitea\n",
        "    hf_api.create_repo(repo_id=temp_repo_id, repo_type='dataset', exist_ok=True)\n",
        "    # Delete temporary repo (namespace directory will remain)\n",
        "    try:\n",
        "        hf_api.delete_repo(repo_id=temp_repo_id, repo_type='dataset')\n",
        "    except:\n",
        "        pass  # Ignore if deletion fails\n",
        "    print(f\"‚úÖ Namespace '{NMS_NAMESPACE}' initialized in Gitea\")\n",
        "except Exception as e:\n",
        "    # If temp repo creation fails, namespace might already exist - continue\n",
        "    print(f\"‚ÑπÔ∏è  Namespace check: {e}\")\n",
        "\n",
        "# Create repository (now namespace should exist in Gitea)\n",
        "try:\n",
        "    hf_api.create_repo(repo_id=repo_id, repo_type='dataset', exist_ok=True)\n",
        "    print(f\"‚úÖ Repository created: {repo_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Repository may already exist: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Data uploaded to anemo-rhoai/custom-llm-as-a-judge-eval-data\n"
          ]
        }
      ],
      "source": [
        "# Upload data file\n",
        "import os\n",
        "data_file = \"./data/doctor_consults_with_summaries.jsonl\"\n",
        "\n",
        "# Verify file exists\n",
        "if not os.path.exists(data_file):\n",
        "    raise FileNotFoundError(f\"‚ùå Data file not found: {data_file}\\n\"\n",
        "                           f\"   Make sure the file exists in the data/ directory.\\n\"\n",
        "                           f\"   Current working directory: {os.getcwd()}\")\n",
        "\n",
        "print(f\"üìÅ Uploading data file: {data_file}\")\n",
        "print(f\"   File size: {os.path.getsize(data_file)} bytes\")\n",
        "\n",
        "try:\n",
        "    hf_api.upload_file(\n",
        "        path_or_fileobj=data_file,\n",
        "        path_in_repo=\"doctor_consults_with_summaries.jsonl\",\n",
        "        repo_id=repo_id,\n",
        "        repo_type='dataset',\n",
        "    )\n",
        "    print(f\"‚úÖ Data uploaded to {repo_id}\")\n",
        "    \n",
        "    # Verify upload by listing repository files\n",
        "    try:\n",
        "        repo_files = hf_api.list_repo_files(repo_id=repo_id, repo_type='dataset')\n",
        "        print(f\"‚úÖ Verified: Repository contains {len(repo_files)} file(s)\")\n",
        "        for file in repo_files:\n",
        "            print(f\"   - {file}\")\n",
        "        if not repo_files:\n",
        "            raise Exception(\"Repository is empty after upload!\")\n",
        "    except Exception as verify_error:\n",
        "        print(f\"‚ùå Upload verification failed: {verify_error}\")\n",
        "        print(f\"   The evaluation job will fail if the file is not in the repository!\")\n",
        "        raise\n",
        "        \n",
        "except Exception as e:\n",
        "    if \"already exists\" in str(e).lower() or \"409\" in str(e):\n",
        "        print(f\"‚ÑπÔ∏è  File already exists in repository (this is OK)\")\n",
        "        # Still verify it's there\n",
        "        try:\n",
        "            repo_files = hf_api.list_repo_files(repo_id=repo_id, repo_type='dataset')\n",
        "            print(f\"‚úÖ Verified: Repository contains {len(repo_files)} file(s)\")\n",
        "            for file in repo_files:\n",
        "                print(f\"   - {file}\")\n",
        "            if not repo_files:\n",
        "                print(f\"‚ö†Ô∏è  WARNING: Repository appears empty even though file exists!\")\n",
        "                print(f\"   This may cause the evaluation job to fail.\")\n",
        "                print(f\"   Try deleting and re-uploading the file.\")\n",
        "        except Exception as verify_error:\n",
        "            print(f\"‚ö†Ô∏è  Could not verify existing file: {verify_error}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Upload failed: {e}\")\n",
        "        print(f\"   This will cause the evaluation job to fail!\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Register Dataset with LlamaStack\n",
        "\n",
        "Register the dataset with LlamaStack so it can be used for training/fine-tuning workflows.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Register Dataset in Entity Store\n",
        "\n",
        "Register the dataset in Entity Store so it can be used in evaluation jobs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register dataset in Entity Store (required for Evaluator service)\n",
        "# IMPORTANT: Make sure Step 2 (upload) completed successfully before running this cell\n",
        "if repo_id:\n",
        "    print(f\"Step 4: Registering dataset in Entity Store...\")\n",
        "    print(f\"   Dataset: {repo_id}\")\n",
        "    print(f\"   Make sure Step 2 (upload) completed successfully!\")\n",
        "    \n",
        "    try:\n",
        "        files_url = f\"hf://datasets/{repo_id}\"\n",
        "        print(f\"   Files URL: {files_url}\")\n",
        "        \n",
        "        resp = requests.post(\n",
        "            url=f\"{ENTITY_STORE_URL}/v1/datasets\",\n",
        "            json={\n",
        "                \"name\": DATASET_NAME,\n",
        "                \"namespace\": NMS_NAMESPACE,\n",
        "                \"description\": \"Medical consultation summaries for LLM-as-a-Judge evaluation\",\n",
        "                \"files_url\": files_url,\n",
        "                \"project\": \"custom-llm-as-a-judge-test\",\n",
        "            },\n",
        "            timeout=30\n",
        "        )\n",
        "        \n",
        "        # Handle response - 409 means dataset already exists (OK for re-running notebook)\n",
        "        if resp.status_code in (200, 201):\n",
        "            print(f\"‚úÖ Dataset registered in Entity Store: {DATASET_NAME}\")\n",
        "            dataset_obj = resp.json()\n",
        "            if 'files_url' in dataset_obj:\n",
        "                print(f\"   Files URL: {dataset_obj['files_url']}\")\n",
        "        elif resp.status_code == 409:\n",
        "            print(f\"‚ÑπÔ∏è  Dataset {DATASET_NAME} already exists in Entity Store (this is OK)\")\n",
        "            print(f\"   The dataset is ready to use\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  Failed to register in Entity Store: {resp.status_code}\")\n",
        "            print(f\"   Response: {resp.text}\")\n",
        "            print(f\"\\nüí° Troubleshooting:\")\n",
        "            print(f\"   1. Make sure Step 2 (upload) cell completed successfully\")\n",
        "            print(f\"   2. Verify files were uploaded: Check the output of Step 2 cell\")\n",
        "            print(f\"   3. Wait a few seconds and try running Step 2 again, then this cell\")\n",
        "            print(f\"   4. Check Entity Store: oc get pods -n {NMS_NAMESPACE} | grep entitystore\")\n",
        "            print(f\"   5. Check Data Store: oc get pods -n {NMS_NAMESPACE} | grep datastore\")\n",
        "            print(f\"   6. Verify Entity Store URL is correct: {ENTITY_STORE_URL}\")\n",
        "            print(f\"   7. If dataset already exists, you can skip this step\")\n",
        "            raise Exception(f\"Status Code {resp.status_code} Failed to create dataset: {resp.text}\")\n",
        "        \n",
        "        # Verify dataset exists\n",
        "        res = requests.get(url=f\"{ENTITY_STORE_URL}/v1/datasets/{NMS_NAMESPACE}/{DATASET_NAME}\", timeout=30)\n",
        "        if res.status_code not in (200, 201):\n",
        "            raise Exception(f\"Status Code {res.status_code} Failed to fetch dataset: {res.text}\")\n",
        "        \n",
        "        dataset_obj = res.json()\n",
        "        print(f\"‚úÖ Dataset verified. Files URL: {dataset_obj['files_url']}\")\n",
        "        \n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"‚ö†Ô∏è  Timeout connecting to Entity Store\")\n",
        "        print(f\"   Check Entity Store is running: oc get pods -n {NMS_NAMESPACE} | grep entitystore\")\n",
        "        raise\n",
        "    except requests.exceptions.ConnectionError as e:\n",
        "        print(f\"‚ö†Ô∏è  Connection error to Entity Store: {e}\")\n",
        "        print(f\"   Check Entity Store URL: {ENTITY_STORE_URL}\")\n",
        "        print(f\"   Check Entity Store is running: oc get pods -n {NMS_NAMESPACE} | grep entitystore\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error registering dataset in Entity Store: {e}\")\n",
        "        print(f\"\\nüí° Troubleshooting:\")\n",
        "        print(f\"   1. Make sure Step 2 (upload) cell completed successfully\")\n",
        "        print(f\"   2. Check Entity Store: oc get pods -n {NMS_NAMESPACE} | grep entitystore\")\n",
        "        print(f\"   3. Check Entity Store logs: oc logs -n {NMS_NAMESPACE} deployment/nemoentitystore-sample --tail=50\")\n",
        "        raise\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Skipping Entity Store registration (files not uploaded to Data Store)\")\n",
        "    print(f\"   Run Step 2 (upload) cell first to upload files to Data Store\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è  Dataset already exists: custom-llm-as-a-judge-eval-data (this is OK)\n",
            "‚úÖ Dataset verified. Files URL: hf://datasets/anemo-rhoai/custom-llm-as-a-judge-eval-data\n"
          ]
        }
      ],
      "source": [
        "# Register dataset with LlamaStack (only if files were uploaded and client is available)\n",
        "# IMPORTANT: Make sure Step 2 (upload) completed successfully before running this cell\n",
        "if repo_id and client is not None:\n",
        "    print(f\"Step 3: Registering dataset with LlamaStack...\")\n",
        "    print(f\"   Dataset: {repo_id}\")\n",
        "    print(f\"   Make sure Step 2 (upload) completed successfully!\")\n",
        "    \n",
        "    try:\n",
        "        dataset_uri = f\"hf://datasets/{repo_id}\"\n",
        "        print(f\"   Dataset URI: {dataset_uri}\")\n",
        "        \n",
        "        response = client.beta.datasets.register(\n",
        "            purpose=\"post-training/messages\",\n",
        "            dataset_id=DATASET_NAME,\n",
        "            source={\n",
        "                \"type\": \"uri\",\n",
        "                \"uri\": dataset_uri\n",
        "            },\n",
        "            metadata={\n",
        "                \"format\": \"jsonl\",\n",
        "                \"description\": \"Medical consultation summaries for LLM-as-a-Judge evaluation\",\n",
        "                \"provider_id\": \"nvidia\",\n",
        "            }\n",
        "        )\n",
        "        print(f\"‚úÖ Dataset registered with LlamaStack: {DATASET_NAME}\")\n",
        "        if hasattr(response, 'dataset_id'):\n",
        "            print(f\"   Dataset ID: {response.dataset_id}\")\n",
        "    except Exception as e:\n",
        "        error_msg = str(e)\n",
        "        if \"already exists\" in error_msg.lower() or \"409\" in error_msg:\n",
        "            print(f\"‚ÑπÔ∏è  Dataset {DATASET_NAME} already exists in LlamaStack (this is OK)\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  Error registering dataset with LlamaStack: {error_msg}\")\n",
        "            print(f\"\\nüí° Troubleshooting:\")\n",
        "            print(f\"   1. Make sure Step 2 (upload) cell completed successfully\")\n",
        "            print(f\"   2. Verify files were uploaded: Check the output of Step 2 cell\")\n",
        "            print(f\"   3. Wait a few seconds and try running Step 2 again, then this cell\")\n",
        "            print(f\"   4. Check Data Store: oc get pods -n {NMS_NAMESPACE} | grep datastore\")\n",
        "            print(f\"   5. Check LlamaStack: oc get pods -n {NMS_NAMESPACE} | grep llamastack\")\n",
        "            print(f\"   6. If dataset already exists, you can skip this step\")\n",
        "            print(f\"\\n   Continuing without LlamaStack registration...\")\n",
        "elif not repo_id:\n",
        "    print(f\"\\n‚ö†Ô∏è  Skipping LlamaStack registration (files not uploaded to Data Store)\")\n",
        "    print(f\"   Run Step 2 (upload) cell first to upload files to Data Store\")\n",
        "elif client is None:\n",
        "    print(f\"\\n‚ö†Ô∏è  Skipping LlamaStack registration (LlamaStack client not available)\")\n",
        "    print(f\"   Make sure the LlamaStack initialization cell ran successfully\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Skipping LlamaStack registration\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Configure Judge LLM and Target Model\n",
        "\n",
        "Set up the judge model (OpenAI) and target model (for generating summaries).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Judge model configured: Your NIM (meta/llama-3.2-1b-instruct)\n",
            "‚ÑπÔ∏è  Creating evaluation target with cluster URL: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/chat/completions\n",
            "   (Service mesh handles authentication - no token needed)\n",
            "   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\n",
            "   If job fails, this is a known Evaluator limitation\n"
          ]
        }
      ],
      "source": [
        "# Judge LLM Configuration\n",
        "# IMPORTANT: Use NIM Model Serving (anemo-rhoai) for meta-llama-2-7b-chat\n",
        "# This uses the NIM Model Serving InferenceService (KServe/Knative) on port 80\n",
        "#\n",
        "# ‚ö†Ô∏è  WORKAROUND for Evaluator v25.06 URL stripping bug:\n",
        "# Evaluator strips /chat/completions from Knative URLs, so we configure the base URL\n",
        "# and rely on the model_id to indicate it's a chat model. The Evaluator should handle\n",
        "# the endpoint routing based on the model type.\n",
        "\n",
        "import importlib\n",
        "import config\n",
        "importlib.reload(config)\n",
        "from config import NIM_URL_CLUSTER, ACTIVE_NIM_MODEL, ACTIVE_NIM_SERVICE\n",
        "\n",
        "# Use external URL to work around Evaluator URL stripping bug\n",
        "# External URLs may not have the same URL stripping issue as cluster-internal Knative URLs\n",
        "# External URLs require authentication - use service account token from environment\n",
        "base_url = NIM_URL_CLUSTER.rstrip('/')\n",
        "# Get service account token from environment (set in cell 1)\n",
        "SERVICE_ACCOUNT_TOKEN = os.environ.get(\"NIM_SERVICE_ACCOUNT_TOKEN\", \"\")\n",
        "if not SERVICE_ACCOUNT_TOKEN:\n",
        "    raise ValueError(\"NIM_SERVICE_ACCOUNT_TOKEN not set! Please set it in cell 1 (environment configuration).\")\n",
        "\n",
        "judge_model_config = {\n",
        "    \"api_endpoint\": {\n",
        "        \"url\": f\"{base_url}/v1/chat/completions\",  # Full path with external URL\n",
        "        \"model_id\": ACTIVE_NIM_MODEL,  # meta/llama-3.2-1b-instruct (from NIM Model Serving)\n",
        "        \"format\": \"openai\",  # Specify format\n",
        "        \"api_key\": SERVICE_ACCOUNT_TOKEN  # Service account token for external URL authentication\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Judge model configured: NIM Model Serving ({ACTIVE_NIM_MODEL})\")\n",
        "print(f\"   Service: {ACTIVE_NIM_SERVICE}\")\n",
        "print(f\"   URL: {base_url}/v1/chat/completions\")\n",
        "print(f\"   ‚ÑπÔ∏è  Using external URL with authentication token\")\n",
        "print(f\"   (External URL bypasses Evaluator URL stripping bug)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Target model configured: Your NIM (meta/llama-3.2-1b-instruct)\n",
            "‚ÑπÔ∏è  Creating evaluation target with cluster URL: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/chat/completions\n",
            "   (Service mesh handles authentication - no token needed)\n",
            "   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\n",
            "   If job fails, try creating evaluation target first (see troubleshooting)\n"
          ]
        }
      ],
      "source": [
        "# Target Model Configuration\n",
        "# IMPORTANT: Use NIM Model Serving (anemo-rhoai) for meta-llama-2-7b-chat\n",
        "# This uses the NIM Model Serving InferenceService (KServe/Knative) on port 80\n",
        "#\n",
        "# ‚ö†Ô∏è  WORKAROUND for Evaluator v25.06 URL stripping bug:\n",
        "# Evaluator strips /chat/completions from Knative URLs, so we configure the base URL\n",
        "# and rely on the model_id to indicate it's a chat model.\n",
        "\n",
        "from config import NMS_NAMESPACE\n",
        "\n",
        "# This uses the NIM Model Serving service (anemo-rhoai) deployed via Helm chart\n",
        "# Use NIM_URL_CLUSTER from config (automatically uses NIM Model Serving if enabled)\n",
        "import importlib\n",
        "import config\n",
        "importlib.reload(config)\n",
        "from config import NIM_URL_CLUSTER, NMS_NAMESPACE, ACTIVE_NIM_MODEL, ACTIVE_NIM_SERVICE\n",
        "\n",
        "# Use external URL to work around Evaluator URL stripping bug\n",
        "# External URLs may not have the same URL stripping issue as cluster-internal Knative URLs\n",
        "# External URLs require authentication - use service account token from environment\n",
        "base_url = NIM_URL_CLUSTER.rstrip('/')\n",
        "# Get service account token from environment (set in cell 1)\n",
        "SERVICE_ACCOUNT_TOKEN = os.environ.get(\"NIM_SERVICE_ACCOUNT_TOKEN\", \"\")\n",
        "if not SERVICE_ACCOUNT_TOKEN:\n",
        "    raise ValueError(\"NIM_SERVICE_ACCOUNT_TOKEN not set! Please set it in cell 1 (environment configuration).\")\n",
        "\n",
        "target_model_config = {\n",
        "    \"type\": \"model\",\n",
        "    \"model\": {\n",
        "        \"api_endpoint\": {\n",
        "            \"url\": f\"{base_url}/v1/chat/completions\",  # Full path with external URL\n",
        "            \"model_id\": ACTIVE_NIM_MODEL,  # meta/llama-3.2-1b-instruct (from NIM Model Serving)\n",
        "            \"format\": \"openai\",  # Specify format\n",
        "            \"api_key\": SERVICE_ACCOUNT_TOKEN  # Service account token for external URL authentication\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Target model configured: NIM Model Serving ({ACTIVE_NIM_MODEL})\")\n",
        "print(f\"   Service: {ACTIVE_NIM_SERVICE}\")\n",
        "print(f\"   URL: {base_url}/v1/chat/completions\")\n",
        "print(f\"   ‚ÑπÔ∏è  Using external URL with authentication token\")\n",
        "print(f\"   (External URL bypasses Evaluator URL stripping bug)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Define Evaluation Prompts\n",
        "\n",
        "Create prompts for the judge to evaluate completeness and correctness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Evaluation prompts defined\n"
          ]
        }
      ],
      "source": [
        "# System prompts for judge evaluation\n",
        "completeness_system_prompt = \"\"\"\n",
        "You are a judge. Rate how complete the summary is \n",
        "on a scale from 1 to 5:\n",
        "1 = missing critical information ‚Ä¶ 5 = fully complete\n",
        "Please respond with RATING: <number>\n",
        "\"\"\"\n",
        "\n",
        "correctness_system_prompt = \"\"\"\n",
        "You are a judge. Rate the summary's correctness \n",
        "(no false info) on a scale 1-5:\n",
        "1 = many inaccuracies ‚Ä¶ 5 = completely accurate\n",
        "Please respond with RATING: <number>\n",
        "\"\"\"\n",
        "\n",
        "# User prompt template (references dataset item and model output)\n",
        "user_prompt = \"\"\"\n",
        "Full Consult: {{ item.content }}\n",
        "Summary: {{ sample.output_text }}\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚úÖ Evaluation prompts defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create Evaluation Configuration\n",
        "\n",
        "Build the custom LLM-as-a-Judge evaluation configuration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Evaluation configuration created\n",
            "   - Type: custom\n",
            "   - Metrics: completeness, correctness\n",
            "   - Sample limit: 5 (for quick test)\n"
          ]
        }
      ],
      "source": [
        "llm_as_a_judge_config = {\n",
        "    \"type\": \"custom\",\n",
        "    \"name\": \"doctor_consult_summary_eval\",\n",
        "    \"tasks\": {\n",
        "        \"consult_summary_eval\": {\n",
        "            \"type\": \"chat-completion\",\n",
        "            \"params\": {\n",
        "                \"template\": {\n",
        "                    # Prompt sent to target LLM to generate summary\n",
        "                    \"messages\": [\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": \"Given a full medical consultation, please provide a 50 word summary of the consultation.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": \"Full Consult: {{ item.content }}\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"max_tokens\": 200\n",
        "                }\n",
        "            },\n",
        "            \"dataset\": {\n",
        "                \"files_url\": f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}/\",\n",
        "                \"limit\": 5  # Reduced for quick test - increase for full evaluation\n",
        "            },\n",
        "            \"metrics\": {\n",
        "                \"completeness\": {\n",
        "                    \"type\": \"llm-judge\",\n",
        "                    \"params\": {\n",
        "                        \"model\": judge_model_config,\n",
        "                        \"template\": {\n",
        "                            \"messages\": [\n",
        "                                {\"role\": \"system\", \"content\": completeness_system_prompt},\n",
        "                                {\"role\": \"user\", \"content\": user_prompt}\n",
        "                            ]\n",
        "                        },\n",
        "                        \"scores\": {\n",
        "                            \"completeness\": {\n",
        "                                \"type\": \"int\",\n",
        "                                \"parser\": {\n",
        "                                    \"type\": \"regex\",\n",
        "                                    \"pattern\": r\"RATING: *([0-9]+)\"\n",
        "                                }\n",
        "                            }\n",
        "                        }\n",
        "                    }\n",
        "                },\n",
        "                \"correctness\": {\n",
        "                    \"type\": \"llm-judge\",\n",
        "                    \"params\": {\n",
        "                        \"model\": judge_model_config,\n",
        "                        \"template\": {\n",
        "                            \"messages\": [\n",
        "                                {\"role\": \"system\", \"content\": correctness_system_prompt},\n",
        "                                {\"role\": \"user\", \"content\": user_prompt}\n",
        "                            ]\n",
        "                        },\n",
        "                        \"scores\": {\n",
        "                            \"correctness\": {\n",
        "                                \"type\": \"int\",\n",
        "                                \"parser\": {\n",
        "                                    \"type\": \"regex\",\n",
        "                                    \"pattern\": r\"RATING: *([0-9]+)\"\n",
        "                                }\n",
        "                            }\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Evaluation configuration created\")\n",
        "print(f\"   - Type: custom\")\n",
        "print(f\"   - Metrics: completeness, correctness\")\n",
        "print(f\"   - Sample limit: 5 (for quick test)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6.5: Create Evaluation Targets\n",
        "\n",
        "**‚ö†Ô∏è CRITICAL: Known Evaluator v25.06 Bug with NIM Model Serving (Knative)**\n",
        "\n",
        "There is a **known bug in NeMo Evaluator v25.06** that strips `/chat/completions` from Knative service URLs during job execution. This is a **fundamental Evaluator bug** that cannot be worked around in the notebook configuration.\n",
        "\n",
        "**What Happens:**\n",
        "1. ‚úÖ **Target creation works**: URLs are stored correctly with `/v1/chat/completions`\n",
        "2. ‚úÖ **Job submission works**: Jobs are accepted and created successfully  \n",
        "3. ‚ùå **Job execution fails**: Evaluator strips `/chat/completions` from the URL, resulting in:\n",
        "   ```\n",
        "   Error connecting to inference server at http://anemo-rhoai-predictor.../v1\n",
        "   ```\n",
        "   Instead of the correct: `http://anemo-rhoai-predictor.../v1/chat/completions`\n",
        "\n",
        "**Why This Happens:**\n",
        "- NIM Model Serving uses Knative/KServe InferenceServices\n",
        "- Evaluator v25.06 has a bug in its URL handling for Knative services\n",
        "- The bug strips path components from Knative URLs during job execution\n",
        "- NIM services require `/v1/chat/completions` endpoint - `/v1` alone doesn't work\n",
        "\n",
        "**Solutions:**\n",
        "1. **Use Standard NIM Service** instead - standard NIM services (not Knative) work correctly with Evaluator\n",
        "2. **Wait for Evaluator fix** - this needs to be fixed in the Evaluator codebase (bug persists in v25.08)\n",
        "3. **Use external API endpoints** - if your NIM service is accessible via external URL, that might work\n",
        "\n",
        "**Current Status**: \n",
        "- ‚úÖ Evaluator upgraded to v25.08\n",
        "- ‚ùå **Bug persists in v25.08** - URL stripping still occurs\n",
        "- This notebook is configured to use NIM Model Serving as requested, but **it will fail due to the Evaluator bug**\n",
        "- The configuration is correct, but Evaluator cannot work with Knative InferenceServices for LLM-as-a-Judge evaluation jobs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Cleaned up existing judge target (if any)\n",
            "Creating judge model evaluation target: meta-llama3-1b-instruct-judge\n",
            "‚úÖ Judge target created: meta-llama3-1b-instruct-judge\n",
            "\n",
            "üí° Judge target reference: anemo-rhoai/meta-llama3-1b-instruct-judge\n",
            "   (Will use this in evaluation config)\n"
          ]
        }
      ],
      "source": [
        "# Create evaluation target for judge model\n",
        "# Use target reference (created in previous cells) for cleaner configuration\n",
        "import requests\n",
        "from config import EVALUATOR_URL, NMS_NAMESPACE\n",
        "\n",
        "headers = {\n",
        "    'accept': 'application/json',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Delete existing target if it exists (for clean re-runs)\n",
        "from config import ACTIVE_NIM_MODEL\n",
        "# Get service account token from environment (set in cell 1)\n",
        "SERVICE_ACCOUNT_TOKEN = os.environ.get(\"NIM_SERVICE_ACCOUNT_TOKEN\", \"\")\n",
        "if not SERVICE_ACCOUNT_TOKEN:\n",
        "    raise ValueError(\"NIM_SERVICE_ACCOUNT_TOKEN not set! Please set it in cell 1 (environment configuration).\")\n",
        "\n",
        "judge_target_name = \"anemo-rhoai-llama-3.2-1b-judge\"\n",
        "try:\n",
        "    res = requests.delete(f\"{EVALUATOR_URL}/v1/evaluation/targets/{NMS_NAMESPACE}/{judge_target_name}\")\n",
        "    if res.status_code in (200, 404):\n",
        "        print(f\"‚úÖ Cleaned up existing judge target (if any)\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Create judge model target\n",
        "judge_target_data = {\n",
        "    \"type\": \"model\",\n",
        "    \"name\": judge_target_name,\n",
        "    \"namespace\": NMS_NAMESPACE,\n",
        "    \"model\": {\n",
        "        \"api_endpoint\": {\n",
        "            # Use external URL with full path - may work around Evaluator URL stripping\n",
        "            \"url\": f\"{NIM_URL_CLUSTER.rstrip('/')}/v1/chat/completions\",\n",
        "            \"model_id\": ACTIVE_NIM_MODEL,  # meta/llama-3.2-1b-instruct\n",
        "            \"format\": \"openai\",  # Specify format\n",
        "            \"api_key\": SERVICE_ACCOUNT_TOKEN  # Service account token for authentication\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Creating judge model evaluation target: {judge_target_name}\")\n",
        "res = requests.post(f\"{EVALUATOR_URL}/v1/evaluation/targets\", headers=headers, json=judge_target_data)\n",
        "\n",
        "if res.status_code not in (200, 201):\n",
        "    print(f\"‚ö†Ô∏è  Warning: Could not create judge target: {res.status_code}\")\n",
        "    print(f\"Response: {res.text[:200]}\")\n",
        "    # Continue anyway - might already exist\n",
        "else:\n",
        "    judge_target_response = res.json()\n",
        "    print(f\"‚úÖ Judge target created: {judge_target_response.get('name')}\")\n",
        "\n",
        "# Update judge_model_config to use target name for job submission\n",
        "# The config will reference this target by name\n",
        "judge_target_ref = f\"{NMS_NAMESPACE}/{judge_target_name}\"\n",
        "print(f\"\\nüí° Judge target reference: {judge_target_ref}\")\n",
        "print(\"   (Will use this in evaluation config)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Cleaned up existing target model target (if any)\n",
            "Creating target model evaluation target: meta-llama3-1b-instruct-target\n",
            "‚úÖ Target model target created: meta-llama3-1b-instruct-target\n",
            "\n",
            "üí° Target model reference: anemo-rhoai/meta-llama3-1b-instruct-target\n",
            "   (Will use this in job submission)\n"
          ]
        }
      ],
      "source": [
        "# Create evaluation target for target model\n",
        "# Delete existing target if it exists (for clean re-runs)\n",
        "from config import ACTIVE_NIM_MODEL\n",
        "# Get service account token from environment (set in cell 1)\n",
        "SERVICE_ACCOUNT_TOKEN = os.environ.get(\"NIM_SERVICE_ACCOUNT_TOKEN\", \"\")\n",
        "if not SERVICE_ACCOUNT_TOKEN:\n",
        "    raise ValueError(\"NIM_SERVICE_ACCOUNT_TOKEN not set! Please set it in cell 1 (environment configuration).\")\n",
        "\n",
        "target_target_name = \"anemo-rhoai-llama-3.2-1b-target\"\n",
        "try:\n",
        "    res = requests.delete(f\"{EVALUATOR_URL}/v1/evaluation/targets/{NMS_NAMESPACE}/{target_target_name}\")\n",
        "    if res.status_code in (200, 404):\n",
        "        print(f\"‚úÖ Cleaned up existing target model target (if any)\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Create target model evaluation target\n",
        "target_target_data = {\n",
        "    \"type\": \"model\",\n",
        "    \"name\": target_target_name,\n",
        "    \"namespace\": NMS_NAMESPACE,\n",
        "    \"model\": {\n",
        "        \"api_endpoint\": {\n",
        "            # Use external URL with full path - may work around Evaluator URL stripping\n",
        "            \"url\": f\"{NIM_URL_CLUSTER.rstrip('/')}/v1/chat/completions\",\n",
        "            \"model_id\": ACTIVE_NIM_MODEL,  # meta/llama-3.2-1b-instruct\n",
        "            \"format\": \"openai\",  # Specify format\n",
        "            \"api_key\": SERVICE_ACCOUNT_TOKEN  # Service account token for authentication\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Creating target model evaluation target: {target_target_name}\")\n",
        "res = requests.post(f\"{EVALUATOR_URL}/v1/evaluation/targets\", headers=headers, json=target_target_data)\n",
        "\n",
        "if res.status_code not in (200, 201):\n",
        "    print(f\"‚ö†Ô∏è  Warning: Could not create target model target: {res.status_code}\")\n",
        "    print(f\"Response: {res.text[:200]}\")\n",
        "    # Continue anyway - might already exist\n",
        "else:\n",
        "    target_target_response = res.json()\n",
        "    print(f\"‚úÖ Target model target created: {target_target_response.get('name')}\")\n",
        "\n",
        "# Store target reference for job submission\n",
        "target_model_ref = f\"{NMS_NAMESPACE}/{target_target_name}\"\n",
        "print(f\"\\nüí° Target model reference: {target_model_ref}\")\n",
        "print(\"   (Will use this in job submission)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Submit Evaluation Job\n",
        "\n",
        "Submit the evaluation job to NeMo Evaluator.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì§ Submitting evaluation job with inline target config...\n",
            "   Target: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/chat/completions\n",
            "‚úÖ Evaluation job submitted\n",
            "   Job ID: eval-VgyjqL9ciYXZ9XCVGGLmfe\n",
            "   Status: created\n"
          ]
        }
      ],
      "source": [
        "# Submit evaluation job\n",
        "# IMPORTANT: Use inline target config (like original notebook) to avoid Data Store validation issues\n",
        "# Using inline config bypasses evaluation target lookup which triggers Data Store dataset validation\n",
        "try:\n",
        "    # Use inline target config (matches original notebook approach)\n",
        "    job_payload = {\n",
        "        \"config\": llm_as_a_judge_config,\n",
        "        \"target\": target_model_config  # Use inline config object, not target reference\n",
        "    }\n",
        "    \n",
        "    print(\"üì§ Submitting evaluation job with inline target config...\")\n",
        "    print(f\"   Target: {target_model_config['model']['api_endpoint']['url']}\")\n",
        "    \n",
        "    res = requests.post(\n",
        "        f\"{EVALUATOR_URL}/v1/evaluation/jobs\",\n",
        "        json=job_payload,\n",
        "        timeout=30\n",
        "    )\n",
        "\n",
        "    if res.status_code not in (200, 201):\n",
        "        print(f\"‚ùå Failed to submit job: {res.status_code}\")\n",
        "        print(f\"Response: {res.text}\")\n",
        "        raise Exception(f\"Job submission failed: {res.status_code} - {res.text}\")\n",
        "\n",
        "    job_data = res.json()\n",
        "    base_eval_job_id = job_data[\"id\"]\n",
        "    print(f\"‚úÖ Evaluation job submitted\")\n",
        "    print(f\"   Job ID: {base_eval_job_id}\")\n",
        "    print(f\"   Status: {job_data.get('status', 'unknown')}\")\n",
        "    \n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"‚ùå Network error submitting job: {e}\")\n",
        "    print(f\"   Check that Evaluator is accessible at: {EVALUATOR_URL}\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error submitting job: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Wait for Job Completion\n",
        "\n",
        "Monitor the evaluation job until it completes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Waiting for evaluation job to complete...\n",
            "Initial status: running\n",
            "‚è≥ Status: running | Progress: 60.0% | Elapsed: 5.2s\n",
            "‚úÖ Status: completed | Progress: 100% | Elapsed: 10.3s\n"
          ]
        }
      ],
      "source": [
        "from time import sleep, time\n",
        "\n",
        "def wait_eval_job(job_url: str, polling_interval: int = 10, timeout: int = 600):\n",
        "    \"\"\"Helper for waiting an eval job with error handling.\"\"\"\n",
        "    start_time = time()\n",
        "    \n",
        "    try:\n",
        "        res = requests.get(job_url, timeout=10)\n",
        "        if res.status_code != 200:\n",
        "            raise Exception(f\"Failed to get job status: {res.status_code} - {res.text}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        raise Exception(f\"Network error getting job status: {e}\")\n",
        "    \n",
        "    job_data = res.json()\n",
        "    status = job_data[\"status\"]\n",
        "    print(f\"Initial status: {status}\")\n",
        "    \n",
        "    # Check for immediate terminal states\n",
        "    if status == \"failed\":\n",
        "        print(f\"‚ùå Job failed immediately!\")\n",
        "        status_details = job_data.get('status_details', {})\n",
        "        error_msg = status_details.get('message', 'Unknown error')\n",
        "        print(f\"Error: {error_msg}\")\n",
        "        return res\n",
        "    elif status == \"completed\":\n",
        "        print(f\"‚úÖ Job completed immediately!\")\n",
        "        return res\n",
        "\n",
        "    # Poll for status updates\n",
        "    while status in [\"pending\", \"created\", \"running\"]:\n",
        "        # Check for timeout\n",
        "        elapsed = time() - start_time\n",
        "        if elapsed > timeout:\n",
        "            raise RuntimeError(f\"Job took more than {timeout} seconds (timed out).\")\n",
        "\n",
        "        # Sleep before polling again\n",
        "        sleep(polling_interval)\n",
        "\n",
        "        # Fetch updated status and progress\n",
        "        try:\n",
        "            res = requests.get(job_url, timeout=10)\n",
        "            if res.status_code != 200:\n",
        "                print(f\"‚ö†Ô∏è  Failed to get status: {res.status_code} - {res.text}\")\n",
        "                sleep(polling_interval)  # Wait before retrying\n",
        "                continue\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"‚ö†Ô∏è  Network error getting status: {e} - retrying...\")\n",
        "            sleep(polling_interval)\n",
        "            continue\n",
        "            \n",
        "        job_data = res.json()\n",
        "        status = job_data[\"status\"]\n",
        "        elapsed = time() - start_time\n",
        "\n",
        "        # Handle terminal states immediately\n",
        "        if status == \"failed\":\n",
        "            print(f\"\\n‚ùå Job failed after {elapsed:.1f}s\")\n",
        "            status_details = job_data.get('status_details', {})\n",
        "            error_msg = status_details.get('message', 'Unknown error')\n",
        "            print(f\"Error: {error_msg}\")\n",
        "            \n",
        "            # Print task status if available\n",
        "            task_status = status_details.get('task_status', {})\n",
        "            if task_status:\n",
        "                print(f\"\\nTask status details:\")\n",
        "                for task_name, task_info in task_status.items():\n",
        "                    print(f\"  - {task_name}: {task_info}\")\n",
        "            return res\n",
        "        elif status == \"completed\":\n",
        "            progress = 100\n",
        "            print(f\"‚úÖ Status: {status} | Progress: {progress}% | Elapsed: {elapsed:.1f}s\")\n",
        "            return res\n",
        "        elif status == \"running\":\n",
        "            progress = job_data.get(\"status_details\", {}).get(\"progress\", 0)\n",
        "            print(f\"‚è≥ Status: {status} | Progress: {progress}% | Elapsed: {elapsed:.1f}s\")\n",
        "        else:\n",
        "            # Unknown status - log and continue\n",
        "            print(f\"‚ö†Ô∏è  Status: {status} | Elapsed: {elapsed:.1f}s\")\n",
        "\n",
        "    # If we exit the loop, status should be terminal, but check anyway\n",
        "    if status not in [\"completed\", \"failed\"]:\n",
        "        print(f\"‚ö†Ô∏è  Unexpected final status: {status}\")\n",
        "        print(f\"   Full job data: {job_data}\")\n",
        "\n",
        "    return res\n",
        "\n",
        "print(\"‚è≥ Waiting for evaluation job to complete...\")\n",
        "try:\n",
        "    res = wait_eval_job(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}\", polling_interval=5, timeout=600)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error waiting for job: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Job completed successfully!\n",
            "   You can now view results in the next cell.\n"
          ]
        }
      ],
      "source": [
        "# Check final status (this cell provides additional details if needed)\n",
        "try:\n",
        "    job_data = res.json()\n",
        "    final_status = job_data[\"status\"]\n",
        "    \n",
        "    if final_status == \"completed\":\n",
        "        print(f\"‚úÖ Job completed successfully!\")\n",
        "        print(f\"   You can now view results in the next cell.\")\n",
        "    elif final_status == \"failed\":\n",
        "        print(f\"\\n‚ùå Job failed - Summary:\")\n",
        "        status_details = job_data.get('status_details', {})\n",
        "        error_msg = status_details.get('message', 'Unknown error')\n",
        "        \n",
        "        # Extract key error information\n",
        "        if \"Error connecting to inference server\" in error_msg:\n",
        "            print(f\"   Issue: Cannot connect to NIM endpoint\")\n",
        "            print(f\"   Check: Is the NIM service running and accessible from cluster?\")\n",
        "            print(f\"   URL used: Check the target/judge model configuration\")\n",
        "        \n",
        "        print(f\"\\n   Full error message:\")\n",
        "        print(f\"   {error_msg[:500]}...\")  # Truncate very long errors\n",
        "        \n",
        "        # Print task status if available\n",
        "        task_status = status_details.get('task_status', {})\n",
        "        if task_status:\n",
        "            print(f\"\\n   Task status details:\")\n",
        "            for task_name, task_info in task_status.items():\n",
        "                print(f\"     - {task_name}: {task_info}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Job status: {final_status}\")\n",
        "        print(f\"   Full response: {job_data}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Error parsing job status: {e}\")\n",
        "    print(f\"   Raw response: {res.text if hasattr(res, 'text') else res}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: View Results\n",
        "\n",
        "Retrieve and display the evaluation results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Task: consult_summary_eval\n",
            "   completeness: 4.0 (mean: 4.0, count: 5)\n",
            "   correctness: 1.6 (mean: 1.6, count: 5)\n",
            "\n",
            "‚úÖ Results retrieved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Get results\n",
        "try:\n",
        "    res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}/results\", timeout=30)\n",
        "    \n",
        "    if res.status_code == 200:\n",
        "        results = res.json()\n",
        "        \n",
        "        # Extract metrics\n",
        "        tasks = results.get(\"tasks\", {})\n",
        "        if not tasks:\n",
        "            print(\"‚ö†Ô∏è  No tasks found in results\")\n",
        "            print(f\"   Full response: {results}\")\n",
        "        else:\n",
        "            for task_name, task_data in tasks.items():\n",
        "                print(f\"\\nüìä Task: {task_name}\")\n",
        "                metrics = task_data.get(\"metrics\", {})\n",
        "                if not metrics:\n",
        "                    print(f\"   ‚ö†Ô∏è  No metrics found for this task\")\n",
        "                else:\n",
        "                    for metric_name, metric_data in metrics.items():\n",
        "                        scores = metric_data.get(\"scores\", {})\n",
        "                        if not scores:\n",
        "                            print(f\"   ‚ö†Ô∏è  No scores found for metric: {metric_name}\")\n",
        "                        else:\n",
        "                            for score_name, score_data in scores.items():\n",
        "                                value = score_data.get(\"value\", \"N/A\")\n",
        "                                stats = score_data.get(\"stats\", {})\n",
        "                                mean = stats.get(\"mean\", \"N/A\")\n",
        "                                count = stats.get(\"count\", \"N/A\")\n",
        "                                print(f\"   {score_name}: {value} (mean: {mean}, count: {count})\")\n",
        "        \n",
        "        print(f\"\\n‚úÖ Results retrieved successfully!\")\n",
        "    elif res.status_code == 404:\n",
        "        print(f\"‚ö†Ô∏è  Results not yet available (404)\")\n",
        "        print(f\"   Job may still be processing. Wait a moment and try again.\")\n",
        "    else:\n",
        "        print(f\"‚ùå Failed to get results: {res.status_code}\")\n",
        "        print(f\"   Response: {res.text}\")\n",
        "        \n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"‚ùå Network error getting results: {e}\")\n",
        "    print(f\"   Check that Evaluator is accessible at: {EVALUATOR_URL}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error getting results: {e}\")\n",
        "    raise\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
