{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom LLM-as-a-Judge Implementation\n",
    "\n",
    "This notebook demonstrates how to leverage Custom LLM-as-a-Judge through NeMo Evaluator Microservice.\n",
    "\n",
    "Full documentation: [NeMo Evaluator Custom Evaluation](https://docs.nvidia.com/nemo/microservices/latest/evaluate/evaluation-custom.html#evaluation-with-llm-as-a-judge)\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this example, we'll evaluate medical consultation summaries using:\n",
    "- **Target Model**: A model that generates summaries (default: your deployed NIM, no API key needed)\n",
    "- **Judge Model**: A model that evaluates the summaries (default: your deployed NIM, no API key needed)\n",
    "  - Evaluates on two metrics:\n",
    "    - **Completeness**: How well the summary captures all critical information (1-5 scale)\n",
    "    - **Correctness**: How accurate the summary is without false information (1-5 scale)\n",
    "\n",
    "**No API keys required!** The notebook is pre-configured to use your deployed NIM endpoint for both models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- NeMo Evaluator service deployed\n",
    "- NeMo Data Store service deployed\n",
    "- NeMo Entity Store service deployed\n",
    "- **Judge Model**: Choose one:\n",
    "  - Option A: OpenAI API key (for GPT-4.1 judge) - **Optional**\n",
    "  - Option B: NVIDIA API key (for NVIDIA models as judge)\n",
    "  - Option C: Your deployed NIM endpoint (no API key needed)\n",
    "- **Target Model**: NVIDIA API key OR your deployed NIM endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Set RUN_LOCALLY=true (using localhost with port-forwards)\n",
      "Collecting git+https://github.com/meta-llama/llama-stack-client-python.git@main\n",
      "  Cloning https://github.com/meta-llama/llama-stack-client-python.git (to revision main) to /private/var/folders/54/0nyyn56s1bsd1kbwqv8fdwxr0000gn/T/pip-req-build-r6o1bsk6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/meta-llama/llama-stack-client-python.git /private/var/folders/54/0nyyn56s1bsd1kbwqv8fdwxr0000gn/T/pip-req-build-r6o1bsk6\n",
      "  Resolved https://github.com/meta-llama/llama-stack-client-python.git to commit f8eb65140836de310042c914be5ec8c26e87554a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (4.10.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (8.1.8)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (1.9.0)\n",
      "Requirement already satisfied: fire in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (0.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (0.28.1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (2.2.3)\n",
      "Requirement already satisfied: prompt-toolkit in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (3.0.50)\n",
      "Requirement already satisfied: pyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (25.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (2.9.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (2.32.3)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (13.9.4)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (1.3.1)\n",
      "Requirement already satisfied: termcolor in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (3.1.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama_stack_client==0.4.0a12) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->llama_stack_client==0.4.0a12) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.4.0a12) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client==0.4.0a12) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama_stack_client==0.4.0a12) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.4.0a12) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client==0.4.0a12) (2.23.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a12) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a12) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a12) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->llama_stack_client==0.4.0a12) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama_stack_client==0.4.0a12) (1.17.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from prompt-toolkit->llama_stack_client==0.4.0a12) (0.2.13)\n",
      "Requirement already satisfied: PyYAML in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyaml->llama_stack_client==0.4.0a12) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->llama_stack_client==0.4.0a12) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->llama_stack_client==0.4.0a12) (1.26.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->llama_stack_client==0.4.0a12) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->llama_stack_client==0.4.0a12) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama_stack_client==0.4.0a12) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.34.4)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.4.1)\n",
      "Requirement already satisfied: jupyterlab in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.3.6)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.99.9)\n",
      "Requirement already satisfied: llama-stack-client in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.4.0a12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (6.29.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (75.8.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (6.4.2)\n",
      "Requirement already satisfied: traitlets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (8.6.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (26.3.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (8.1.8)\n",
      "Requirement already satisfied: fire in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (0.7.0)\n",
      "Requirement already satisfied: prompt-toolkit in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (3.0.50)\n",
      "Requirement already satisfied: pyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (25.7.0)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (13.9.4)\n",
      "Requirement already satisfied: termcolor in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from llama-stack-client) (3.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.32.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (6.1.1)\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from prompt-toolkit->llama-stack-client) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: rfc3339-validator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (5.0.1)\n",
      "Requirement already satisfied: defusedxml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.2,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.1.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.6)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241206)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->llama-stack-client) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama-stack-client) (0.1.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Set RUN_LOCALLY BEFORE importing config (for port-forward mode)\n",
    "import os\n",
    "if \"RUN_LOCALLY\" not in os.environ:\n",
    "    os.environ[\"RUN_LOCALLY\"] = \"true\"\n",
    "    print(\"‚úÖ Set RUN_LOCALLY=true (using localhost with port-forwards)\")\n",
    "\n",
    "# Install llama-stack-client from GitHub main (same as llamastack demo)\n",
    "# This ensures compatibility with the latest server version\n",
    "%pip install --upgrade git+https://github.com/meta-llama/llama-stack-client-python.git@main\n",
    "\n",
    "# Install required packages\n",
    "%pip install requests huggingface-hub datasets jupyterlab python-dotenv openai llama-stack-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "Mode: Local (port-forward)\n",
      "Data Store: http://localhost:8001\n",
      "Entity Store: http://localhost:8002\n",
      "Evaluator: http://localhost:8004\n",
      "LlamaStack: http://localhost:8321\n",
      "Namespace: anemo-rhoai\n",
      "Dataset: custom-llm-as-a-judge-eval-data\n",
      "‚úÖ Data Store connectivity: OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/ \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LlamaStack connectivity: OK\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "from config import (\n",
    "    NDS_URL, ENTITY_STORE_URL, EVALUATOR_URL, NEMO_URL, LLAMASTACK_URL,\n",
    "    NMS_NAMESPACE, DATASET_NAME, NDS_TOKEN,\n",
    "    OPENAI_API_KEY, NVIDIA_API_KEY, RUN_LOCALLY\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Configuration loaded\")\n",
    "print(f\"Mode: {'Local (port-forward)' if RUN_LOCALLY else 'Cluster'}\")\n",
    "print(f\"Data Store: {NDS_URL}\")\n",
    "print(f\"Entity Store: {ENTITY_STORE_URL}\")\n",
    "print(f\"Evaluator: {EVALUATOR_URL}\")\n",
    "print(f\"LlamaStack: {LLAMASTACK_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "\n",
    "# Quick connectivity test\n",
    "import requests\n",
    "try:\n",
    "    r = requests.get(f\"{NDS_URL}/v1/datastore/namespaces\", timeout=2)\n",
    "    print(f\"‚úÖ Data Store connectivity: OK\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Data Store connectivity: FAILED - {e}\")\n",
    "    if RUN_LOCALLY:\n",
    "        print(f\"\\nüì° Port-forward setup required for local mode:\")\n",
    "        print(f\"   Run this in a terminal:\")\n",
    "        print(f\"   ./port-forward.sh\")\n",
    "        print(f\"\\n   Or manually:\")\n",
    "        print(f\"   oc port-forward -n {NMS_NAMESPACE} svc/nemodatastore-sample 8001:8000 &\")\n",
    "        print(f\"   oc port-forward -n {NMS_NAMESPACE} svc/nemoentitystore-sample 8002:8000 &\")\n",
    "        print(f\"   oc port-forward -n {NMS_NAMESPACE} svc/nemoevaluator-sample 8004:8000 &\")\n",
    "        print(f\"   oc port-forward -n {NMS_NAMESPACE} svc/llamastack 8321:8321 &\")\n",
    "    else:\n",
    "        print(f\"   If running from outside cluster, set RUN_LOCALLY=true environment variable\")\n",
    "        print(f\"   Or ensure you're running this notebook from within the cluster\")\n",
    "\n",
    "# Initialize LlamaStack client\n",
    "try:\n",
    "    from llama_stack_client import LlamaStackClient\n",
    "    client = LlamaStackClient(base_url=LLAMASTACK_URL)\n",
    "    # Test connectivity\n",
    "    try:\n",
    "        server_info = client._client.get(\"/\")\n",
    "        print(f\"‚úÖ LlamaStack connectivity: OK\")\n",
    "        try:\n",
    "            client_version = client._client._version\n",
    "            print(f\"   LlamaStack client version: {client_version}\")\n",
    "        except:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  LlamaStack connectivity: FAILED - {e}\")\n",
    "        print(f\"   Make sure LlamaStack is deployed and port-forward is active: oc port-forward -n {NMS_NAMESPACE} svc/llamastack 8321:8321\")\n",
    "        client = None\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  LlamaStack client not available - install with: %pip install --upgrade git+https://github.com/meta-llama/llama-stack-client-python.git@main\")\n",
    "    print(\"   Continuing without LlamaStack integration...\")\n",
    "    client = None\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  LlamaStack initialization failed: {e}\")\n",
    "    print(\"   Continuing without LlamaStack integration...\")\n",
    "    client = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set Up Namespaces\n",
    "\n",
    "Create namespaces in both Entity Store and Data Store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entity Store namespace created/verified: anemo-rhoai\n",
      "‚úÖ Data Store namespace created/verified: anemo-rhoai\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def create_namespaces(entity_host, ds_host, namespace):\n",
    "    \"\"\"Create namespace in both Entity Store and Data Store.\"\"\"\n",
    "    # Create namespace in Entity Store\n",
    "    entity_store_url = f\"{entity_host}/v1/namespaces\"\n",
    "    resp = requests.post(entity_store_url, json={\"id\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Entity Store: {resp.status_code} - {resp.text}\"\n",
    "    print(f\"‚úÖ Entity Store namespace created/verified: {namespace}\")\n",
    "\n",
    "    # Create namespace in Data Store\n",
    "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
    "    resp = requests.post(nds_url, data={\"namespace\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Data Store: {resp.status_code} - {resp.text}\"\n",
    "    print(f\"‚úÖ Data Store namespace created/verified: {namespace}\")\n",
    "\n",
    "create_namespaces(entity_host=ENTITY_STORE_URL, ds_host=NDS_URL, namespace=NMS_NAMESPACE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Dataset to Data Store\n",
    "\n",
    "Upload the medical consultation data to the Data Store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository ID: anemo-rhoai/custom-llm-as-a-judge-eval-data\n",
      "‚ÑπÔ∏è  Namespace check: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'anemo-rhoai/.namespace-init'.\n",
      "‚úÖ Repository created: anemo-rhoai/custom-llm-as-a-judge-eval-data\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\"\n",
    "print(f\"Repository ID: {repo_id}\")\n",
    "\n",
    "# Create HfApi client pointing to NeMo Data Store\n",
    "hf_api = HfApi(endpoint=f\"{NDS_URL}/v1/hf\", token=NDS_TOKEN if NDS_TOKEN != \"token\" else None)\n",
    "\n",
    "# IMPORTANT: Ensure namespace exists in Gitea before creating repository\n",
    "# Data Store's Gitea backend needs the namespace directory to exist,\n",
    "# otherwise it defaults to \"default\" namespace. Creating a temporary\n",
    "# repository first ensures the namespace is created in Gitea.\n",
    "temp_repo_id = f\"{NMS_NAMESPACE}/.namespace-init\"\n",
    "try:\n",
    "    # Create temporary repo to ensure namespace exists in Gitea\n",
    "    hf_api.create_repo(repo_id=temp_repo_id, repo_type='dataset', exist_ok=True)\n",
    "    # Delete temporary repo (namespace directory will remain)\n",
    "    try:\n",
    "        hf_api.delete_repo(repo_id=temp_repo_id, repo_type='dataset')\n",
    "    except:\n",
    "        pass  # Ignore if deletion fails\n",
    "    print(f\"‚úÖ Namespace '{NMS_NAMESPACE}' initialized in Gitea\")\n",
    "except Exception as e:\n",
    "    # If temp repo creation fails, namespace might already exist - continue\n",
    "    print(f\"‚ÑπÔ∏è  Namespace check: {e}\")\n",
    "\n",
    "# Create repository (now namespace should exist in Gitea)\n",
    "try:\n",
    "    hf_api.create_repo(repo_id=repo_id, repo_type='dataset', exist_ok=True)\n",
    "    print(f\"‚úÖ Repository created: {repo_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Repository may already exist: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data uploaded to anemo-rhoai/custom-llm-as-a-judge-eval-data\n"
     ]
    }
   ],
   "source": [
    "# Upload data file\n",
    "data_file = \"./data/doctor_consults_with_summaries.jsonl\"\n",
    "\n",
    "try:\n",
    "    hf_api.upload_file(\n",
    "        path_or_fileobj=data_file,\n",
    "        path_in_repo=\"doctor_consults_with_summaries.jsonl\",\n",
    "        repo_id=repo_id,\n",
    "        repo_type='dataset',\n",
    "    )\n",
    "    print(f\"‚úÖ Data uploaded to {repo_id}\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower() or \"409\" in str(e):\n",
    "        print(f\"‚ÑπÔ∏è  File already exists in repository (this is OK)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Upload warning: {e}\")\n",
    "        # Try to continue anyway - file might already be there\n",
    "        print(f\"   Continuing...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Register Dataset in Entity Store\n",
    "\n",
    "Register the dataset so it can be used in evaluation jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è  Dataset already exists: custom-llm-as-a-judge-eval-data (this is OK)\n",
      "‚úÖ Dataset verified. Files URL: hf://datasets/anemo-rhoai/custom-llm-as-a-judge-eval-data\n"
     ]
    }
   ],
   "source": [
    "# Register dataset in Entity Store\n",
    "resp = requests.post(\n",
    "    url=f\"{ENTITY_STORE_URL}/v1/datasets\",\n",
    "    json={\n",
    "        \"name\": DATASET_NAME,\n",
    "        \"namespace\": NMS_NAMESPACE,\n",
    "        \"description\": \"Medical consultation summaries for LLM-as-a-Judge evaluation\",\n",
    "        \"files_url\": f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}\",\n",
    "        \"project\": \"custom-llm-as-a-judge-test\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Handle response - 409 means dataset already exists (OK for re-running notebook)\n",
    "if resp.status_code in (200, 201):\n",
    "    print(f\"‚úÖ Dataset registered: {DATASET_NAME}\")\n",
    "elif resp.status_code == 409:\n",
    "    print(f\"‚ÑπÔ∏è  Dataset already exists: {DATASET_NAME} (this is OK)\")\n",
    "else:\n",
    "    raise Exception(f\"Status Code {resp.status_code} Failed to create dataset: {resp.text}\")\n",
    "\n",
    "# Verify dataset exists\n",
    "res = requests.get(url=f\"{ENTITY_STORE_URL}/v1/datasets/{NMS_NAMESPACE}/{DATASET_NAME}\")\n",
    "if res.status_code not in (200, 201):\n",
    "    raise Exception(f\"Status Code {res.status_code} Failed to fetch dataset: {res.text}\")\n",
    "\n",
    "dataset_obj = res.json()\n",
    "print(f\"‚úÖ Dataset verified. Files URL: {dataset_obj['files_url']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Configure Judge LLM and Target Model\n",
    "\n",
    "Set up the judge model (OpenAI) and target model (for generating summaries).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Judge model configured: Your NIM (meta/llama-3.2-1b-instruct)\n",
      "‚ÑπÔ∏è  Creating evaluation target with cluster URL: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/chat/completions\n",
      "   (Service mesh handles authentication - no token needed)\n",
      "   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\n",
      "   If job fails, this is a known Evaluator limitation\n"
     ]
    }
   ],
   "source": [
    "# Judge LLM Configuration\n",
    "# IMPORTANT: Use NIM_URL_CLUSTER from config (matches e2e-notebook pattern)\n",
    "# This uses the standard NIM service (meta-llama3-1b-instruct) on port 8000\n",
    "\n",
    "# Option 1: Use your deployed NIM as judge (RECOMMENDED - no API key needed)\n",
    "# This uses the standard NIM service (meta-llama3-1b-instruct) on port 8000\n",
    "# Use NIM_URL_CLUSTER from config (matches e2e-notebook pattern)\n",
    "import importlib\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import NIM_URL_CLUSTER\n",
    "\n",
    "judge_model_config = {\n",
    "    \"api_endpoint\": {\n",
    "        \"url\": f\"{NIM_URL_CLUSTER}/v1/chat/completions\",  # Full path with revision service\n",
    "        \"model_id\": \"meta/llama-3.2-1b-instruct\",  # Adjust to your deployed model\n",
    "        \"format\": \"openai\"  # Specify format - may help with URL handling\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Judge model configured: Your NIM (meta/llama-3.2-1b-instruct)\")\n",
    "print(f\"‚ÑπÔ∏è  Creating evaluation target with cluster URL: {NIM_URL_CLUSTER}/v1/chat/completions\")\n",
    "print(\"   (Service mesh handles authentication - no token needed)\")\n",
    "print(\"   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\")\n",
    "print(\"   If job fails, this is a known Evaluator limitation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Target model configured: Your NIM (meta/llama-3.2-1b-instruct)\n",
      "‚ÑπÔ∏è  Creating evaluation target with cluster URL: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/chat/completions\n",
      "   (Service mesh handles authentication - no token needed)\n",
      "   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\n",
      "   If job fails, try creating evaluation target first (see troubleshooting)\n"
     ]
    }
   ],
   "source": [
    "# Target Model Configuration\n",
    "# IMPORTANT: Use NIM_URL_CLUSTER from config (matches e2e-notebook pattern)\n",
    "# This uses the standard NIM service (meta-llama3-1b-instruct) on port 8000\n",
    "\n",
    "# Option 1: Use your deployed NIM as target (RECOMMENDED - no API key needed)\n",
    "from config import NMS_NAMESPACE\n",
    "\n",
    "# This uses the standard NIM service (meta-llama3-1b-instruct) on port 8000\n",
    "# Then use: oc get svc <name>-<revision> -n <namespace>\n",
    "# Use NIM_URL_CLUSTER from config (matches e2e-notebook pattern)\n",
    "import importlib\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import NIM_URL_CLUSTER, NMS_NAMESPACE\n",
    "\n",
    "target_model_config = {\n",
    "    \"type\": \"model\",\n",
    "    \"model\": {\n",
    "        \"api_endpoint\": {\n",
    "            \"url\": f\"{NIM_URL_CLUSTER}/v1/chat/completions\",  # Full path with revision service\n",
    "            \"model_id\": \"meta/llama-3.2-1b-instruct\",  # Adjust to your deployed model\n",
    "            \"format\": \"openai\"  # Specify format - may help with URL handling\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Target model configured: Your NIM (meta/llama-3.2-1b-instruct)\")\n",
    "print(f\"‚ÑπÔ∏è  Creating evaluation target with cluster URL: {NIM_URL_CLUSTER}/v1/chat/completions\")\n",
    "print(\"   (Service mesh handles authentication - no token needed)\")\n",
    "print(\"   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\")\n",
    "print(\"   If job fails, try creating evaluation target first (see troubleshooting)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Evaluation Prompts\n",
    "\n",
    "Create prompts for the judge to evaluate completeness and correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation prompts defined\n"
     ]
    }
   ],
   "source": [
    "# System prompts for judge evaluation\n",
    "completeness_system_prompt = \"\"\"\n",
    "You are a judge. Rate how complete the summary is \n",
    "on a scale from 1 to 5:\n",
    "1 = missing critical information ‚Ä¶ 5 = fully complete\n",
    "Please respond with RATING: <number>\n",
    "\"\"\"\n",
    "\n",
    "correctness_system_prompt = \"\"\"\n",
    "You are a judge. Rate the summary's correctness \n",
    "(no false info) on a scale 1-5:\n",
    "1 = many inaccuracies ‚Ä¶ 5 = completely accurate\n",
    "Please respond with RATING: <number>\n",
    "\"\"\"\n",
    "\n",
    "# User prompt template (references dataset item and model output)\n",
    "user_prompt = \"\"\"\n",
    "Full Consult: {{ item.content }}\n",
    "Summary: {{ sample.output_text }}\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ Evaluation prompts defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Evaluation Configuration\n",
    "\n",
    "Build the custom LLM-as-a-Judge evaluation configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation configuration created\n",
      "   - Type: custom\n",
      "   - Metrics: completeness, correctness\n",
      "   - Sample limit: 5 (for quick test)\n"
     ]
    }
   ],
   "source": [
    "llm_as_a_judge_config = {\n",
    "    \"type\": \"custom\",\n",
    "    \"name\": \"doctor_consult_summary_eval\",\n",
    "    \"tasks\": {\n",
    "        \"consult_summary_eval\": {\n",
    "            \"type\": \"chat-completion\",\n",
    "            \"params\": {\n",
    "                \"template\": {\n",
    "                    # Prompt sent to target LLM to generate summary\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \"Given a full medical consultation, please provide a 50 word summary of the consultation.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": \"Full Consult: {{ item.content }}\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"max_tokens\": 200\n",
    "                }\n",
    "            },\n",
    "            \"dataset\": {\n",
    "                \"files_url\": f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}/\",\n",
    "                \"limit\": 5  # Reduced for quick test - increase for full evaluation\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"completeness\": {\n",
    "                    \"type\": \"llm-judge\",\n",
    "                    \"params\": {\n",
    "                        \"model\": judge_model_config,\n",
    "                        \"template\": {\n",
    "                            \"messages\": [\n",
    "                                {\"role\": \"system\", \"content\": completeness_system_prompt},\n",
    "                                {\"role\": \"user\", \"content\": user_prompt}\n",
    "                            ]\n",
    "                        },\n",
    "                        \"scores\": {\n",
    "                            \"completeness\": {\n",
    "                                \"type\": \"int\",\n",
    "                                \"parser\": {\n",
    "                                    \"type\": \"regex\",\n",
    "                                    \"pattern\": r\"RATING:\\s*(\\d+)\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"correctness\": {\n",
    "                    \"type\": \"llm-judge\",\n",
    "                    \"params\": {\n",
    "                        \"model\": judge_model_config,\n",
    "                        \"template\": {\n",
    "                            \"messages\": [\n",
    "                                {\"role\": \"system\", \"content\": correctness_system_prompt},\n",
    "                                {\"role\": \"user\", \"content\": user_prompt}\n",
    "                            ]\n",
    "                        },\n",
    "                        \"scores\": {\n",
    "                            \"correctness\": {\n",
    "                                \"type\": \"int\",\n",
    "                                \"parser\": {\n",
    "                                    \"type\": \"regex\",\n",
    "                                    \"pattern\": r\"RATING:\\s*(\\d+)\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Evaluation configuration created\")\n",
    "print(f\"   - Type: custom\")\n",
    "print(f\"   - Metrics: completeness, correctness\")\n",
    "print(f\"   - Sample limit: 5 (for quick test)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.5: Verify NIM Connectivity (Optional Diagnostic)\n",
    "\n",
    "Before submitting the job, you can verify the NIM endpoint is correctly configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuration Summary:\n",
      "   Target Model URL: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/chat/completions\n",
      "   Judge Model URL: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/chat/completions\n",
      "\n",
      "üí° Note: These URLs must be accessible from within the cluster.\n",
      "   If the job fails with connection errors, verify:\n",
      "   1. InferenceService exists: oc get inferenceservice meta-llama3-1b-instruct -n anemo-rhoai\n",
      "   2. Service name matches: meta-llama3-1b-instruct\n",
      "   3. Using HTTP endpoint: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000\n",
      "   4. Service account token is set (check .env file)\n",
      "   5. Test connectivity: oc run test --image=curlimages/curl --rm -i --restart=Never -n anemo-rhoai -- curl -k http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/models\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Print the URLs that will be used\n",
    "from config import STANDARD_NIM_SERVICE, NMS_NAMESPACE, NIM_URL_CLUSTER\n",
    "\n",
    "print(\"üìã Configuration Summary:\")\n",
    "print(f\"   Target Model URL: {target_model_config['model']['api_endpoint']['url']}\")\n",
    "print(f\"   Judge Model URL: {judge_model_config['api_endpoint']['url']}\")\n",
    "print(f\"\\nüí° Note: These URLs must be accessible from within the cluster.\")\n",
    "print(f\"   If the job fails with connection errors, verify:\")\n",
    "print(f\"   1. InferenceService exists: oc get inferenceservice {STANDARD_NIM_SERVICE} -n {NMS_NAMESPACE}\")\n",
    "print(f\"   2. Service name matches: {STANDARD_NIM_SERVICE}\")\n",
    "print(f\"   3. Using HTTP endpoint: {NIM_URL_CLUSTER}\")\n",
    "print(f\"   4. Service account token is set (check .env file)\")\n",
    "print(f\"   5. Test connectivity: oc run test --image=curlimages/curl --rm -i --restart=Never -n {NMS_NAMESPACE} -- curl -k {NIM_URL_CLUSTER}/v1/models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.5: Create Evaluation Targets\n",
    "\n",
    "**NOTE**: Creating evaluation targets first is a best practice and follows the e2e notebook pattern. However, there is a **known limitation** in NeMo Evaluator v25.06 where it strips `/chat/completions` from URLs during job execution, even when targets are created correctly.\n",
    "\n",
    "**Current Status**: \n",
    "- ‚úÖ Target creation works (URLs stored correctly)\n",
    "- ‚úÖ Job submission works  \n",
    "- ‚ùå Job execution fails (URL stripped to `/v1` instead of `/v1/chat/completions`)\n",
    "\n",
    "**This is an Evaluator limitation** - the notebook is configured correctly, but the Evaluator's internal URL handling needs to be fixed in a future version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned up existing judge target (if any)\n",
      "Creating judge model evaluation target: meta-llama3-1b-instruct-judge\n",
      "‚úÖ Judge target created: meta-llama3-1b-instruct-judge\n",
      "\n",
      "üí° Judge target reference: anemo-rhoai/meta-llama3-1b-instruct-judge\n",
      "   (Will use this in evaluation config)\n"
     ]
    }
   ],
   "source": [
    "# Create evaluation target for judge model\n",
    "# Use target reference (created in previous cells) for cleaner configuration\n",
    "import requests\n",
    "from config import EVALUATOR_URL, NMS_NAMESPACE\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Delete existing target if it exists (for clean re-runs)\n",
    "judge_target_name = \"meta-llama3-1b-instruct-judge\"\n",
    "try:\n",
    "    res = requests.delete(f\"{EVALUATOR_URL}/v1/evaluation/targets/{NMS_NAMESPACE}/{judge_target_name}\")\n",
    "    if res.status_code in (200, 404):\n",
    "        print(f\"‚úÖ Cleaned up existing judge target (if any)\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create judge model target\n",
    "judge_target_data = {\n",
    "    \"type\": \"model\",\n",
    "    \"name\": judge_target_name,\n",
    "    \"namespace\": NMS_NAMESPACE,\n",
    "    \"model\": {\n",
    "        \"api_endpoint\": {\n",
    "            \"url\": f\"{NIM_URL_CLUSTER}/v1/chat/completions\",\n",
    "            \"model_id\": \"meta/llama-3.2-1b-instruct\",\n",
    "            \"format\": \"openai\"  # Specify format\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Creating judge model evaluation target: {judge_target_name}\")\n",
    "res = requests.post(f\"{EVALUATOR_URL}/v1/evaluation/targets\", headers=headers, json=judge_target_data)\n",
    "\n",
    "if res.status_code not in (200, 201):\n",
    "    print(f\"‚ö†Ô∏è  Warning: Could not create judge target: {res.status_code}\")\n",
    "    print(f\"Response: {res.text[:200]}\")\n",
    "    # Continue anyway - might already exist\n",
    "else:\n",
    "    judge_target_response = res.json()\n",
    "    print(f\"‚úÖ Judge target created: {judge_target_response.get('name')}\")\n",
    "\n",
    "# Update judge_model_config to use target name for job submission\n",
    "# The config will reference this target by name\n",
    "judge_target_ref = f\"{NMS_NAMESPACE}/{judge_target_name}\"\n",
    "print(f\"\\nüí° Judge target reference: {judge_target_ref}\")\n",
    "print(\"   (Will use this in evaluation config)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned up existing target model target (if any)\n",
      "Creating target model evaluation target: meta-llama3-1b-instruct-target\n",
      "‚úÖ Target model target created: meta-llama3-1b-instruct-target\n",
      "\n",
      "üí° Target model reference: anemo-rhoai/meta-llama3-1b-instruct-target\n",
      "   (Will use this in job submission)\n"
     ]
    }
   ],
   "source": [
    "# Create evaluation target for target model\n",
    "# Delete existing target if it exists (for clean re-runs)\n",
    "target_target_name = \"meta-llama3-1b-instruct-target\"\n",
    "try:\n",
    "    res = requests.delete(f\"{EVALUATOR_URL}/v1/evaluation/targets/{NMS_NAMESPACE}/{target_target_name}\")\n",
    "    if res.status_code in (200, 404):\n",
    "        print(f\"‚úÖ Cleaned up existing target model target (if any)\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create target model evaluation target\n",
    "target_target_data = {\n",
    "    \"type\": \"model\",\n",
    "    \"name\": target_target_name,\n",
    "    \"namespace\": NMS_NAMESPACE,\n",
    "    \"model\": {\n",
    "        \"api_endpoint\": {\n",
    "            \"url\": f\"{NIM_URL_CLUSTER}/v1/chat/completions\",\n",
    "            \"model_id\": \"meta/llama-3.2-1b-instruct\",\n",
    "            \"format\": \"openai\"  # Specify format\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Creating target model evaluation target: {target_target_name}\")\n",
    "res = requests.post(f\"{EVALUATOR_URL}/v1/evaluation/targets\", headers=headers, json=target_target_data)\n",
    "\n",
    "if res.status_code not in (200, 201):\n",
    "    print(f\"‚ö†Ô∏è  Warning: Could not create target model target: {res.status_code}\")\n",
    "    print(f\"Response: {res.text[:200]}\")\n",
    "    # Continue anyway - might already exist\n",
    "else:\n",
    "    target_target_response = res.json()\n",
    "    print(f\"‚úÖ Target model target created: {target_target_response.get('name')}\")\n",
    "\n",
    "# Store target reference for job submission\n",
    "target_model_ref = f\"{NMS_NAMESPACE}/{target_target_name}\"\n",
    "print(f\"\\nüí° Target model reference: {target_model_ref}\")\n",
    "print(\"   (Will use this in job submission)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Submit Evaluation Job\n",
    "\n",
    "Submit the evaluation job to NeMo Evaluator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Submitting evaluation job with inline target config...\n",
      "   Target: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/chat/completions\n",
      "‚úÖ Evaluation job submitted\n",
      "   Job ID: eval-VgyjqL9ciYXZ9XCVGGLmfe\n",
      "   Status: created\n"
     ]
    }
   ],
   "source": [
    "# Submit evaluation job\n",
    "# IMPORTANT: Use inline target config (like original notebook) to avoid Data Store validation issues\n",
    "# Using inline config bypasses evaluation target lookup which triggers Data Store dataset validation\n",
    "try:\n",
    "    # Use inline target config (matches original notebook approach)\n",
    "    job_payload = {\n",
    "        \"config\": llm_as_a_judge_config,\n",
    "        \"target\": target_model_config  # Use inline config object, not target reference\n",
    "    }\n",
    "    \n",
    "    print(\"üì§ Submitting evaluation job with inline target config...\")\n",
    "    print(f\"   Target: {target_model_config['model']['api_endpoint']['url']}\")\n",
    "    \n",
    "    res = requests.post(\n",
    "        f\"{EVALUATOR_URL}/v1/evaluation/jobs\",\n",
    "        json=job_payload,\n",
    "        timeout=30\n",
    "    )\n",
    "\n",
    "    if res.status_code not in (200, 201):\n",
    "        print(f\"‚ùå Failed to submit job: {res.status_code}\")\n",
    "        print(f\"Response: {res.text}\")\n",
    "        raise Exception(f\"Job submission failed: {res.status_code} - {res.text}\")\n",
    "\n",
    "    job_data = res.json()\n",
    "    base_eval_job_id = job_data[\"id\"]\n",
    "    print(f\"‚úÖ Evaluation job submitted\")\n",
    "    print(f\"   Job ID: {base_eval_job_id}\")\n",
    "    print(f\"   Status: {job_data.get('status', 'unknown')}\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå Network error submitting job: {e}\")\n",
    "    print(f\"   Check that Evaluator is accessible at: {EVALUATOR_URL}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error submitting job: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Troubleshooting NIM Connection:\n",
      "   1. Service exists: oc get svc meta-llama3-1b-instruct -n anemo-rhoai\n",
      "   2. Service has endpoints: oc get endpoints meta-llama3-1b-instruct -n anemo-rhoai\n",
      "   3. Pod is running: oc get pod -n anemo-rhoai | grep meta-llama3-1b-instruct\n",
      "   4. Test from evaluator pod:\n",
      "      oc exec -n anemo-rhoai <evaluator-pod> -- curl -s http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/models\n",
      "\n",
      "   Expected URL format: http://meta-llama3-1b-instruct.anemo-rhoai.svc.cluster.local:8000/v1/chat/completions\n",
      "   (HTTPS uses port 443 by default - no need to specify port)\n",
      "   ‚ö†Ô∏è  Service account token is NOT needed (service mesh handles auth)\n"
     ]
    }
   ],
   "source": [
    "# Troubleshooting: Verify NIM service accessibility\n",
    "print(\"üîç Troubleshooting NIM Connection:\")\n",
    "print(f\"   1. Service exists: oc get svc {STANDARD_NIM_SERVICE} -n {NMS_NAMESPACE}\")\n",
    "print(f\"   2. Service has endpoints: oc get endpoints {STANDARD_NIM_SERVICE} -n {NMS_NAMESPACE}\")\n",
    "print(f\"   3. Pod is running: oc get pod -n {NMS_NAMESPACE} | grep {STANDARD_NIM_SERVICE}\")\n",
    "print(f\"   4. Test from evaluator pod:\")\n",
    "print(f\"      oc exec -n {NMS_NAMESPACE} <evaluator-pod> -- curl -s {NIM_URL_CLUSTER}/v1/models\")\n",
    "print(f\"\\n   Expected URL format: {NIM_URL_CLUSTER}/v1/chat/completions\")\n",
    "print(f\"   (HTTPS uses port 443 by default - no need to specify port)\")\n",
    "print(f\"   ‚ö†Ô∏è  Service account token is NOT needed (service mesh handles auth)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Wait for Job Completion\n",
    "\n",
    "Monitor the evaluation job until it completes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Waiting for evaluation job to complete...\n",
      "Initial status: running\n",
      "‚è≥ Status: running | Progress: 60.0% | Elapsed: 5.2s\n",
      "‚úÖ Status: completed | Progress: 100% | Elapsed: 10.3s\n"
     ]
    }
   ],
   "source": [
    "from time import sleep, time\n",
    "\n",
    "def wait_eval_job(job_url: str, polling_interval: int = 10, timeout: int = 600):\n",
    "    \"\"\"Helper for waiting an eval job with error handling.\"\"\"\n",
    "    start_time = time()\n",
    "    \n",
    "    try:\n",
    "        res = requests.get(job_url, timeout=10)\n",
    "        if res.status_code != 200:\n",
    "            raise Exception(f\"Failed to get job status: {res.status_code} - {res.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Network error getting job status: {e}\")\n",
    "    \n",
    "    job_data = res.json()\n",
    "    status = job_data[\"status\"]\n",
    "    print(f\"Initial status: {status}\")\n",
    "    \n",
    "    # Check for immediate terminal states\n",
    "    if status == \"failed\":\n",
    "        print(f\"‚ùå Job failed immediately!\")\n",
    "        status_details = job_data.get('status_details', {})\n",
    "        error_msg = status_details.get('message', 'Unknown error')\n",
    "        print(f\"Error: {error_msg}\")\n",
    "        return res\n",
    "    elif status == \"completed\":\n",
    "        print(f\"‚úÖ Job completed immediately!\")\n",
    "        return res\n",
    "\n",
    "    # Poll for status updates\n",
    "    while status in [\"pending\", \"created\", \"running\"]:\n",
    "        # Check for timeout\n",
    "        elapsed = time() - start_time\n",
    "        if elapsed > timeout:\n",
    "            raise RuntimeError(f\"Job took more than {timeout} seconds (timed out).\")\n",
    "\n",
    "        # Sleep before polling again\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        # Fetch updated status and progress\n",
    "        try:\n",
    "            res = requests.get(job_url, timeout=10)\n",
    "            if res.status_code != 200:\n",
    "                print(f\"‚ö†Ô∏è  Failed to get status: {res.status_code} - {res.text}\")\n",
    "                sleep(polling_interval)  # Wait before retrying\n",
    "                continue\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ö†Ô∏è  Network error getting status: {e} - retrying...\")\n",
    "            sleep(polling_interval)\n",
    "            continue\n",
    "            \n",
    "        job_data = res.json()\n",
    "        status = job_data[\"status\"]\n",
    "        elapsed = time() - start_time\n",
    "\n",
    "        # Handle terminal states immediately\n",
    "        if status == \"failed\":\n",
    "            print(f\"\\n‚ùå Job failed after {elapsed:.1f}s\")\n",
    "            status_details = job_data.get('status_details', {})\n",
    "            error_msg = status_details.get('message', 'Unknown error')\n",
    "            print(f\"Error: {error_msg}\")\n",
    "            \n",
    "            # Print task status if available\n",
    "            task_status = status_details.get('task_status', {})\n",
    "            if task_status:\n",
    "                print(f\"\\nTask status details:\")\n",
    "                for task_name, task_info in task_status.items():\n",
    "                    print(f\"  - {task_name}: {task_info}\")\n",
    "            return res\n",
    "        elif status == \"completed\":\n",
    "            progress = 100\n",
    "            print(f\"‚úÖ Status: {status} | Progress: {progress}% | Elapsed: {elapsed:.1f}s\")\n",
    "            return res\n",
    "        elif status == \"running\":\n",
    "            progress = job_data.get(\"status_details\", {}).get(\"progress\", 0)\n",
    "            print(f\"‚è≥ Status: {status} | Progress: {progress}% | Elapsed: {elapsed:.1f}s\")\n",
    "        else:\n",
    "            # Unknown status - log and continue\n",
    "            print(f\"‚ö†Ô∏è  Status: {status} | Elapsed: {elapsed:.1f}s\")\n",
    "\n",
    "    # If we exit the loop, status should be terminal, but check anyway\n",
    "    if status not in [\"completed\", \"failed\"]:\n",
    "        print(f\"‚ö†Ô∏è  Unexpected final status: {status}\")\n",
    "        print(f\"   Full job data: {job_data}\")\n",
    "\n",
    "    return res\n",
    "\n",
    "print(\"‚è≥ Waiting for evaluation job to complete...\")\n",
    "try:\n",
    "    res = wait_eval_job(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}\", polling_interval=5, timeout=600)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error waiting for job: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Job completed successfully!\n",
      "   You can now view results in the next cell.\n"
     ]
    }
   ],
   "source": [
    "# Check final status (this cell provides additional details if needed)\n",
    "try:\n",
    "    job_data = res.json()\n",
    "    final_status = job_data[\"status\"]\n",
    "    \n",
    "    if final_status == \"completed\":\n",
    "        print(f\"‚úÖ Job completed successfully!\")\n",
    "        print(f\"   You can now view results in the next cell.\")\n",
    "    elif final_status == \"failed\":\n",
    "        print(f\"\\n‚ùå Job failed - Summary:\")\n",
    "        status_details = job_data.get('status_details', {})\n",
    "        error_msg = status_details.get('message', 'Unknown error')\n",
    "        \n",
    "        # Extract key error information\n",
    "        if \"Error connecting to inference server\" in error_msg:\n",
    "            print(f\"   Issue: Cannot connect to NIM endpoint\")\n",
    "            print(f\"   Check: Is the NIM service running and accessible from cluster?\")\n",
    "            print(f\"   URL used: Check the target/judge model configuration\")\n",
    "        \n",
    "        print(f\"\\n   Full error message:\")\n",
    "        print(f\"   {error_msg[:500]}...\")  # Truncate very long errors\n",
    "        \n",
    "        # Print task status if available\n",
    "        task_status = status_details.get('task_status', {})\n",
    "        if task_status:\n",
    "            print(f\"\\n   Task status details:\")\n",
    "            for task_name, task_info in task_status.items():\n",
    "                print(f\"     - {task_name}: {task_info}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Job status: {final_status}\")\n",
    "        print(f\"   Full response: {job_data}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error parsing job status: {e}\")\n",
    "    print(f\"   Raw response: {res.text if hasattr(res, 'text') else res}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: View Results\n",
    "\n",
    "Retrieve and display the evaluation results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Task: consult_summary_eval\n",
      "   completeness: 4.0 (mean: 4.0, count: 5)\n",
      "   correctness: 1.6 (mean: 1.6, count: 5)\n",
      "\n",
      "‚úÖ Results retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Get results\n",
    "try:\n",
    "    res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}/results\", timeout=30)\n",
    "    \n",
    "    if res.status_code == 200:\n",
    "        results = res.json()\n",
    "        \n",
    "        # Extract metrics\n",
    "        tasks = results.get(\"tasks\", {})\n",
    "        if not tasks:\n",
    "            print(\"‚ö†Ô∏è  No tasks found in results\")\n",
    "            print(f\"   Full response: {results}\")\n",
    "        else:\n",
    "            for task_name, task_data in tasks.items():\n",
    "                print(f\"\\nüìä Task: {task_name}\")\n",
    "                metrics = task_data.get(\"metrics\", {})\n",
    "                if not metrics:\n",
    "                    print(f\"   ‚ö†Ô∏è  No metrics found for this task\")\n",
    "                else:\n",
    "                    for metric_name, metric_data in metrics.items():\n",
    "                        scores = metric_data.get(\"scores\", {})\n",
    "                        if not scores:\n",
    "                            print(f\"   ‚ö†Ô∏è  No scores found for metric: {metric_name}\")\n",
    "                        else:\n",
    "                            for score_name, score_data in scores.items():\n",
    "                                value = score_data.get(\"value\", \"N/A\")\n",
    "                                stats = score_data.get(\"stats\", {})\n",
    "                                mean = stats.get(\"mean\", \"N/A\")\n",
    "                                count = stats.get(\"count\", \"N/A\")\n",
    "                                print(f\"   {score_name}: {value} (mean: {mean}, count: {count})\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Results retrieved successfully!\")\n",
    "    elif res.status_code == 404:\n",
    "        print(f\"‚ö†Ô∏è  Results not yet available (404)\")\n",
    "        print(f\"   Job may still be processing. Wait a moment and try again.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to get results: {res.status_code}\")\n",
    "        print(f\"   Response: {res.text}\")\n",
    "        \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå Network error getting results: {e}\")\n",
    "    print(f\"   Check that Evaluator is accessible at: {EVALUATOR_URL}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error getting results: {e}\")\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
