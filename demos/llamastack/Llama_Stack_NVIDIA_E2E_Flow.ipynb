{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning, Inference, and Evaluation with NVIDIA NeMo Microservices and NIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the following workflows:\n",
    "- Creating a dataset and uploading files for customizing and evaluating models\n",
    "- Running inference on base and customized models\n",
    "- Customizing and evaluating models, comparing metrics between base models and fine-tuned models\n",
    "- Running a safety check and evaluating a model using Guardrails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy NeMo Microservices\n",
    "Ensure the NeMo Microservices platform is up and running, including the model downloading step for `meta/llama-3.1-8b-instruct`. Please refer to the [installation guide](https://aire.gitlab-master-pages.nvidia.com/microservices/documentation/latest/nemo-microservices/latest-internal/set-up/deploy-as-platform/index.html) for instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify the `meta/llama-3.1-8b-instruct` is deployed by querying the NIM endpoint. The response should include a model with an `id` of `meta/llama-3.1-8b-instruct`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# URL to NeMo deployment management service\n",
    "export NEMO_URL=\"http://nemo.test\"\n",
    "\n",
    "curl -X GET \"$NEMO_URL/v1/models\" \\\n",
    "  -H \"Accept: application/json\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Developer Environment\n",
    "Set up your development environment on your machine. The project uses `uv` to manage Python dependencies. From the root of the project, install dependencies and create your virtual environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "uv sync --extra dev\n",
    "uv pip install -U llama-stack-client\n",
    "uv pip install -e .\n",
    "source .venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Llama Stack Image\n",
    "Build the Llama Stack image using the virtual environment you just created. For local development, set `LLAMA_STACK_DIR` to ensure your local code is use in the image. To use the production version of `llama-stack`, omit `LLAMA_STACK_DIR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "uv run --with llama-stack llama stack list-deps nvidia | xargs -L1 uv pip install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Update the following variables in [config.py](./config.py) with your deployment URLs and API keys. The other variables are optional. You can update these to organize the resources created by this notebook.\n",
    "```python\n",
    "# (Required) NeMo Microservices URLs\n",
    "NDS_URL = \"\" # NeMo Data Store\n",
    "NEMO_URL = \"\" # Other NeMo Microservices (Customizer, Evaluator, Guardrails)\n",
    "NIM_URL = \"\" # NIM\n",
    "\n",
    "# (Required) Hugging Face Token\n",
    "HF_TOKEN = \"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set environment variables used by each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import *\n",
    "\n",
    "# Metadata associated with Datasets and Customization Jobs\n",
    "os.environ[\"NVIDIA_DATASET_NAMESPACE\"] = NAMESPACE\n",
    "os.environ[\"NVIDIA_PROJECT_ID\"] = PROJECT_ID\n",
    "\n",
    "# Inference env vars\n",
    "os.environ[\"NVIDIA_BASE_URL\"] = NIM_URL\n",
    "\n",
    "# Data Store env vars\n",
    "os.environ[\"NVIDIA_DATASETS_URL\"] = NEMO_URL\n",
    "\n",
    "# Customizer env vars\n",
    "os.environ[\"NVIDIA_CUSTOMIZER_URL\"] = NEMO_URL\n",
    "os.environ[\"NVIDIA_OUTPUT_MODEL_DIR\"] = CUSTOMIZED_MODEL_DIR\n",
    "\n",
    "# Evaluator env vars\n",
    "os.environ[\"NVIDIA_EVALUATOR_URL\"] = NEMO_URL\n",
    "\n",
    "# Guardrails env vars\n",
    "os.environ[\"GUARDRAILS_SERVICE_URL\"] = NEMO_URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Initialize the HuggingFace API client. Here, we use NeMo Data Store as the endpoint the client will invoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hacohen/Desktop/repos/install-NeMo-on-OpenShift/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import json\n",
    "import pprint\n",
    "import requests\n",
    "from time import sleep, time\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = f\"{NDS_URL}/v1/hf\"\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "hf_api = HfApi(endpoint=os.environ.get(\"HF_ENDPOINT\"), token=os.environ.get(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize the Llama Stack client using the NVIDIA provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0-alpha.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "client = LlamaStackClient(base_url=LLAMASTACK_URL)\n",
    "client._version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base model registered in Entity Store\n"
     ]
    }
   ],
   "source": [
    "# Register base model in Entity Store (required for evaluator and customizer)\n",
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{ENTITY_STORE_URL}/v1/models\",\n",
    "    json={\n",
    "        \"name\": \"llama-3.2-1b-instruct\",\n",
    "        \"namespace\": \"meta\",\n",
    "        \"description\": \"Base Llama 3.2 1B Instruct model\",\n",
    "        \"project\": \"tool_calling\",\n",
    "        \"spec\": {\n",
    "            \"num_parameters\": 1000000000,\n",
    "            \"context_size\": 4096,\n",
    "            \"num_virtual_tokens\": 0,\n",
    "            \"is_chat\": True\n",
    "        },\n",
    "        \"artifact\": {\n",
    "            \"gpu_arch\": \"Ampere\",\n",
    "            \"precision\": \"bf16-mixed\",\n",
    "            \"tensor_parallelism\": 1,\n",
    "            \"backend_engine\": \"nemo\",\n",
    "            \"status\": \"upload_completed\",\n",
    "            \"files_url\": \"nim://meta/llama-3.2-1b-instruct\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "if response.status_code in (200, 201):\n",
    "    print(\"✅ Base model registered in Entity Store\")\n",
    "elif response.status_code == 409:\n",
    "    print(\"⚠️ Base model already exists in Entity Store\")\n",
    "else:\n",
    "    print(f\"❌ Failed to register: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define a few helper functions we'll use later that wait for async jobs to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack.apis.common.job_types import JobStatus\n",
    "\n",
    "def wait_customization_job(job_id: str, polling_interval: int = 30, timeout: int = 3600):\n",
    "    start_time = time()\n",
    "\n",
    "    response = client.alpha.post_training.job.status(job_uuid=job_id)\n",
    "    job_status = response.status\n",
    "\n",
    "    print(f\"Waiting for Customization job {job_id} to finish.\")\n",
    "    print(f\"Job status: {job_status} after {time() - start_time} seconds.\")\n",
    "\n",
    "    while job_status in [JobStatus.scheduled.value, JobStatus.in_progress.value]:\n",
    "        sleep(polling_interval)\n",
    "        response = client.alpha.post_training.job.status(job_uuid=job_id)\n",
    "        job_status = response.status\n",
    "\n",
    "        print(f\"Job status: {job_status} after {time() - start_time} seconds.\")\n",
    "\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Customization Job {job_id} took more than {timeout} seconds.\")\n",
    "        \n",
    "    return job_status\n",
    "\n",
    "def wait_eval_job(benchmark_id: str, job_id: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    start_time = time()\n",
    "    job_status = client.alpha.eval.jobs.status(benchmark_id=benchmark_id, job_id=job_id)\n",
    "\n",
    "    print(f\"Waiting for Evaluation job {job_id} to finish.\")\n",
    "    print(f\"Job status: {job_status} after {time() - start_time} seconds.\")\n",
    "\n",
    "    while job_status.status in [JobStatus.scheduled.value, JobStatus.in_progress.value]:\n",
    "        sleep(polling_interval)\n",
    "        job_status = client.alpha.eval.jobs.status(benchmark_id=benchmark_id, job_id=job_id)\n",
    "\n",
    "        print(f\"Job status: {job_status} after {time() - start_time} seconds.\")\n",
    "\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Evaluation Job {job_id} took more than {timeout} seconds.\")\n",
    "\n",
    "    return job_status\n",
    "\n",
    "# When creating a customized model, NIM asynchronously loads the model in its model registry.\n",
    "# After this, we can run inference on the new model. This helper function waits for NIM to pick up the new model.\n",
    "def wait_nim_loads_customized_model(model_id: str, polling_interval: int = 10, timeout: int = 300):\n",
    "    found = False\n",
    "    start_time = time()\n",
    "\n",
    "    print(f\"Checking if NIM has loaded customized model {model_id}.\")\n",
    "\n",
    "    while not found:\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        response = requests.get(f\"{NIM_URL}/v1/models\")\n",
    "        if model_id in [model[\"id\"] for model in response.json()[\"data\"]]:\n",
    "            found = True\n",
    "            print(f\"Model {model_id} available after {time() - start_time} seconds.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Model {model_id} not available after {time() - start_time} seconds.\")\n",
    "\n",
    "    if not found:\n",
    "        raise RuntimeError(f\"Model {model_id} not available after {timeout} seconds.\")\n",
    "\n",
    "    assert found, f\"Could not find model {model_id} in the list of available models.\"\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Dataset Using the HuggingFace Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating a dataset with the `sample_squad_data` files. This data is pulled from the Stanford Question Answering Dataset (SQuAD) reading comprehension dataset, consisting of questions posed on a set of Wikipedia articles, where the answer to every question is a segment of text from the corresponding passage, or the question is unanswerable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_squad_dataset_name = \"sample-squad-test\"\n",
    "repo_id = f\"{NAMESPACE}/{sample_squad_dataset_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the repo\n",
    "response = hf_api.create_repo(repo_id, repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.jsonl: 100%|██████████| 1.18M/1.18M [00:04<00:00, 260kB/s]\n",
      "validation.jsonl: 100%|██████████| 171k/171k [00:00<00:00, 223kB/s]\n",
      "testing.jsonl: 100%|██████████| 345k/345k [00:01<00:00, 250kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='', commit_message='Upload folder using huggingface_hub', commit_description='', oid='2b91468badc4f3708f0173be4a65f1c245656a83', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the files from the local folder\n",
    "hf_api.upload_folder(\n",
    "    folder_path=\"./sample_data/sample_squad_data/training\",\n",
    "    path_in_repo=\"training\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "hf_api.upload_folder(\n",
    "    folder_path=\"./sample_data/sample_squad_data/validation\",\n",
    "    path_in_repo=\"validation\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "hf_api.upload_folder(\n",
    "    folder_path=\"./sample_data/sample_squad_data/testing\",\n",
    "    path_in_repo=\"testing\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/ipykernel_54678/1884562134.py:2: DeprecationWarning: deprecated\n",
      "  response = client.beta.datasets.register(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1beta/datasets \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetRegisterResponse(identifier='sample-squad-test', provider_id='nvidia', purpose='post-training/messages', source=SourceUriDataSource(uri='hf://datasets/nvidia-e2e-tutorial/sample-squad-test', type='uri'), metadata={'format': 'json', 'description': 'Test sample_squad_data dataset for NVIDIA E2E notebook', 'provider_id': 'nvidia'}, provider_resource_id='sample-squad-test', type='dataset', owner=None)\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "response = client.beta.datasets.register(\n",
    "    purpose=\"post-training/messages\",\n",
    "    dataset_id=sample_squad_dataset_name,\n",
    "    source={\n",
    "        \"type\": \"uri\",\n",
    "        \"uri\": f\"hf://datasets/{repo_id}\"\n",
    "    },\n",
    "    metadata={\n",
    "        \"format\": \"json\",\n",
    "        \"description\": \"Test sample_squad_data dataset for NVIDIA E2E notebook\",\n",
    "        \"provider_id\": \"nvidia\",\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Dataset already exists in Entity Store - continuing...\n"
     ]
    }
   ],
   "source": [
    "# Register dataset in Entity Store (required for customizer/evaluator)\n",
    "import requests\n",
    "response = requests.post(\n",
    "    f\"{ENTITY_STORE_URL}/v1/datasets\",\n",
    "    json={\n",
    "        \"name\": sample_squad_dataset_name,\n",
    "        \"namespace\": NAMESPACE,\n",
    "        \"description\": \"Test sample_squad_data dataset for NVIDIA E2E notebook\",\n",
    "        \"files_url\": f\"hf://datasets/{repo_id}\",\n",
    "        \"project\": \"tool_calling\",\n",
    "        \"format\": \"json\",\n",
    "    },\n",
    ")\n",
    "\n",
    "if response.status_code in (200, 201):\n",
    "    print(\"✅ Dataset registered in Entity Store\")\n",
    "    dataset_obj = response.json()\n",
    "    print(f\"Files URL: {dataset_obj['files_url']}\")\n",
    "    assert dataset_obj[\"files_url\"] == f\"hf://datasets/{repo_id}\"\n",
    "elif response.status_code == 409:\n",
    "    print(\"⚠️ Dataset already exists in Entity Store - continuing...\")\n",
    "else:\n",
    "    print(f\"❌ Failed to register: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use an entry from the `sample_squad_data` test data to verify we can run inference using NVIDIA NIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Extract from the following context the minimal span word for word that best '\n",
      " 'answers the question.\\n'\n",
      " '- If a question does not make any sense, or is not factually coherent, '\n",
      " 'explain why instead of answering something not correct.\\n'\n",
      " \"- If you don't know the answer to a question, please don't share false \"\n",
      " 'information.\\n'\n",
      " '- If the answer is not in the context, the answer should be \"?\".\\n'\n",
      " '- Your answer should not include any other text than the answer to the '\n",
      " 'question. Don\\'t include any other text like \"Here is the answer to the '\n",
      " 'question:\" or \"The minimal span word for word that best answers the question '\n",
      " 'is:\" or anything like that.\\n'\n",
      " '\\n'\n",
      " 'Context: The league announced on October 16, 2012, that the two finalists '\n",
      " \"were Sun Life Stadium and Levi's Stadium. The South Florida/Miami area has \"\n",
      " 'previously hosted the event 10 times (tied for most with New Orleans), with '\n",
      " 'the most recent one being Super Bowl XLIV in 2010. The San Francisco Bay '\n",
      " 'Area last hosted in 1985 (Super Bowl XIX), held at Stanford Stadium in '\n",
      " 'Stanford, California, won by the home team 49ers. The Miami bid depended on '\n",
      " 'whether the stadium underwent renovations. However, on May 3, 2013, the '\n",
      " 'Florida legislature refused to approve the funding plan to pay for the '\n",
      " \"renovations, dealing a significant blow to Miami's chances.\\n\"\n",
      " 'Question: In what year was the Super Bowl last held in the Miami/South '\n",
      " 'Florida area? Answer:')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "with open(\"./sample_data/sample_squad_data/testing/testing.jsonl\", \"r\") as f:\n",
    "    examples = [json.loads(line) for line in f]\n",
    "\n",
    "# Get the user prompt from the last example\n",
    "sample_prompt = examples[-1][\"prompt\"]\n",
    "pprint.pprint(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/ipykernel_54678/3103298560.py:5: DeprecationWarning: deprecated\n",
      "  client.models.register(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/models \"HTTP/1.1 400 Bad Request\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error registering model: Error code: 400 - {'detail': 'Invalid value: Model meta/llama-3.2-1b-instruct is not available from provider nvidia'}\n"
     ]
    }
   ],
   "source": [
    "# Register the base model with LlamaStack\n",
    "from llama_stack.apis.models.models import ModelType\n",
    "\n",
    "try:\n",
    "    client.models.register(\n",
    "        model_id=BASE_MODEL,\n",
    "        model_type=ModelType.llm,\n",
    "        provider_id=\"nvidia\",\n",
    "    )\n",
    "    print(f\"✅ Registered model: {BASE_MODEL}\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\"⚠️ Model {BASE_MODEL} already registered\")\n",
    "    else:\n",
    "        print(f\"Error registering model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference response: 1985\n"
     ]
    }
   ],
   "source": [
    "# Test inference\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": sample_prompt}\n",
    "    ],\n",
    "    model=f\"nvidia/{BASE_MODEL}\",\n",
    "    max_tokens=20,\n",
    "    temperature=0.7,\n",
    ")\n",
    "print(f\"Inference response: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run an Evaluation, we'll first register a benchmark. A benchmark corresponds to an Evaluation Config in NeMo Evaluator, which contains the metadata to use when launching an Evaluation Job. Here, we'll create a benchmark that uses the testing file uploaded in the previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_id = \"test-eval-config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_eval_config = {\n",
    "    \"benchmark_id\": benchmark_id,\n",
    "    \"dataset_id\": \"\",\n",
    "    \"scoring_functions\": [],\n",
    "    \"metadata\": {\n",
    "        \"type\": \"custom\",\n",
    "        \"params\": {\"parallelism\": 8},\n",
    "        \"tasks\": {\n",
    "            \"qa\": {\n",
    "                \"type\": \"completion\",\n",
    "                \"params\": {\n",
    "                    \"template\": {\n",
    "                        \"prompt\": \"{{prompt}}\",\n",
    "                        \"max_tokens\": 20,\n",
    "                        \"temperature\": 0.7,\n",
    "                        \"top_p\": 0.9,\n",
    "                    },\n",
    "                },\n",
    "                \"dataset\": {\"files_url\": f\"hf://datasets/{repo_id}/testing/testing.jsonl\"},\n",
    "                \"metrics\": {\n",
    "                    \"bleu\": {\n",
    "                        \"type\": \"bleu\",\n",
    "                        \"params\": {\"references\": [\"{{ideal_response}}\"]},\n",
    "                    },\n",
    "                    \"string-check\": {\n",
    "                        \"type\": \"string-check\",\n",
    "                        \"params\": {\"check\": [\"{{ideal_response | trim}}\", \"equals\", \"{{output_text | trim}}\"]},\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/ipykernel_54678/1973298325.py:2: DeprecationWarning: deprecated\n",
      "  response = client.alpha.benchmarks.register(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/eval/benchmarks \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created benchmark test-eval-config\n"
     ]
    }
   ],
   "source": [
    "# Register a benchmark, which creates an Evaluation Config\n",
    "response = client.alpha.benchmarks.register(\n",
    "    benchmark_id=benchmark_id,\n",
    "    dataset_id=repo_id,\n",
    "    scoring_functions=simple_eval_config[\"scoring_functions\"],\n",
    "    metadata=simple_eval_config[\"metadata\"]\n",
    ")\n",
    "print(f\"Created benchmark {benchmark_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created evaluation job eval-Wgr4rnBbS9A8R2ps5E4yCi\n"
     ]
    }
   ],
   "source": [
    "# Launch a simple evaluation with the benchmark\n",
    "response = client.alpha.eval.run_eval(\n",
    "    benchmark_id=benchmark_id,\n",
    "    benchmark_config={\n",
    "        \"eval_candidate\": {\n",
    "            \"type\": \"model\",\n",
    "            \"model\": BASE_MODEL,\n",
    "            \"sampling_params\": {}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "job_id = response.model_dump()[\"job_id\"]\n",
    "print(f\"Created evaluation job {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs/eval-Wgr4rnBbS9A8R2ps5E4yCi \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Evaluation job eval-Wgr4rnBbS9A8R2ps5E4yCi to finish.\n",
      "Job status: Job(job_id='eval-Wgr4rnBbS9A8R2ps5E4yCi', status='in_progress') after 0.2252950668334961 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs/eval-Wgr4rnBbS9A8R2ps5E4yCi \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Job(job_id='eval-Wgr4rnBbS9A8R2ps5E4yCi', status='in_progress') after 5.720567226409912 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs/eval-Wgr4rnBbS9A8R2ps5E4yCi \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Job(job_id='eval-Wgr4rnBbS9A8R2ps5E4yCi', status='completed') after 11.216270923614502 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Wait for the job to complete\n",
    "job = wait_eval_job(benchmark_id=benchmark_id, job_id=job_id, polling_interval=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job eval-Wgr4rnBbS9A8R2ps5E4yCi status: completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job {job_id} status: {job.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs/eval-Wgr4rnBbS9A8R2ps5E4yCi/result \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job results: {\n",
      "  \"generations\": [],\n",
      "  \"scores\": {\n",
      "    \"test-eval-config\": {\n",
      "      \"aggregated_results\": {\n",
      "        \"created_at\": \"2025-11-20T13:35:35.355164\",\n",
      "        \"updated_at\": \"2025-11-20T13:35:35.355165\",\n",
      "        \"id\": \"evaluation_result-37ZwsBfu6sZRRjBfq6Z9PE\",\n",
      "        \"job\": \"eval-Wgr4rnBbS9A8R2ps5E4yCi\",\n",
      "        \"tasks\": {\n",
      "          \"qa\": {\n",
      "            \"metrics\": {\n",
      "              \"bleu\": {\n",
      "                \"scores\": {\n",
      "                  \"sentence\": {\n",
      "                    \"value\": 9.095718887216758,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 200,\n",
      "                      \"sum\": 1819.1437774433518,\n",
      "                      \"mean\": 9.095718887216758\n",
      "                    }\n",
      "                  },\n",
      "                  \"corpus\": {\n",
      "                    \"value\": 4.227454564913527\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"string-check\": {\n",
      "                \"scores\": {\n",
      "                  \"string-check\": {\n",
      "                    \"value\": 0.005,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 200,\n",
      "                      \"sum\": 1.0,\n",
      "                      \"mean\": 0.005\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"groups\": {},\n",
      "        \"namespace\": \"default\",\n",
      "        \"custom_fields\": {}\n",
      "      },\n",
      "      \"score_rows\": []\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_results = client.alpha.eval.jobs.retrieve(benchmark_id=benchmark_id, job_id=job_id)\n",
    "print(f\"Job results: {json.dumps(job_results.model_dump(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial bleu score: 4.227454564913527\n"
     ]
    }
   ],
   "source": [
    "# Extract bleu score and assert it's within range\n",
    "initial_bleu_score = job_results.scores[benchmark_id].aggregated_results[\"tasks\"][\"qa\"][\"metrics\"][\"bleu\"][\"scores\"][\"corpus\"][\"value\"]\n",
    "print(f\"Initial bleu score: {initial_bleu_score}\")\n",
    "\n",
    "assert initial_bleu_score >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy: 0.005\n"
     ]
    }
   ],
   "source": [
    "# Extract accuracy and assert it's within range\n",
    "initial_accuracy_score = job_results.scores[benchmark_id].aggregated_results[\"tasks\"][\"qa\"][\"metrics\"][\"string-check\"][\"scores\"][\"string-check\"][\"value\"]\n",
    "print(f\"Initial accuracy: {initial_accuracy_score}\")\n",
    "\n",
    "assert initial_accuracy_score >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've established our baseline Evaluation metrics, we'll customize a model using our training data uploaded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/post-training/supervised-fine-tune \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job with ID: cust-KizmczUEpGiA37zAdAdfrZ\n"
     ]
    }
   ],
   "source": [
    "# Start the customization job\n",
    "response = client.alpha.post_training.supervised_fine_tune(\n",
    "    job_uuid=\"\",\n",
    "    model=f\"{BASE_MODEL}@v1.0.0+A100\",\n",
    "    training_config={\n",
    "        \"n_epochs\": 2,\n",
    "        \"data_config\": {\n",
    "            \"batch_size\": 16,\n",
    "            \"dataset_id\": sample_squad_dataset_name,\n",
    "        },\n",
    "        \"optimizer_config\": {\n",
    "            \"lr\": 0.0001,\n",
    "        }\n",
    "    },\n",
    "    algorithm_config={\n",
    "        \"type\": \"LoRA\",\n",
    "        \"adapter_dim\": 16,\n",
    "        \"adapter_dropout\": 0.1,\n",
    "        \"alpha\": 16,\n",
    "        # NOTE: These fields are required, but not directly used by NVIDIA\n",
    "        \"rank\": 8,\n",
    "        \"lora_attn_modules\": [],\n",
    "        \"apply_lora_to_mlp\": True,\n",
    "        \"apply_lora_to_output\": False\n",
    "    },\n",
    "    hyperparam_search_config={},\n",
    "    logger_config={},\n",
    "    checkpoint_dir=\"\",\n",
    ")\n",
    "\n",
    "job_id = response.job_uuid\n",
    "print(f\"Created job with ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Customization job cust-KizmczUEpGiA37zAdAdfrZ to finish.\n",
      "Job status: scheduled after 0.17851614952087402 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 30.721986770629883 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 61.24327778816223 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 91.75424790382385 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 122.30662298202515 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 152.81220698356628 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 183.36947584152222 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 213.87795114517212 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 244.38700914382935 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 274.897922039032 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 305.4090518951416 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 335.9244771003723 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-KizmczUEpGiA37zAdAdfrZ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: completed after 366.4423270225525 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Wait for the job to complete\n",
    "job_status = wait_customization_job(job_id=job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job cust-KizmczUEpGiA37zAdAdfrZ status: completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job {job_id} status: {job_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the fine-tuning job succeeds, we can't immediately run inference on the customized model. In the background, NIM will load newly-created models and make them available for inference. This process typically takes < 5 minutes - here, we wait for our customized model to be picked up before attempting to run inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if NIM has loaded customized model nvidia-e2e-tutorial/test-messages-model@v1.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1 not available after 10.493601083755493 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1 not available after 20.984079837799072 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1 not available after 31.47391676902771 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1 not available after 41.96597099304199 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1 not available after 52.45623183250427 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1 not available after 62.94737505912781 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1 available after 73.4358777999878 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Check that the customized model has been picked up by NIM;\n",
    "# We allow up to 5 minutes for the LoRA adapter to be loaded\n",
    "wait_nim_loads_customized_model(model_id=CUSTOMIZED_MODEL_DIR, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, NIM can run inference on the customized model. However, to use the Llama Stack client to run inference, we need to explicitly register the model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inference response:  green, and the sun is shining brightly today.\n"
     ]
    }
   ],
   "source": [
    "# Check that inference with the new customized model works using direct NIM call\n",
    "# (LlamaStack's nvidia provider doesn't see newly created models immediately)\n",
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{NIM_URL}/v1/completions\",\n",
    "    json={\n",
    "        \"model\": CUSTOMIZED_MODEL_DIR,\n",
    "        \"prompt\": \"Complete the sentence using one word: Roses are red, violets are \",\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"✅ Inference response: {response.json()['choices'][0]['text']}\")\n",
    "else:\n",
    "    print(f\"❌ Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Customized Model\n",
    "Now that we've customized the model, let's run another Evaluation to compare its performance with the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created evaluation job eval-3EfZyAvvjYbeynjwdHC2J6\n"
     ]
    }
   ],
   "source": [
    "# Launch a simple evaluation with the same benchmark with the customized model\n",
    "response = client.alpha.eval.run_eval(\n",
    "    benchmark_id=benchmark_id,\n",
    "    benchmark_config={\n",
    "        \"eval_candidate\": {\n",
    "            \"type\": \"model\",\n",
    "            \"model\": CUSTOMIZED_MODEL_DIR,\n",
    "            \"sampling_params\": {}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "job_id = response.model_dump()[\"job_id\"]\n",
    "print(f\"Created evaluation job {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs/eval-3EfZyAvvjYbeynjwdHC2J6 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Evaluation job eval-3EfZyAvvjYbeynjwdHC2J6 to finish.\n",
      "Job status: Job(job_id='eval-3EfZyAvvjYbeynjwdHC2J6', status='in_progress') after 0.17874503135681152 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs/eval-3EfZyAvvjYbeynjwdHC2J6 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Job(job_id='eval-3EfZyAvvjYbeynjwdHC2J6', status='in_progress') after 5.677712678909302 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs/eval-3EfZyAvvjYbeynjwdHC2J6 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Job(job_id='eval-3EfZyAvvjYbeynjwdHC2J6', status='completed') after 11.171893835067749 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Wait for the job to complete\n",
    "customized_model_job = wait_eval_job(benchmark_id=benchmark_id, job_id=job_id, polling_interval=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job eval-3EfZyAvvjYbeynjwdHC2J6 status: completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job {job_id} status: {customized_model_job.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config/jobs/eval-3EfZyAvvjYbeynjwdHC2J6/result \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job results: {\n",
      "  \"generations\": [],\n",
      "  \"scores\": {\n",
      "    \"test-eval-config\": {\n",
      "      \"aggregated_results\": {\n",
      "        \"created_at\": \"2025-11-20T13:43:09.574352\",\n",
      "        \"updated_at\": \"2025-11-20T13:43:09.574353\",\n",
      "        \"id\": \"evaluation_result-MBkgexnVNMHy9HBLwPb9oK\",\n",
      "        \"job\": \"eval-3EfZyAvvjYbeynjwdHC2J6\",\n",
      "        \"tasks\": {\n",
      "          \"qa\": {\n",
      "            \"metrics\": {\n",
      "              \"bleu\": {\n",
      "                \"scores\": {\n",
      "                  \"sentence\": {\n",
      "                    \"value\": 66.00271830401283,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 200,\n",
      "                      \"sum\": 13200.543660802567,\n",
      "                      \"mean\": 66.00271830401283\n",
      "                    }\n",
      "                  },\n",
      "                  \"corpus\": {\n",
      "                    \"value\": 48.895642888018884\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"string-check\": {\n",
      "                \"scores\": {\n",
      "                  \"string-check\": {\n",
      "                    \"value\": 0.525,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 200,\n",
      "                      \"sum\": 105.0,\n",
      "                      \"mean\": 0.525\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"groups\": {},\n",
      "        \"namespace\": \"default\",\n",
      "        \"custom_fields\": {}\n",
      "      },\n",
      "      \"score_rows\": []\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "customized_model_job_results = client.alpha.eval.jobs.retrieve(benchmark_id=benchmark_id, job_id=job_id)\n",
    "print(f\"Job results: {json.dumps(customized_model_job_results.model_dump(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customized bleu score: 48.895642888018884\n"
     ]
    }
   ],
   "source": [
    "# Extract bleu score and assert it's within range\n",
    "customized_bleu_score = customized_model_job_results.scores[benchmark_id].aggregated_results[\"tasks\"][\"qa\"][\"metrics\"][\"bleu\"][\"scores\"][\"corpus\"][\"value\"]\n",
    "print(f\"Customized bleu score: {customized_bleu_score}\")\n",
    "\n",
    "assert customized_bleu_score >= 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy: 0.525\n"
     ]
    }
   ],
   "source": [
    "# Extract accuracy and assert it's within range\n",
    "customized_accuracy_score = customized_model_job_results.scores[benchmark_id].aggregated_results[\"tasks\"][\"qa\"][\"metrics\"][\"string-check\"][\"scores\"][\"string-check\"][\"value\"]\n",
    "print(f\"Initial accuracy: {customized_accuracy_score}\")\n",
    "\n",
    "assert customized_accuracy_score >= 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect to see an improvement in the bleu score and accuracy in the customized model's evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customized_bleu_score - initial_bleu_score: 44.668188323105355\n",
      "customized_accuracy_score - initial_accuracy_score: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Ensure the customized model evaluation is better than the original model evaluation\n",
    "print(f\"customized_bleu_score - initial_bleu_score: {customized_bleu_score - initial_bleu_score}\")\n",
    "assert (customized_bleu_score - initial_bleu_score) >= 27\n",
    "\n",
    "print(f\"customized_accuracy_score - initial_accuracy_score: {customized_accuracy_score - initial_accuracy_score}\")\n",
    "assert (customized_accuracy_score - initial_accuracy_score) >= 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Chat Dataset Using the HuggingFace Client\n",
    "Repeat the fine-tuning and evaluation workflow with a chat-style dataset, which has a list of `messages` instead of a `prompt` and `completion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_squad_messages_dataset_name = \"test-squad-messages-dataset\"\n",
    "repo_id = f\"{NAMESPACE}/{sample_squad_messages_dataset_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the repo\n",
    "res = hf_api.create_repo(repo_id, repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.jsonl: 100%|██████████| 1.28M/1.28M [00:01<00:00, 988kB/s]\n",
      "validation.jsonl: 100%|██████████| 184k/184k [00:00<00:00, 973kB/s]\n",
      "testing.jsonl: 100%|██████████| 370k/370k [00:00<00:00, 1.78MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='', commit_message='Upload folder using huggingface_hub', commit_description='', oid='08d111e91ead3502475571005b37096be6c8515e', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the files from the local folder\n",
    "hf_api.upload_folder(\n",
    "    folder_path=\"./sample_data/sample_squad_messages/training\",\n",
    "    path_in_repo=\"training\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "hf_api.upload_folder(\n",
    "    folder_path=\"./sample_data/sample_squad_messages/validation\",\n",
    "    path_in_repo=\"validation\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "hf_api.upload_folder(\n",
    "    folder_path=\"./sample_data/sample_squad_messages/testing\",\n",
    "    path_in_repo=\"testing\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/ipykernel_54678/694515331.py:2: DeprecationWarning: deprecated\n",
      "  response = client.beta.datasets.register(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1beta/datasets \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetRegisterResponse(identifier='test-squad-messages-dataset', provider_id='nvidia', purpose='post-training/messages', source=SourceUriDataSource(uri='hf://datasets/nvidia-e2e-tutorial/test-squad-messages-dataset', type='uri'), metadata={'format': 'json', 'description': 'Test sample_squad_messages dataset for NVIDIA E2E notebook', 'provider_id': 'nvidia'}, provider_resource_id='test-squad-messages-dataset', type='dataset', owner=None)\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "response = client.beta.datasets.register(\n",
    "    purpose=\"post-training/messages\",\n",
    "    dataset_id=sample_squad_messages_dataset_name,\n",
    "    source={\n",
    "        \"type\": \"uri\",\n",
    "        \"uri\": f\"hf://datasets/{repo_id}\"\n",
    "    },\n",
    "    metadata={\n",
    "        \"format\": \"json\",\n",
    "        \"description\": \"Test sample_squad_messages dataset for NVIDIA E2E notebook\",\n",
    "        \"provider_id\": \"nvidia\",\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Dataset already exists in Entity Store - continuing...\n"
     ]
    }
   ],
   "source": [
    "# Register dataset in Entity Store (required for customizer/evaluator)\n",
    "import requests\n",
    "response = requests.post(\n",
    "    f\"{ENTITY_STORE_URL}/v1/datasets\",\n",
    "    json={\n",
    "        \"name\": sample_squad_dataset_name,\n",
    "        \"namespace\": NAMESPACE,\n",
    "        \"description\": \"Test sample_squad_data dataset for NVIDIA E2E notebook\",\n",
    "        \"files_url\": f\"hf://datasets/{repo_id}\",\n",
    "        \"project\": \"tool_calling\",\n",
    "        \"format\": \"json\",\n",
    "    },\n",
    ")\n",
    "\n",
    "if response.status_code in (200, 201):\n",
    "    print(\"✅ Dataset registered in Entity Store\")\n",
    "    dataset_obj = response.json()\n",
    "    print(f\"Files URL: {dataset_obj['files_url']}\")\n",
    "    assert dataset_obj[\"files_url\"] == f\"hf://datasets/{repo_id}\"\n",
    "elif response.status_code == 409:\n",
    "    print(\"⚠️ Dataset already exists in Entity Store - continuing...\")\n",
    "else:\n",
    "    print(f\"❌ Failed to register: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with chat/completions\n",
    "We'll use an entry from the `sample_squad_messages` test data to verify we can run inference using NVIDIA NIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful, respectful and honest assistant. Extract from '\n",
      "             'the following context the minimal span word for word that best '\n",
      "             'answers the question.\\n'\n",
      "             '- If a question does not make any sense, or is not factually '\n",
      "             'coherent, explain why instead of answering something not '\n",
      "             'correct.\\n'\n",
      "             \"- If you don't know the answer to a question, please don't share \"\n",
      "             'false information.\\n'\n",
      "             '- If the answer is not in the context, the answer should be '\n",
      "             '\"?\".\\n'\n",
      "             '- Your answer should not include any other text than the answer '\n",
      "             'to the question. Don\\'t include any other text like \"Here is the '\n",
      "             'answer to the question:\" or \"The minimal span word for word that '\n",
      "             'best answers the question is:\" or anything like that.',\n",
      "  'role': 'system'},\n",
      " {'content': 'Context: The league announced on October 16, 2012, that the two '\n",
      "             \"finalists were Sun Life Stadium and Levi's Stadium. The South \"\n",
      "             'Florida/Miami area has previously hosted the event 10 times '\n",
      "             '(tied for most with New Orleans), with the most recent one being '\n",
      "             'Super Bowl XLIV in 2010. The San Francisco Bay Area last hosted '\n",
      "             'in 1985 (Super Bowl XIX), held at Stanford Stadium in Stanford, '\n",
      "             'California, won by the home team 49ers. The Miami bid depended '\n",
      "             'on whether the stadium underwent renovations. However, on May 3, '\n",
      "             '2013, the Florida legislature refused to approve the funding '\n",
      "             'plan to pay for the renovations, dealing a significant blow to '\n",
      "             \"Miami's chances.\\n\"\n",
      "             'Question: In what year was the Super Bowl last held in the '\n",
      "             'Miami/South Florida area?',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./sample_data/sample_squad_messages/testing/testing.jsonl\", \"r\") as f:\n",
    "    examples = [json.loads(line) for line in f]\n",
    "\n",
    "# get the user and assistant messages from the last example\n",
    "sample_messages = examples[-1][\"messages\"][:-1]\n",
    "pprint.pprint(sample_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference response: 2010\n"
     ]
    }
   ],
   "source": [
    "# Test inference\n",
    "response = client.chat.completions.create(\n",
    "    messages=sample_messages,\n",
    "    model=\"nvidia/meta/llama-3.2-1b-instruct\", # BASE_MODEL,\n",
    "    max_tokens=20,\n",
    "    temperature=0.7,\n",
    ")\n",
    "assert response.choices[0].message.content is not None\n",
    "print(f\"Inference response: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with chat dataset\n",
    "We'll register a new benchmark that uses the chat-style testing file uploaded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "# Use a unique benchmark ID to avoid conflicts with existing benchmarks\n",
    "benchmark_id = f\"test-eval-config-chat-{int(time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a benchmark, which creates an Eval Config\n",
    "simple_eval_config = {\n",
    "    \"benchmark_id\": benchmark_id,\n",
    "    \"dataset_id\": \"\",\n",
    "    \"scoring_functions\": [],\n",
    "    \"metadata\": {\n",
    "        \"type\": \"custom\",\n",
    "        \"params\": {\"parallelism\": 8},\n",
    "        \"tasks\": {\n",
    "            \"qa\": {\n",
    "                \"type\": \"completion\",\n",
    "                \"params\": {\n",
    "                    \"template\": {\n",
    "                        \"messages\": [\n",
    "                            {\"role\": \"{{item.messages[0].role}}\", \"content\": \"{{item.messages[0].content}}\"},\n",
    "                            {\"role\": \"{{item.messages[1].role}}\", \"content\": \"{{item.messages[1].content}}\"},\n",
    "                        ],\n",
    "                        \"max_tokens\": 20,\n",
    "                        \"temperature\": 0.7,\n",
    "                        \"top_p\": 0.9,\n",
    "                    },\n",
    "                },\n",
    "                \"dataset\": {\"files_url\": f\"hf://datasets/{repo_id}/testing/testing.jsonl\"},\n",
    "                \"metrics\": {\n",
    "                    \"bleu\": {\n",
    "                        \"type\": \"bleu\",\n",
    "                        \"params\": {\"references\": [\"{{item.messages[2].content | trim}}\"]},\n",
    "                    },\n",
    "                    \"string-check\": {\n",
    "                        \"type\": \"string-check\",\n",
    "                        \"params\": {\"check\": [\"{{item.messages[2].content}}\", \"equals\", \"{{output_text | trim}}\"]},\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/ipykernel_54678/1090845224.py:1: DeprecationWarning: deprecated\n",
      "  response = client.alpha.benchmarks.register(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/eval/benchmarks \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created benchmark test-eval-config-chat-1763646207\n"
     ]
    }
   ],
   "source": [
    "response = client.alpha.benchmarks.register(\n",
    "    benchmark_id=benchmark_id,\n",
    "    dataset_id=repo_id,\n",
    "    scoring_functions=simple_eval_config[\"scoring_functions\"],\n",
    "    metadata=simple_eval_config[\"metadata\"]\n",
    ")\n",
    "print(f\"Created benchmark {benchmark_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config-chat-1763646207/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created evaluation job eval-NGy7hxi3tDaZUbpYAc1Ujs\n"
     ]
    }
   ],
   "source": [
    "# Launch a simple evaluation with the benchmark\n",
    "response = client.alpha.eval.run_eval(\n",
    "    benchmark_id=benchmark_id,\n",
    "    benchmark_config={\n",
    "        \"eval_candidate\": {\n",
    "            \"type\": \"model\",\n",
    "            \"model\": \"meta/llama-3.2-1b-instruct\", # BASE_MODEL\n",
    "            \"sampling_params\": {}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "job_id = response.model_dump()[\"job_id\"]\n",
    "print(f\"Created evaluation job {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config-chat-1763646207/jobs/eval-NGy7hxi3tDaZUbpYAc1Ujs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Evaluation job eval-NGy7hxi3tDaZUbpYAc1Ujs to finish.\n",
      "Job status: Job(job_id='eval-NGy7hxi3tDaZUbpYAc1Ujs', status='in_progress') after 0.16646504402160645 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config-chat-1763646207/jobs/eval-NGy7hxi3tDaZUbpYAc1Ujs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Job(job_id='eval-NGy7hxi3tDaZUbpYAc1Ujs', status='in_progress') after 5.693363904953003 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config-chat-1763646207/jobs/eval-NGy7hxi3tDaZUbpYAc1Ujs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Job(job_id='eval-NGy7hxi3tDaZUbpYAc1Ujs', status='completed') after 11.280320882797241 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Wait for the job to complete\n",
    "job = wait_eval_job(benchmark_id=benchmark_id, job_id=job_id, polling_interval=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job eval-NGy7hxi3tDaZUbpYAc1Ujs status: completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job {job_id} status: {job.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config-chat-1763646207/jobs/eval-NGy7hxi3tDaZUbpYAc1Ujs/result \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job results: {\n",
      "  \"generations\": [],\n",
      "  \"scores\": {\n",
      "    \"test-eval-config-chat-1763646207\": {\n",
      "      \"aggregated_results\": {\n",
      "        \"created_at\": \"2025-11-20T13:43:27.996624\",\n",
      "        \"updated_at\": \"2025-11-20T13:43:27.996625\",\n",
      "        \"id\": \"evaluation_result-422RmKHVFAirB4BTcm2hhw\",\n",
      "        \"job\": \"eval-NGy7hxi3tDaZUbpYAc1Ujs\",\n",
      "        \"tasks\": {\n",
      "          \"qa\": {\n",
      "            \"metrics\": {\n",
      "              \"bleu\": {\n",
      "                \"scores\": {\n",
      "                  \"sentence\": {\n",
      "                    \"value\": 32.557034344436985,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 200,\n",
      "                      \"sum\": 6511.406868887398,\n",
      "                      \"mean\": 32.557034344436985\n",
      "                    }\n",
      "                  },\n",
      "                  \"corpus\": {\n",
      "                    \"value\": 12.92432521051032\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"string-check\": {\n",
      "                \"scores\": {\n",
      "                  \"string-check\": {\n",
      "                    \"value\": 0.26,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 200,\n",
      "                      \"sum\": 52.0,\n",
      "                      \"mean\": 0.26\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"groups\": {},\n",
      "        \"namespace\": \"default\",\n",
      "        \"custom_fields\": {}\n",
      "      },\n",
      "      \"score_rows\": []\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_results = client.alpha.eval.jobs.retrieve(benchmark_id=benchmark_id, job_id=job_id)\n",
    "print(f\"Job results: {json.dumps(job_results.model_dump(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial bleu score: 12.92432521051032\n"
     ]
    }
   ],
   "source": [
    "# Extract bleu score and assert it's within range\n",
    "initial_bleu_score = job_results.scores[benchmark_id].aggregated_results[\"tasks\"][\"qa\"][\"metrics\"][\"bleu\"][\"scores\"][\"corpus\"][\"value\"]\n",
    "print(f\"Initial bleu score: {initial_bleu_score}\")\n",
    "\n",
    "assert initial_bleu_score >= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy: 0.26\n"
     ]
    }
   ],
   "source": [
    "# Extract accuracy and assert it's within range\n",
    "initial_accuracy_score = job_results.scores[benchmark_id].aggregated_results[\"tasks\"][\"qa\"][\"metrics\"][\"string-check\"][\"scores\"][\"string-check\"][\"value\"]\n",
    "print(f\"Initial accuracy: {initial_accuracy_score}\")\n",
    "\n",
    "assert initial_accuracy_score >= 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization with chat dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've established our baseline Evaluation metrics for the chat-style dataset, we'll customize a model using our training data uploaded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated LlamaStack deployment with model dir: nvidia-e2e-tutorial/test-messages-model@v1763646228\n",
      "Waiting for deployment \"llamastack\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "deployment \"llamastack\" successfully rolled out\n",
      "✅ LlamaStack deployment updated successfully\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "customized_chat_model_name = \"test-messages-model\"\n",
    "# Use a unique version to avoid conflicts with existing models\n",
    "customized_chat_model_version = f\"v{int(time())}\"\n",
    "customized_chat_model_dir = f\"{NAMESPACE}/{customized_chat_model_name}@{customized_chat_model_version}\"\n",
    "\n",
    "# NOTE: The output model name is derived from the environment variable in the LlamaStack deployment\n",
    "# Update the LlamaStack deployment to use the new model version\n",
    "result = subprocess.run(\n",
    "    [\"oc\", \"set\", \"env\", \"deployment/llamastack\", \n",
    "     f\"NVIDIA_OUTPUT_MODEL_DIR={customized_chat_model_dir}\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"✅ Updated LlamaStack deployment with model dir: {customized_chat_model_dir}\")\n",
    "    # Wait for the deployment to rollout\n",
    "    subprocess.run(\n",
    "        [\"oc\", \"rollout\", \"status\", \"deployment/llamastack\"],\n",
    "        timeout=120\n",
    "    )\n",
    "    print(\"✅ LlamaStack deployment updated successfully\")\n",
    "else:\n",
    "    print(f\"❌ Failed to update deployment: {result.stderr}\")\n",
    "    raise Exception(f\"Failed to update deployment: {result.stderr}\")\n",
    "\n",
    "# Also set it locally for reference\n",
    "os.environ[\"NVIDIA_OUTPUT_MODEL_DIR\"] = customized_chat_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nvidia-e2e-tutorial/test-messages-model@v1763646228'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customized_chat_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    f\"{ENTITY_STORE_URL}/v1/datasets\",\n",
    "    json={\n",
    "        \"name\": sample_squad_messages_dataset_name,  \n",
    "        \"namespace\": NAMESPACE,\n",
    "        \"description\": \"Test sample_squad_messages dataset for NVIDIA E2E notebook\",  # Also update description\n",
    "        \"files_url\": f\"hf://datasets/{repo_id}\",\n",
    "        \"project\": \"tool_calling\",\n",
    "        \"format\": \"json\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/post-training/supervised-fine-tune \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = client.alpha.post_training.supervised_fine_tune(\n",
    "    job_uuid=\"\",\n",
    "    model=\"meta/llama-3.2-1b-instruct@v1.0.0+A100\",  \n",
    "    training_config={\n",
    "        \"n_epochs\": 2,\n",
    "        \"data_config\": {\n",
    "            \"batch_size\": 16,\n",
    "            \"dataset_id\": sample_squad_messages_dataset_name,\n",
    "        },\n",
    "        \"optimizer_config\": {\n",
    "            \"lr\": 0.0001,\n",
    "        }\n",
    "    },\n",
    "    algorithm_config={\n",
    "        \"type\": \"LoRA\",\n",
    "        \"adapter_dim\": 16,\n",
    "        \"adapter_dropout\": 0.1,\n",
    "        \"alpha\": 16,\n",
    "        \"rank\": 8,\n",
    "        \"lora_attn_modules\": [],\n",
    "        \"apply_lora_to_mlp\": True,\n",
    "        \"apply_lora_to_output\": False\n",
    "    },\n",
    "    hyperparam_search_config={},\n",
    "    logger_config={},\n",
    "    checkpoint_dir=\"\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job with ID: cust-DHndZjk1zmqeJDf7FMJuoe\n"
     ]
    }
   ],
   "source": [
    "job_id = response.job_uuid\n",
    "print(f\"Created job with ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Customization job cust-DHndZjk1zmqeJDf7FMJuoe to finish.\n",
      "Job status: scheduled after 0.17351388931274414 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 30.762430906295776 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 61.298707008361816 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 91.80515718460083 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 122.314857006073 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 152.81673789024353 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 183.36792588233948 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 213.87998414039612 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 244.39159083366394 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 274.889102935791 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress after 305.4221601486206 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/post-training/job/status?job_uuid=cust-DHndZjk1zmqeJDf7FMJuoe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: completed after 335.8395550251007 seconds.\n"
     ]
    }
   ],
   "source": [
    "job = wait_customization_job(job_id=job_id, polling_interval=30, timeout=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job cust-DHndZjk1zmqeJDf7FMJuoe status: completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Job {job_id} status: {job_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if NIM has loaded customized model nvidia-e2e-tutorial/test-messages-model@v1763646228.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 10.596751928329468 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 21.086602926254272 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 31.566166877746582 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 42.22009587287903 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 52.86898708343506 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 63.35778498649597 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 73.84983396530151 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 84.33940100669861 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 94.82941198348999 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 105.3087830543518 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 not available after 115.79959392547607 seconds.\n",
      "Model nvidia-e2e-tutorial/test-messages-model@v1763646228 available after 126.27090287208557 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Check that the customized model has been picked up by NIM;\n",
    "# We allow up to 5 minutes for the LoRA adapter to be loaded\n",
    "wait_nim_loads_customized_model(model_id=customized_chat_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inference response: -----------\n",
      "A) blue\n",
      "B) purple\n",
      "C) white\n",
      "D) yellow\n",
      "\n",
      "The best answer\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{NIM_URL}/v1/completions\",\n",
    "    json={\n",
    "        \"model\": customized_chat_model_dir,\n",
    "        \"prompt\": \"Complete the sentence using one word: Roses are red, violets are \",\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"✅ Inference response: {response.json()['choices'][0]['text']}\")\n",
    "else:\n",
    "    print(f\"❌ Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(response.content) > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Customized Model with chat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new benchmark ID: test-eval-config-chat-1763646850\n"
     ]
    }
   ],
   "source": [
    "# Re-create benchmark ID with new timestamp (since LlamaStack pod restarted in cell 84)\n",
    "benchmark_id = f\"test-eval-config-chat-{int(time())}\"\n",
    "print(f\"Creating new benchmark ID: {benchmark_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define the eval config with the new benchmark ID\n",
    "simple_eval_config = {\n",
    "    \"benchmark_id\": benchmark_id,\n",
    "    \"dataset_id\": \"\",\n",
    "    \"scoring_functions\": [],\n",
    "    \"metadata\": {\n",
    "        \"type\": \"custom\",\n",
    "        \"params\": {\"parallelism\": 8},\n",
    "        \"tasks\": {\n",
    "            \"qa\": {\n",
    "                \"type\": \"completion\",\n",
    "                \"params\": {\n",
    "                    \"template\": {\n",
    "                        \"messages\": [\n",
    "                            {\"role\": \"{{item.messages[0].role}}\", \"content\": \"{{item.messages[0].content}}\"},\n",
    "                            {\"role\": \"{{item.messages[1].role}}\", \"content\": \"{{item.messages[1].content}}\"},\n",
    "                        ],\n",
    "                        \"max_tokens\": 20,\n",
    "                        \"temperature\": 0.7,\n",
    "                        \"top_p\": 0.9,\n",
    "                    },\n",
    "                },\n",
    "                \"dataset\": {\"files_url\": f\"hf://datasets/{repo_id}/testing/testing.jsonl\"},\n",
    "                \"metrics\": {\n",
    "                    \"bleu\": {\n",
    "                        \"type\": \"bleu\",\n",
    "                        \"params\": {\"references\": [\"{{item.messages[2].content | trim}}\"]},\n",
    "                    },\n",
    "                    \"string-check\": {\n",
    "                        \"type\": \"string-check\",\n",
    "                        \"params\": {\"check\": [\"{{item.messages[2].content}}\", \"equals\", \"{{output_text | trim}}\"]},\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/jvwmjx1j6vn5njz069y5lcn40000gn/T/ipykernel_54678/3862291133.py:2: DeprecationWarning: deprecated\n",
      "  response = client.alpha.benchmarks.register(\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/eval/benchmarks \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Registered benchmark test-eval-config-chat-1763646850\n"
     ]
    }
   ],
   "source": [
    "# Re-register the benchmark with LlamaStack (after pod restart)\n",
    "response = client.alpha.benchmarks.register(\n",
    "    benchmark_id=benchmark_id,\n",
    "    dataset_id=repo_id,\n",
    "    scoring_functions=simple_eval_config[\"scoring_functions\"],\n",
    "    metadata=simple_eval_config[\"metadata\"]\n",
    ")\n",
    "print(f\"✅ Registered benchmark {benchmark_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bfbe25e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config-chat-1763646850/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created evaluation job eval-4KiU7JesTLyr1uPWg1WVwM\n"
     ]
    }
   ],
   "source": [
    "# Launch evaluation for customized model\n",
    "response = client.alpha.eval.run_eval(\n",
    "    benchmark_id=benchmark_id,\n",
    "    benchmark_config={\n",
    "        \"eval_candidate\": {\n",
    "            \"type\": \"model\",\n",
    "            \"model\": customized_chat_model_dir,\n",
    "            \"sampling_params\": {}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "job_id = response.model_dump()[\"job_id\"]\n",
    "print(f\"Created evaluation job {job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config-chat-1763646850/jobs/eval-4KiU7JesTLyr1uPWg1WVwM \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Evaluation job eval-4KiU7JesTLyr1uPWg1WVwM to finish.\n",
      "Job status: Job(job_id='eval-4KiU7JesTLyr1uPWg1WVwM', status='in_progress') after 0.16409921646118164 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config-chat-1763646850/jobs/eval-4KiU7JesTLyr1uPWg1WVwM \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Job(job_id='eval-4KiU7JesTLyr1uPWg1WVwM', status='completed') after 5.662703275680542 seconds.\n"
     ]
    }
   ],
   "source": [
    "job = wait_eval_job(benchmark_id=benchmark_id, job_id=job_id, polling_interval=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1alpha/eval/benchmarks/test-eval-config-chat-1763646850/jobs/eval-4KiU7JesTLyr1uPWg1WVwM/result \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job results: {\n",
      "  \"generations\": [],\n",
      "  \"scores\": {\n",
      "    \"test-eval-config-chat-1763646850\": {\n",
      "      \"aggregated_results\": {\n",
      "        \"created_at\": \"2025-11-20T13:54:13.686229\",\n",
      "        \"updated_at\": \"2025-11-20T13:54:13.686230\",\n",
      "        \"id\": \"evaluation_result-4y532gccosY7k2ddzGmNpe\",\n",
      "        \"job\": \"eval-4KiU7JesTLyr1uPWg1WVwM\",\n",
      "        \"tasks\": {\n",
      "          \"qa\": {\n",
      "            \"metrics\": {\n",
      "              \"bleu\": {\n",
      "                \"scores\": {\n",
      "                  \"sentence\": {\n",
      "                    \"value\": 68.94887522892891,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 200,\n",
      "                      \"sum\": 13789.775045785784,\n",
      "                      \"mean\": 68.94887522892891\n",
      "                    }\n",
      "                  },\n",
      "                  \"corpus\": {\n",
      "                    \"value\": 53.23802090091468\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"string-check\": {\n",
      "                \"scores\": {\n",
      "                  \"string-check\": {\n",
      "                    \"value\": 0.545,\n",
      "                    \"stats\": {\n",
      "                      \"count\": 200,\n",
      "                      \"sum\": 109.0,\n",
      "                      \"mean\": 0.545\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"groups\": {},\n",
      "        \"namespace\": \"default\",\n",
      "        \"custom_fields\": {}\n",
      "      },\n",
      "      \"score_rows\": []\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_results = client.alpha.eval.jobs.retrieve(benchmark_id=benchmark_id, job_id=job_id)\n",
    "print(f\"Job results: {json.dumps(job_results.model_dump(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customized bleu score: 53.23802090091468\n"
     ]
    }
   ],
   "source": [
    "# Extract bleu score and assert it's within range\n",
    "customized_bleu_score = job_results.scores[benchmark_id].aggregated_results[\"tasks\"][\"qa\"][\"metrics\"][\"bleu\"][\"scores\"][\"corpus\"][\"value\"]\n",
    "print(f\"Customized bleu score: {customized_bleu_score}\")\n",
    "\n",
    "assert customized_bleu_score >= 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customized accuracy: 0.545\n"
     ]
    }
   ],
   "source": [
    "# Extract accuracy and assert it's within range\n",
    "customized_accuracy_score = job_results.scores[benchmark_id].aggregated_results[\"tasks\"][\"qa\"][\"metrics\"][\"string-check\"][\"scores\"][\"string-check\"][\"value\"]\n",
    "print(f\"Customized accuracy: {customized_accuracy_score}\")\n",
    "\n",
    "assert customized_accuracy_score >= 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customized_bleu_score - initial_bleu_score: 40.31369569040436\n",
      "customized_accuracy_score - initial_accuracy_score: 0.28500000000000003\n"
     ]
    }
   ],
   "source": [
    "# Ensure the customized model evaluation is better than the original model evaluation\n",
    "print(f\"customized_bleu_score - initial_bleu_score: {customized_bleu_score - initial_bleu_score}\")\n",
    "assert (customized_bleu_score - initial_bleu_score) >= 20\n",
    "\n",
    "print(f\"customized_accuracy_score - initial_accuracy_score: {customized_accuracy_score - initial_accuracy_score}\")\n",
    "assert (customized_accuracy_score - initial_accuracy_score) >= 0.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
