{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a65fb3-f1a5-4de8-b54d-67346fa35c8a",
   "metadata": {},
   "source": [
    " # Part I: Preparing Datasets for Fine-tuning and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905e4a5",
   "metadata": {},
   "source": [
    "The following code cell imports necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-requirements",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.34.4)\n",
      "Requirement already satisfied: transformers>=4.36.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: peft in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.17.1)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.4.1)\n",
      "Requirement already satisfied: trl in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.25.0)\n",
      "Requirement already satisfied: jsonschema in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.23.0)\n",
      "Requirement already satisfied: litellm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.79.1)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.1.6)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.99.9)\n",
      "Requirement already satisfied: jupyterlab in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.3.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers>=4.36.0) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers>=4.36.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers>=4.36.0) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers>=4.36.0) (0.5.3)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (6.1.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (1.8.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema) (0.22.3)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from litellm) (8.1.8)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from litellm) (0.14.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from litellm) (8.5.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from litellm) (2.9.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from litellm) (0.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=3.1.0) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.23.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=2.0.0) (75.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=2.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=2.0.0) (3.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (6.29.5)\n",
      "Requirement already satisfied: jupyter-core in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (6.4.2)\n",
      "Requirement already satisfied: traitlets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (8.6.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (26.3.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.32.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: rfc3339-validator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (5.0.1)\n",
      "Requirement already satisfied: defusedxml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.2,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.1.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.6)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241206)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ Package installation completed\n"
     ]
    }
   ],
   "source": [
    "# Install required Python packages for this notebook environment\n",
    "%pip install \\\n",
    "  huggingface_hub \\\n",
    "  \"transformers>=4.36.0\" \\\n",
    "  peft \\\n",
    "  datasets \\\n",
    "  trl \\\n",
    "  jsonschema \\\n",
    "  litellm \\\n",
    "  \"jinja2>=3.1.0\" \\\n",
    "  \"torch>=2.0.0\" \\\n",
    "  openai \\\n",
    "  jupyterlab \\\n",
    "  requests \\\n",
    "  python-dotenv\n",
    "\n",
    "# Note: print_status function is defined in the next cell\n",
    "print(\"✅ Package installation completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6193d10c-583c-4a78-8459-66e7ec2bbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "def print_status(message):\n",
    "    \"\"\"Print a status message with a checkmark emoji.\"\"\"\n",
    "    print(f\"✅ {message}\")\n",
    "\n",
    "print_status(\"Imports completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc25e7",
   "metadata": {},
   "source": [
    "The following code cell sets a random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc7314b-0f86-4ed4-bdc1-3d2598092cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random seed configuration completed\n"
     ]
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "# Limits to at most N tool properties\n",
    "LIMIT_TOOL_PROPERTIES = 8\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "print_status(\"Random seed configuration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab9962",
   "metadata": {},
   "source": [
    "The following code cell defines the data root directory and creates necessary directories for storing processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6434b0c-9ad0-403e-9cf4-d9ab22306769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data directories created\n"
     ]
    }
   ],
   "source": [
    "# Processed data will be stored here\n",
    "DATA_ROOT = os.path.join(os.getcwd(), \"data\")\n",
    "CUSTOMIZATION_DATA_ROOT = os.path.join(DATA_ROOT, \"customization\")\n",
    "VALIDATION_DATA_ROOT = os.path.join(DATA_ROOT, \"validation\")\n",
    "EVALUATION_DATA_ROOT = os.path.join(DATA_ROOT, \"evaluation\")\n",
    "\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(CUSTOMIZATION_DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(VALIDATION_DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(EVALUATION_DATA_ROOT, exist_ok=True)\n",
    "\n",
    "print_status(\"Data directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2556c45-8c14-4ea2-a2c2-7937c9902b2d",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-1\"></a>\n",
    "## Step 1: Download xLAM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1f5a8-c741-4657-b6c9-56afd9dccc94",
   "metadata": {},
   "source": [
    "This step loads the xLAM dataset from Hugging Face.\n",
    "\n",
    "Ensure that you have followed the prerequisites mentioned in the associated README, obtained a Hugging Face access token, and configured it in [config.py](./config.py). In addition to getting an access token, you need to apply for access to the xLAM dataset on its [page](https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k), which will be approved instantly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f729c88-e633-4914-b3b3-09311ad79a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hugging Face configuration completed\n"
     ]
    }
   ],
   "source": [
    "from config import HF_TOKEN\n",
    "\n",
    "# Set environment variables for Hugging Face\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://huggingface.co\"\n",
    "\n",
    "# Note: We'll pass the token directly to load_dataset() in the next cell\n",
    "# This is more reliable than using login() which can have issues with environment variables\n",
    "\n",
    "print_status(\"Hugging Face configuration completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d19368-0c33-4595-bea8-24ef645eaaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': '[{\"name\": \"live_giveaways_by_type\", \"arguments\": {\"type\": '\n",
      "            '\"beta\"}}, {\"name\": \"live_giveaways_by_type\", \"arguments\": '\n",
      "            '{\"type\": \"game\"}}]',\n",
      " 'id': 0,\n",
      " 'query': 'Where can I find live giveaways for beta access and games?',\n",
      " 'tools': '[{\"name\": \"live_giveaways_by_type\", \"description\": \"Retrieve live '\n",
      "          'giveaways from the GamerPower API based on the specified type.\", '\n",
      "          '\"parameters\": {\"type\": {\"description\": \"The type of giveaways to '\n",
      "          'retrieve (e.g., game, loot, beta).\", \"type\": \"str\", \"default\": '\n",
      "          '\"game\"}}}]'}\n",
      "✅ xLAM dataset downloaded and inspected\n"
     ]
    }
   ],
   "source": [
    "# Download from Hugging Face\n",
    "# Ensure environment variables are set and pass token explicitly\n",
    "from config import HF_TOKEN\n",
    "import os\n",
    "\n",
    "# Make sure environment variables are set (in case cell 10 wasn't run)\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://huggingface.co\"\n",
    "\n",
    "# Load dataset with explicit token\n",
    "dataset = load_dataset(\"Salesforce/xlam-function-calling-60k\", token=HF_TOKEN)\n",
    "\n",
    "# Inspect a sample\n",
    "example = dataset['train'][0]\n",
    "pprint(example)\n",
    "\n",
    "print_status(\"xLAM dataset downloaded and inspected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa142c-b051-42ad-ad24-aabdd05ea391",
   "metadata": {},
   "source": [
    "For more details on the structure of this data, refer to the [data structure of the xLAM dataset](https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k#structure) in the Hugging Face documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f41f50-2142-4de5-80ee-22e10a868559",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-2\"></a>\n",
    "## Step 2: Prepare Data for Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98b800-5b23-48a4-983b-dc4797e7d496",
   "metadata": {},
   "source": [
    "For Customization, the NeMo Microservices platform leverages the OpenAI data format, comprised of `messages` and `tools`:\n",
    "\n",
    "* `messages` include the `user` query, as well as the ground truth `assistant` response to the query. This response contains the function name(s) and associated argument(s) in a \"tool_calls\" dict.\n",
    "* `tools` include a list of functions and parameters available to the LLM to choose from, as well as their descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f81d2a-ece1-4be2-abe3-e6404e473665",
   "metadata": {},
   "source": [
    "The following is an example of the data format:\n",
    "```\n",
    "{\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Where can I find live giveaways for beta access and games?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": \"call_beta\",\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"live_giveaways_by_type\",\n",
    "                        \"arguments\": {\"type\": \"beta\"}\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"call_game\",\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"live_giveaways_by_type\",\n",
    "                        \"arguments\": {\"type\": \"game\"}\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"live_giveaways_by_type\",\n",
    "                \"description\": \"Retrieve live giveaways from the GamerPower API based on the specified type.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"type\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The type of giveaways to retrieve (e.g., game, loot, beta).\",\n",
    "                            \"default\": \"game\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": []\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb67d5-f95b-47f4-99bc-7a2ad4117f7a",
   "metadata": {},
   "source": [
    "The following helper functions convert a single xLAM JSON data point into OpenAI format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47fc5c3e-0f4b-4423-845e-5c32865283e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data conversion functions defined\n"
     ]
    }
   ],
   "source": [
    "def normalize_type(param_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize Python type hints and parameter definitions to OpenAI function spec types.\n",
    "\n",
    "    Args:\n",
    "        param_type: Type string that could include default values or complex types\n",
    "\n",
    "    Returns:\n",
    "        Normalized type string according to OpenAI function spec\n",
    "    \"\"\"\n",
    "    # Remove whitespace\n",
    "    param_type = param_type.strip()\n",
    "\n",
    "    # Handle types with default values (e.g. \"str, default='London'\")\n",
    "    if \",\" in param_type and \"default\" in param_type:\n",
    "        param_type = param_type.split(\",\")[0].strip()\n",
    "\n",
    "    # Handle types with just default values (e.g. \"default='London'\")\n",
    "    if param_type.startswith(\"default=\"):\n",
    "        return \"string\"  # Default to string if only default value is given\n",
    "\n",
    "    # Remove \", optional\" suffix if present\n",
    "    param_type = param_type.replace(\", optional\", \"\").strip()\n",
    "\n",
    "    # Handle complex types\n",
    "    if param_type.startswith(\"Callable\"):\n",
    "        return \"string\"  # Represent callable as string in JSON schema\n",
    "    if param_type.startswith(\"Tuple\"):\n",
    "        return \"array\"  # Represent tuple as array in JSON schema\n",
    "    if param_type.startswith(\"List[\"):\n",
    "        return \"array\"\n",
    "    if param_type.startswith(\"Set\") or param_type == \"set\":\n",
    "        return \"array\"  # Represent set as array in JSON schema\n",
    "\n",
    "    # Map common type variations to OpenAI spec types\n",
    "    type_mapping: Dict[str, str] = {\n",
    "        \"str\": \"string\",\n",
    "        \"int\": \"integer\",\n",
    "        \"float\": \"number\",\n",
    "        \"bool\": \"boolean\",\n",
    "        \"list\": \"array\",\n",
    "        \"dict\": \"object\",\n",
    "        \"List\": \"array\",\n",
    "        \"Dict\": \"object\",\n",
    "        \"set\": \"array\",\n",
    "        \"Set\": \"array\"\n",
    "    }\n",
    "\n",
    "    if param_type in type_mapping:\n",
    "        return type_mapping[param_type]\n",
    "    else:\n",
    "        print(f\"Unknown type: {param_type}\")\n",
    "        return \"string\"  # Default to string for unknown types\n",
    "\n",
    "\n",
    "def convert_tools_to_openai_spec(tools: Union[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:\n",
    "    # If tools is a string, try to parse it as JSON\n",
    "    if isinstance(tools, str):\n",
    "        try:\n",
    "            tools = json.loads(tools)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse tools string as JSON: {e}\")\n",
    "            return []\n",
    "\n",
    "    # Ensure tools is a list\n",
    "    if not isinstance(tools, list):\n",
    "        print(f\"Expected tools to be a list, but got {type(tools)}\")\n",
    "        return []\n",
    "\n",
    "    openai_tools: List[Dict[str, Any]] = []\n",
    "    for tool in tools:\n",
    "        # Check if tool is a dictionary\n",
    "        if not isinstance(tool, dict):\n",
    "            print(f\"Expected tool to be a dictionary, but got {type(tool)}\")\n",
    "            continue\n",
    "\n",
    "        # Check if 'parameters' is a dictionary\n",
    "        if not isinstance(tool.get(\"parameters\"), dict):\n",
    "            print(f\"Expected 'parameters' to be a dictionary, but got {type(tool.get('parameters'))} for tool: {tool}\")\n",
    "            continue\n",
    "\n",
    "    \n",
    "\n",
    "        normalized_parameters: Dict[str, Dict[str, Any]] = {}\n",
    "        for param_name, param_info in tool[\"parameters\"].items():\n",
    "            if not isinstance(param_info, dict):\n",
    "                print(\n",
    "                    f\"Expected parameter info to be a dictionary, but got {type(param_info)} for parameter: {param_name}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Create parameter info without default first\n",
    "            param_dict = {\n",
    "                \"description\": param_info.get(\"description\", \"\"),\n",
    "                \"type\": normalize_type(param_info.get(\"type\", \"\")),\n",
    "            }\n",
    "\n",
    "            # Only add default if it exists, is not None, and is not an empty string\n",
    "            default_value = param_info.get(\"default\")\n",
    "            if default_value is not None and default_value != \"\":\n",
    "                param_dict[\"default\"] = default_value\n",
    "\n",
    "            normalized_parameters[param_name] = param_dict\n",
    "\n",
    "        openai_tool = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": tool[\"name\"],\n",
    "                \"description\": tool[\"description\"],\n",
    "                \"parameters\": {\"type\": \"object\", \"properties\": normalized_parameters},\n",
    "            },\n",
    "        }\n",
    "        openai_tools.append(openai_tool)\n",
    "    return openai_tools\n",
    "\n",
    "\n",
    "def save_jsonl(filename, data):\n",
    "    \"\"\"Write a list of json objects to a .jsonl file\"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        for entry in data:\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "\n",
    "def convert_tool_calls(xlam_tools):\n",
    "    \"\"\"Convert XLAM tool format to OpenAI's tool schema.\"\"\"\n",
    "    tools = []\n",
    "    for tool in json.loads(xlam_tools):\n",
    "        tools.append({\"type\": \"function\", \"function\": {\"name\": tool[\"name\"], \"arguments\": tool.get(\"arguments\", {})}})\n",
    "    return tools\n",
    "\n",
    "\n",
    "def convert_example(example, dataset_type='single'):\n",
    "    \"\"\"Convert an XLAM dataset example to OpenAI format.\"\"\"\n",
    "    obj = {\"messages\": []}\n",
    "\n",
    "    # User message\n",
    "    obj[\"messages\"].append({\"role\": \"user\", \"content\": example[\"query\"]})\n",
    "\n",
    "    # Tools\n",
    "    if example.get(\"tools\"):\n",
    "        obj[\"tools\"] = convert_tools_to_openai_spec(example[\"tools\"])\n",
    "\n",
    "    # Assistant message\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    if example.get(\"answers\"):\n",
    "        tool_calls = convert_tool_calls(example[\"answers\"])\n",
    "        \n",
    "        if dataset_type == \"single\":\n",
    "            # Only include examples with a single tool call\n",
    "            if len(tool_calls) == 1:\n",
    "                assistant_message[\"tool_calls\"] = tool_calls\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            # For other dataset types, include all tool calls\n",
    "            assistant_message[\"tool_calls\"] = tool_calls\n",
    "                \n",
    "    obj[\"messages\"].append(assistant_message)\n",
    "\n",
    "    return obj\n",
    "\n",
    "print_status(\"Data conversion functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b514a",
   "metadata": {},
   "source": [
    "The following code cell converts the example data to the OpenAI format required by NeMo Customizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3366c584-bf5f-47f2-b0ea-aa421c3d083b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Example conversion completed\n"
     ]
    }
   ],
   "source": [
    "convert_example(example)\n",
    "\n",
    "print_status(\"Example conversion completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62515958-e98d-475b-9fda-18890d353813",
   "metadata": {},
   "source": [
    "**NOTE**: The `convert_example` function by default only retains data points that have exactly one `tool_call` in the output.\n",
    "The `llama-3.2-1b-instruct` model does not support parallel tool calls.\n",
    "For more information, refer to the [supported models](https://docs.nvidia.com/nim/large-language-models/latest/function-calling.html#supported-models) in the NeMo documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76d74a-5df2-443f-aff6-0feff0e06285",
   "metadata": {},
   "source": [
    "### Process Entire Dataset\n",
    "Convert each example by looping through the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706c81c0-3900-4157-9366-afa10a142c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset conversion completed\n"
     ]
    }
   ],
   "source": [
    "all_examples = []\n",
    "with open(os.path.join(DATA_ROOT, \"xlam_openai_format.jsonl\"), \"w\") as f:\n",
    "    for example in dataset[\"train\"]:\n",
    "        converted = convert_example(example)\n",
    "        if converted is not None:\n",
    "            all_examples.append(converted)\n",
    "            f.write(json.dumps(converted) + \"\\n\")\n",
    "\n",
    "print_status(\"Dataset conversion completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b7d931-6c33-4d8f-8a57-e188aacc7616",
   "metadata": {},
   "source": [
    "### Split Dataset\n",
    "This step splits the dataset into a train, validation, and test set.\n",
    "For demonstration, we use a smaller subset of all the examples.\n",
    "You may choose to modify `NUM_EXAMPLES` to leverage a larger subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8be515e-4255-4682-8499-a30c71f129e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset size configuration validated\n"
     ]
    }
   ],
   "source": [
    "# Configure to change the size of dataset to use\n",
    "NUM_EXAMPLES = 5000\n",
    "\n",
    "assert NUM_EXAMPLES <= len(all_examples), f\"{NUM_EXAMPLES} exceeds the total number of available ({len(all_examples)}) data points\"\n",
    "\n",
    "print_status(\"Dataset size configuration validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdc6072-0b85-45be-b3b1-fe9a1c26d641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset split and saved\n"
     ]
    }
   ],
   "source": [
    "# Randomly choose a subset\n",
    "sampled_examples = random.sample(all_examples, NUM_EXAMPLES)\n",
    "\n",
    "# Split into 70% training, 15% validation, 15% testing\n",
    "train_size = int(0.7 * len(sampled_examples))\n",
    "val_size = int(0.15 * len(sampled_examples))\n",
    "\n",
    "train_data = sampled_examples[:train_size]\n",
    "val_data = sampled_examples[train_size : train_size + val_size]\n",
    "test_data = sampled_examples[train_size + val_size :]\n",
    "\n",
    "# Save the training and validation splits. We will use test split in the next section\n",
    "save_jsonl(os.path.join(CUSTOMIZATION_DATA_ROOT, \"training.jsonl\"), train_data)\n",
    "save_jsonl(os.path.join(VALIDATION_DATA_ROOT,\"validation.jsonl\"), val_data)\n",
    "\n",
    "print_status(\"Dataset split and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afdfed-4af3-4deb-90df-081f00300714",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-3\"></a>\n",
    "## Step 3: Prepare Data for Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f2094-2afb-458d-8c9d-526f1270c017",
   "metadata": {},
   "source": [
    "For evaluation, the NeMo Microservices platform uses a format with a minor modification to the OpenAI format. This requires `tools_calls` to be brought out of `messages` to create a distinct parallel field.\n",
    "\n",
    "* `messages` includes the `user` query\n",
    "* `tools` includes a list of functions and parameters available to the LLM to choose from, as well as their descriptions.\n",
    "* `tool_calls` is the ground truth response to the user query. This response contains the function name(s) and associated argument(s) in a \"tool_calls\" dict.\n",
    "\n",
    "Here is an example -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc1448-b09f-426d-81eb-52122a961d80",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Where can I find live giveaways for beta access?\"\n",
    "        },\n",
    "    ],\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"live_giveaways_by_type\",\n",
    "                \"description\": \"Retrieve live giveaways from the GamerPower API based on the specified type.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"type\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The type of giveaways to retrieve (e.g., game, loot, beta).\",\n",
    "                            \"default\": \"game\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": []\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"tool_calls\": [\n",
    "        {\n",
    "            \"id\": \"call_beta\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"live_giveaways_by_type\",\n",
    "                \"arguments\": {\"type\": \"beta\"}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424507e-4097-49bb-b750-96a66f9abd77",
   "metadata": {},
   "source": [
    "The following steps transform the test dataset into a format compatible with the NeMo Evaluator microservice.\n",
    "This dataset is for measuring accuracy metrics before and after customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6487d80-36a0-4314-8c21-93744043ce05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation conversion function defined\n",
      "✅ Evaluation conversion functions defined\n"
     ]
    }
   ],
   "source": [
    "def convert_example_eval(entry):\n",
    "    \"\"\"Convert a single entry in the dataset to the evaluator format\"\"\"\n",
    "\n",
    "    # Note: This is a WAR for a known bug with tool calling in NIM\n",
    "    for tool in entry[\"tools\"]:\n",
    "        if len(tool[\"function\"][\"parameters\"][\"properties\"]) > LIMIT_TOOL_PROPERTIES:\n",
    "            return None\n",
    "    \n",
    "    new_entry = {\n",
    "        \"messages\": [],\n",
    "        \"tools\": entry[\"tools\"],\n",
    "        \"tool_calls\": []\n",
    "    }\n",
    "    \n",
    "    for msg in entry[\"messages\"]:\n",
    "        if msg[\"role\"] == \"assistant\" and \"tool_calls\" in msg:\n",
    "            new_entry[\"tool_calls\"] = msg[\"tool_calls\"]\n",
    "        else:\n",
    "            new_entry[\"messages\"].append(msg)\n",
    "    \n",
    "    return new_entry\n",
    "\n",
    "print_status(\"Evaluation conversion function defined\")\n",
    "\n",
    "def convert_dataset_eval(data):\n",
    "    \"\"\"Convert the entire dataset for evaluation by restructuring the data format.\"\"\"\n",
    "    return [result for entry in data if (result := convert_example_eval(entry)) is not None]\n",
    "\n",
    "print_status(\"Evaluation conversion functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0873c030-56b8-4366-9984-24c310327d26",
   "metadata": {},
   "source": [
    "`NOTE:` We have implemented a workaround for a known bug where tool calls freeze the NIM if a tool description includes a function with a larger number of parameters. As such, we have limited the dataset to use examples with available tools having at most 8 parameters. This will be resolved in the next NIM release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6028d6c5-7a67-4b63-a1ef-e93e0177893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation dataset prepared and saved\n"
     ]
    }
   ],
   "source": [
    "test_data_eval = convert_dataset_eval(test_data)\n",
    "save_jsonl(os.path.join(EVALUATION_DATA_ROOT, \"xlam-test-single.jsonl\"), test_data_eval)\n",
    "\n",
    "print_status(\"Evaluation dataset prepared and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675acc69-4d0c-481c-b093-1f1b849019fa",
   "metadata": {},
   "source": [
    "# Part II: LoRA Fine-tuning Using NeMo Customizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96adf453-5f61-435c-9ed2-257cdcebe24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Part II imports completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "print_status(\"Part II imports completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd6ee1a-0789-4724-8f12-5157363ebf9c",
   "metadata": {},
   "source": [
    "### Configure NeMo Microservices Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34fe25",
   "metadata": {},
   "source": [
    "This section includes importing required libraries, configuring endpoints, and performing health checks to ensure that the NeMo Data Store, NIM, and other services are running correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d29578e1-6757-4e89-8f29-a0f6739015c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store endpoint: http://localhost:8001\n",
      "Entity Store endpoint: http://localhost:8002\n",
      "Customizer endpoint: http://localhost:8003\n",
      "Evaluator endpoint: http://localhost:8004\n",
      "Guardrails endpoint: http://localhost:8005\n",
      "NIM endpoint: http://localhost:8006\n",
      "Namespace: arhkp-nemo-helm\n",
      "Base Model for Customization: meta/llama-3.2-1b-instruct\n",
      "✅ NeMo Microservices endpoints configured\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "\n",
    "print(f\"Data Store endpoint: {NDS_URL}\")\n",
    "print(f\"Entity Store endpoint: {ENTITY_STORE_URL}\")\n",
    "print(f\"Customizer endpoint: {CUSTOMIZER_URL}\")\n",
    "print(f\"Evaluator endpoint: {EVALUATOR_URL}\")\n",
    "print(f\"Guardrails endpoint: {GUARDRAILS_URL}\")\n",
    "print(f\"NIM endpoint: {NIM_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Base Model for Customization: {BASE_MODEL}\")\n",
    "\n",
    "print_status(\"NeMo Microservices endpoints configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf28dc",
   "metadata": {},
   "source": [
    "### Configure Path to Prepared data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510bfcb",
   "metadata": {},
   "source": [
    "The following code sets the paths to the prepared dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b905bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data paths validated\n"
     ]
    }
   ],
   "source": [
    "# Path where data preparation notebook saved finetuning and evaluation data\n",
    "DATA_ROOT = os.path.join(os.getcwd(), \"data\")\n",
    "CUSTOMIZATION_DATA_ROOT = os.path.join(DATA_ROOT, \"customization\")\n",
    "VALIDATION_DATA_ROOT = os.path.join(DATA_ROOT, \"validation\")\n",
    "EVALUATION_DATA_ROOT = os.path.join(DATA_ROOT, \"evaluation\")\n",
    "\n",
    "# Sanity checks\n",
    "train_fp = f\"{CUSTOMIZATION_DATA_ROOT}/training.jsonl\"\n",
    "assert os.path.exists(train_fp), f\"The training data at '{train_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "val_fp = f\"{VALIDATION_DATA_ROOT}/validation.jsonl\"\n",
    "assert os.path.exists(val_fp), f\"The validation data at '{val_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "test_fp = f\"{EVALUATION_DATA_ROOT}/xlam-test-single.jsonl\"\n",
    "assert os.path.exists(test_fp), f\"The test data at '{test_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "print_status(\"Data paths validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step-3\"></a>\n",
    "## Step 3: Sanity Test the Customized Model By Running Sample Inference\n",
    "\n",
    "Once the model is customized, its adapter is automatically saved in NeMo Entity Store and is ready to be picked up by NVIDIA NIM.\n",
    "You can test the model by sending a prompt to its NIM endpoint.\n",
    "\n",
    "First, choose one of the examples from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c7805-727f-4265-9248-5babc4a32fc5",
   "metadata": {},
   "source": [
    "### Resource Organization Using Namespace\n",
    "\n",
    "You can use a [namespace](https://developer.nvidia.com/docs/nemo-microservices/manage-entities/namespaces/index.html) to isolate and organize the artifacts in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57ea9a-05b0-4e5e-9455-fc7c2c515ca1",
   "metadata": {},
   "source": [
    "#### Create Namespace\n",
    "\n",
    "Both Data Store and Entity Store use namespaces. The following code creates namespaces for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dff1528-2c7c-4118-8921-f54167ba57ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Namespace creation function defined\n",
      "<Response [409]>\n",
      "<Response [409]>\n"
     ]
    }
   ],
   "source": [
    "def create_namespaces(entity_host, ds_host, namespace):\n",
    "    # Create namespace in Entity Store\n",
    "    entity_store_url = f\"{entity_host}/v1/namespaces\"\n",
    "    resp = requests.post(entity_store_url, json={\"id\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Entity Store during namespace creation: {resp.status_code}\"\n",
    "    print(resp)\n",
    "\n",
    "    # Create namespace in Data Store\n",
    "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
    "    resp = requests.post(nds_url, data={\"namespace\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Data Store during namespace creation: {resp.status_code}\"\n",
    "    print(resp)\n",
    "\n",
    "print_status(\"Namespace creation function defined\")\n",
    "\n",
    "create_namespaces(entity_host=ENTITY_STORE_URL, ds_host=NDS_URL, namespace=NMS_NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057acae8-4d0b-48ee-bd8f-6f98bd941ba6",
   "metadata": {},
   "source": [
    "#### Verify Namespaces\n",
    "\n",
    "The following [Data Store API](https://developer.nvidia.com/docs/nemo-microservices/api/datastore.html) and [Entity Store API](https://developer.nvidia.com/docs/nemo-microservices/api/entity-store.html) list the namespace created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "413166f0-a314-4db0-a341-914495b583ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 201\n",
      "Response JSON: {'namespace': 'arhkp-nemo-helm', 'created_at': '2025-11-07T16:03:21Z', 'updated_at': '2025-11-07T16:04:06Z'}\n",
      "Status Code: 200\n",
      "Response JSON: {'id': 'arhkp-nemo-helm', 'created_at': '2025-11-07T16:03:21.199666', 'updated_at': '2025-11-07T16:03:21.199669', 'description': None, 'project': None, 'custom_fields': {}, 'ownership': None}\n",
      "✅ Namespaces verified\n"
     ]
    }
   ],
   "source": [
    "# Verify Namespace in Data Store\n",
    "response = requests.get(f\"{NDS_URL}/v1/datastore/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Status Code: {response.status_code}\\nResponse JSON: {response.json()}\")\n",
    "\n",
    "# Verify Namespace in Entity Store\n",
    "response = requests.get(f\"{ENTITY_STORE_URL}/v1/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Status Code: {response.status_code}\\nResponse JSON: {response.json()}\")\n",
    "\n",
    "print_status(\"Namespaces verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e6df9-bb6b-4606-80da-e936f68a5d23",
   "metadata": {},
   "source": [
    "**Tips**:\n",
    "* You may generally use `{DATASTORE_HOST}/v1/datastore/namespaces/` and `{ENTITYSTORE_HOST}/v1/namespaces/` GET APIs to list **all** available namespaces.\n",
    "* Send DELETE requests to `{DATASTORE_HOST}/v1/datastore/namespaces/{namespace}` and `{ENTITYSTORE_HOST}/v1/namespaces/{namespace}` APIs to delete a namespace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e83d04-e092-49bd-8769-3422526e135b",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-1\"></a>\n",
    "## Step 1: Upload Data to NeMo Data Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbdb147-9994-4e08-a742-38098f4dc911",
   "metadata": {},
   "source": [
    "The NeMo Data Store supports data management using the Hugging Face `HfApi` Client. \n",
    "\n",
    "**Note that this step does not interact with Hugging Face at all, it just uses the client library to interact with NeMo Data Store.** This is in comparison to the previous notebook, where we used the `load_dataset` API to download the xLAM dataset from Hugging Face's repository.\n",
    "\n",
    "More information can be found in [documentation](https://developer.nvidia.com/docs/nemo-microservices/manage-entities/tutorials/manage-dataset-files.html#set-up-hugging-face-client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d515c-bd7d-4fdb-9c6d-42370d975e69",
   "metadata": {},
   "source": [
    "### 1.1 Create Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a1178a-b516-4f50-96a3-2dee114f9cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Repository ID configured\n"
     ]
    }
   ],
   "source": [
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\"\n",
    "\n",
    "print_status(\"Repository ID configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd240212-3272-419e-b19b-d31d8aede2b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:02:46.351447Z",
     "start_time": "2025-02-28T14:02:46.343156Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset repository 'arhkp-nemo-helm/xlam-ft-dataset' created or already exists\n",
      "✅ Dataset repository created\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub.utils import HfHubHTTPError\n",
    "\n",
    "hf_api = HfApi(endpoint=f\"{NDS_URL}/v1/hf\", token=\"\")\n",
    "\n",
    "# Create repo (or use existing if it already exists)\n",
    "try:\n",
    "    hf_api.create_repo(\n",
    "        repo_id=repo_id,\n",
    "        repo_type='dataset',\n",
    "        exist_ok=True  # Don't raise error if repo already exists\n",
    "    )\n",
    "    print(f\"✅ Dataset repository '{repo_id}' created or already exists\")\n",
    "except HfHubHTTPError as e:\n",
    "    # Handle 409 Conflict (repo already exists) as success\n",
    "    if e.response is not None and e.response.status_code == 409:\n",
    "        print(f\"ℹ️  Dataset repository '{repo_id}' already exists (this is fine)\")\n",
    "    else:\n",
    "        # Re-raise other HTTP errors\n",
    "        print(f\"❌ Error creating repository: {e}\")\n",
    "        raise\n",
    "except Exception as e:\n",
    "    print(f\"❌ Unexpected error creating repository: {e}\")\n",
    "    raise\n",
    "\n",
    "print_status(\"Dataset repository created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ac352a-31b9-4144-ad0f-699fcceebfc2",
   "metadata": {},
   "source": [
    "Next, creating a dataset programmatically requires two steps: uploading and registration. More information can be found in [documentation](https://developer.nvidia.com/docs/nemo-microservices/manage-entities/datasets/create-dataset.html#how-to-create-a-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f927b0-b216-46f9-a8d0-0f9d6836868f",
   "metadata": {},
   "source": [
    "### 1.2 Upload Dataset Files to NeMo Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50be5cec-5df6-4092-82ff-29d39aceaa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset files uploaded\n"
     ]
    }
   ],
   "source": [
    "hf_api.upload_file(path_or_fileobj=train_fp,\n",
    "    path_in_repo=\"training/training.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=val_fp,\n",
    "    path_in_repo=\"validation/validation.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=test_fp,\n",
    "    path_in_repo=\"testing/xlam-test-single.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "print_status(\"Dataset files uploaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d0ab1-69b2-4ca5-9a25-d514cf72b7cd",
   "metadata": {},
   "source": [
    "Other tips:\n",
    "* Take a look at the `path_in_repo` argument above. If there are more than one files in the subfolders:\n",
    "    * All the .jsonl files in `training/` will be merged and used for training by customizer.\n",
    "    * All the .jsonl files in `validation/` will be merged and used for validation by customizer.\n",
    "* NeMo Data Store generally supports data management using the [HfApi API](https://huggingface.co/docs/huggingface_hub/en/package_reference/hf_api). For example, to delete a repo, you may use - \n",
    "```python\n",
    "   hf_api.delete_repo(\n",
    "     repo_id=repo_id,\n",
    "     repo_type=\"dataset\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371c044-56df-412d-9fb3-7e0e191dd3a8",
   "metadata": {},
   "source": [
    "### 1.3 Register the Dataset with NeMo Entity Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab2d1d-17d5-4c7a-9b1b-8f8b1c68204c",
   "metadata": {},
   "source": [
    "To use a dataset for operations such as evaluations and customizations, register a dataset using the `/v1/datasets` endpoint.\n",
    "Register the dataset to refer to it by its namespace and name afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a45fadd-df51-48e0-b30c-336c5bca071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  Dataset 'arhkp-nemo-helm/xlam-ft-dataset' already exists (this is fine)\n",
      "Fetching existing dataset...\n",
      "Existing Dataset:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T16:03:49.525479\",\n",
      "  \"updated_at\": \"2025-11-07T16:03:49.525481\",\n",
      "  \"name\": \"xlam-ft-dataset\",\n",
      "  \"namespace\": \"arhkp-nemo-helm\",\n",
      "  \"description\": \"Tool calling xLAM dataset in OpenAI ChatCompletions format\",\n",
      "  \"format\": null,\n",
      "  \"files_url\": \"hf://datasets/arhkp-nemo-helm/xlam-ft-dataset\",\n",
      "  \"hf_endpoint\": null,\n",
      "  \"split\": null,\n",
      "  \"limit\": null,\n",
      "  \"id\": \"dataset-7wtxegYYziEtq9GqGiyJwo\",\n",
      "  \"project\": \"tool_calling\",\n",
      "  \"custom_fields\": {}\n",
      "}\n",
      "✅ Dataset registered with Entity Store\n"
     ]
    }
   ],
   "source": [
    "resp = requests.post(\n",
    "    url=f\"{ENTITY_STORE_URL}/v1/datasets\",\n",
    "    json={\n",
    "        \"name\": DATASET_NAME,\n",
    "        \"namespace\": NMS_NAMESPACE,\n",
    "        \"description\": \"Tool calling xLAM dataset in OpenAI ChatCompletions format\",\n",
    "        \"files_url\": f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}\",\n",
    "        \"project\": \"tool_calling\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Handle different response statuses\n",
    "if resp.status_code in (200, 201):\n",
    "    print(f\"✅ Dataset '{NMS_NAMESPACE}/{DATASET_NAME}' created successfully\")\n",
    "    dataset_response = resp.json()\n",
    "    print(\"Dataset Response:\")\n",
    "    print(json.dumps(dataset_response, indent=2))\n",
    "    # Also return it so Jupyter displays it\n",
    "    dataset_response\n",
    "elif resp.status_code == 409:\n",
    "    # Dataset already exists - this is fine, fetch it instead\n",
    "    print(f\"ℹ️  Dataset '{NMS_NAMESPACE}/{DATASET_NAME}' already exists (this is fine)\")\n",
    "    print(\"Fetching existing dataset...\")\n",
    "    get_resp = requests.get(url=f\"{ENTITY_STORE_URL}/v1/datasets/{NMS_NAMESPACE}/{DATASET_NAME}\")\n",
    "    if get_resp.status_code == 200:\n",
    "        dataset_response = get_resp.json()\n",
    "        print(\"Existing Dataset:\")\n",
    "        print(json.dumps(dataset_response, indent=2))\n",
    "        # Also return it so Jupyter displays it\n",
    "        dataset_response\n",
    "    else:\n",
    "        print(f\"⚠️  Warning: Could not fetch existing dataset: {get_resp.status_code}\")\n",
    "        print(f\"Response: {get_resp.text}\")\n",
    "else:\n",
    "    # Other error - raise exception\n",
    "    print(f\"❌ Error creating dataset: Status {resp.status_code}\")\n",
    "    print(f\"Response: {resp.text}\")\n",
    "    raise Exception(f\"Failed to create dataset: Status {resp.status_code}, Response: {resp.text}\")\n",
    "\n",
    "print_status(\"Dataset registered with Entity Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a2b58c7-30d7-4c04-b3a5-872032dbf4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files URL: hf://datasets/arhkp-nemo-helm/xlam-ft-dataset\n",
      "✅ Dataset validation completed\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to validate dataset\n",
    "res = requests.get(url=f\"{ENTITY_STORE_URL}/v1/datasets/{NMS_NAMESPACE}/{DATASET_NAME}\")\n",
    "assert res.status_code in (200, 201), f\"Status Code {res.status_code} Failed to fetch dataset {res.text}\"\n",
    "dataset_obj = res.json()\n",
    "\n",
    "print(\"Files URL:\", dataset_obj[\"files_url\"])\n",
    "assert dataset_obj[\"files_url\"] == f\"hf://datasets/{repo_id}\"\n",
    "\n",
    "print_status(\"Dataset validation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7cebbc-8a5f-492d-820c-b3fbbed6fafb",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-2\"></a>\n",
    "## 2. LoRA Customization with NeMo Customizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915c1f5-9687-443f-92cd-cd30b55fc501",
   "metadata": {},
   "source": [
    "### 2.1 Start the Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22fa48",
   "metadata": {},
   "source": [
    "\n",
    "Start the training job by sending a POST request to the `/v1/customization/jobs` endpoint.\n",
    "The following code sets the training parameters and sends the request.\n",
    "\n",
    " **The training job will take approximately 45 minutes to complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2e9678c-2785-4e95-b11b-1f41067bc920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create training job (attempt 1/3)...\n",
      "✅ Training job created successfully!\n",
      "\n",
      "Customization Response:\n",
      "{\n",
      "  \"id\": \"cust-NA7zfXrZXvECNy62ijNM4P\",\n",
      "  \"created_at\": \"2025-11-07T20:40:33.083339\",\n",
      "  \"updated_at\": \"2025-11-07T20:40:33.083341\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"dataset\": \"arhkp-nemo-helm/xlam-ft-dataset\",\n",
      "  \"output_model\": \"arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P\",\n",
      "  \"config\": \"meta/llama-3.2-1b-instruct@v1.0.0+A100\",\n",
      "  \"hyperparameters\": {\n",
      "    \"finetuning_type\": \"lora\",\n",
      "    \"training_type\": \"sft\",\n",
      "    \"batch_size\": 8,\n",
      "    \"epochs\": 1,\n",
      "    \"learning_rate\": 0.0001,\n",
      "    \"lora\": {\n",
      "      \"adapter_dim\": 32,\n",
      "      \"alpha\": 16,\n",
      "      \"adapter_dropout\": 0.1,\n",
      "      \"target_modules\": null\n",
      "    },\n",
      "    \"sequence_packing_enabled\": false\n",
      "  },\n",
      "  \"status\": \"created\",\n",
      "  \"status_details\": {\n",
      "    \"created_at\": \"2025-11-07T20:40:33.485805\",\n",
      "    \"updated_at\": \"2025-11-07T20:40:33.485805\",\n",
      "    \"elapsed_time\": 0.0,\n",
      "    \"steps_completed\": 0,\n",
      "    \"epochs_completed\": 0,\n",
      "    \"percentage_done\": 0.0,\n",
      "    \"status_logs\": [\n",
      "      {\n",
      "        \"updated_at\": \"2025-11-07T20:40:33.485805\",\n",
      "        \"message\": \"created\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"config_snapshot\": {\n",
      "    \"base_model\": \"meta/llama-3.2-1b-instruct\",\n",
      "    \"precision\": \"bf16-mixed\",\n",
      "    \"training_option\": {\n",
      "      \"training_type\": \"sft\",\n",
      "      \"finetuning_type\": \"lora\",\n",
      "      \"num_gpus\": 1,\n",
      "      \"num_nodes\": 1,\n",
      "      \"tensor_parallel_size\": 1,\n",
      "      \"data_parallel_size\": 1,\n",
      "      \"pipeline_parallel_size\": 1,\n",
      "      \"use_sequence_parallel\": false,\n",
      "      \"micro_batch_size\": 1\n",
      "    },\n",
      "    \"max_seq_length\": 4096,\n",
      "    \"prompt_template\": \"{prompt} {completion}\"\n",
      "  }\n",
      "}\n",
      "\n",
      "==================================================\n",
      "✅ Training job created\n"
     ]
    }
   ],
   "source": [
    "headers = {\"wandb-api-key\": WANDB_API_KEY} if WANDB_API_KEY else None\n",
    "\n",
    "training_params = {\n",
    "    \"name\": \"llama-3.2-1b-xlam-ft\",\n",
    "    \"output_model\": f\"{NMS_NAMESPACE}/llama-3.2-1b-xlam-run1\",\n",
    "    \"config\": f\"{BASE_MODEL}@{BASE_MODEL_VERSION}\",\n",
    "    \"dataset\": {\"name\": DATASET_NAME, \"namespace\" : NMS_NAMESPACE},\n",
    "    \"hyperparameters\": {\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 8,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"lora\": {\n",
    "            \"adapter_dim\": 32,\n",
    "            \"adapter_dropout\": 0.1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create training job with retry logic\n",
    "max_retries = 3\n",
    "retry_delay = 2\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        print(f\"Attempting to create training job (attempt {attempt + 1}/{max_retries})...\")\n",
    "        resp = requests.post(\n",
    "            f\"{CUSTOMIZER_URL}/v1/customization/jobs\", \n",
    "            json=training_params, \n",
    "            headers=headers,\n",
    "            timeout=30  # 30 second timeout\n",
    "        )\n",
    "        \n",
    "        # Check response status\n",
    "        if resp.status_code not in (200, 201):\n",
    "            print(f\"❌ Error creating training job: Status {resp.status_code}\")\n",
    "            print(f\"Response: {resp.text}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                continue\n",
    "            raise Exception(f\"Failed to create training job: {resp.text}\")\n",
    "        \n",
    "        # Success!\n",
    "        customization = resp.json()\n",
    "        \n",
    "        # Explicitly print the customization response\n",
    "        print(\"✅ Training job created successfully!\")\n",
    "        print(\"\\nCustomization Response:\")\n",
    "        print(json.dumps(customization, indent=2))\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        # Also return it so Jupyter displays it\n",
    "        customization\n",
    "        \n",
    "        print_status(\"Training job created\")\n",
    "        break\n",
    "        \n",
    "    except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:\n",
    "        print(f\"⚠️ Connection error (attempt {attempt + 1}/{max_retries}): {e}\")\n",
    "        if attempt < max_retries - 1:\n",
    "            print(f\"Retrying in {retry_delay} seconds...\")\n",
    "            print(\"💡 Tip: Make sure port-forwards are running!\")\n",
    "            time.sleep(retry_delay)\n",
    "        else:\n",
    "            raise Exception(f\"Failed to connect to Customizer after {max_retries} attempts. Check port-forwards!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69131ef8",
   "metadata": {},
   "source": [
    "The following code sets variables for storing the job ID and customized model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57eb5ae6-9b3e-4915-8242-34b65b0c0680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Job ID and customized model name stored\n"
     ]
    }
   ],
   "source": [
    "# To track status\n",
    "JOB_ID = customization[\"id\"]\n",
    "\n",
    "# This will be the name of the model that will be used to send inference queries to\n",
    "CUSTOMIZED_MODEL = customization[\"output_model\"]\n",
    "\n",
    "print_status(\"Job ID and customized model name stored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169153d-2ff0-4b34-9a3d-236ecedb7a5d",
   "metadata": {},
   "source": [
    "**Tips**:\n",
    "* If you configured the NeMo Customizer microservice with your own [Weights & Biases (WandB)](https://wandb.ai/) API key, you can find the training graphs and logs in your WandB account, \"nvidia-nemo-customizer\" project. Your run ID is similar to your customization `JOB_ID`.\n",
    "  \n",
    "* To cancel a job that you scheduled incorrectly, run the following code.\n",
    "  \n",
    "  ```python\n",
    "  requests.post(f\"{CUSTOMIZER_URL}/v1/customization/jobs/{JOB_ID}/cancel\")\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab1b3b7-5e0d-4bbb-a7cb-476e0abb298b",
   "metadata": {},
   "source": [
    "### 2.2 Get Job Status\n",
    "\n",
    "Get the job status by sending a GET request to the `/v1/customization/jobs/{JOB_ID}/status` endpoint.\n",
    "The following code sets the job ID and sends the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "900f28fb-fb8e-4d57-88d7-6c09699523e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response JSON: {\n",
      "    \"created_at\": \"2025-11-07T20:40:33.485805\",\n",
      "    \"updated_at\": \"2025-11-07T20:40:33.485805\",\n",
      "    \"elapsed_time\": 0.0,\n",
      "    \"status\": \"pending\",\n",
      "    \"steps_per_epoch\": null,\n",
      "    \"steps_completed\": 0,\n",
      "    \"epochs_completed\": 0,\n",
      "    \"percentage_done\": 0.0,\n",
      "    \"best_epoch\": null,\n",
      "    \"train_loss\": null,\n",
      "    \"val_loss\": null,\n",
      "    \"metrics\": null,\n",
      "    \"status_logs\": [\n",
      "        {\n",
      "            \"updated_at\": \"2025-11-07T20:40:33.485805\",\n",
      "            \"message\": \"created\",\n",
      "            \"detail\": null\n",
      "        },\n",
      "        {\n",
      "            \"updated_at\": \"2025-11-07T20:40:33.485805\",\n",
      "            \"message\": \"TrainingJobPending\",\n",
      "            \"detail\": \"The training job is pending\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "✅ Job status retrieved\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(f\"{CUSTOMIZER_URL}/v1/customization/jobs/{JOB_ID}/status\")\n",
    "\n",
    "assert response.status_code == 200, (\n",
    "    f\"Status Code {response.status_code}: Failed to get job status. Response: {response.text}\"\n",
    ")\n",
    "print(\"Response JSON:\", json.dumps(response.json(), indent=4))\n",
    "\n",
    "print_status(\"Job status retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b721be-8ca0-4e8f-99a7-5eb12ea1b47f",
   "metadata": {},
   "source": [
    "**IMPORTANT:** Monitor the job status. Ensure training is completed before proceeding by observing the `percentage_done` key in the response frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec56031-ec55-4cec-9f65-b34b87818e01",
   "metadata": {},
   "source": [
    "### 2.3 Validate Availability of Custom Model\n",
    "The following NeMo Entity Store API should display the model when the training job is complete.\n",
    "The list below shows all models filtered by your namespace and sorted by the latest first.\n",
    "For more information about this API, see the [NeMo Entity Store API reference](https://developer.nvidia.com/docs/nemo-microservices/api/entity-store.html).\n",
    "With the following code, you can find all customized models, including the one trained in the previous cells.\n",
    "Look for the `name` fields in the output, which should match your `CUSTOMIZED_MODEL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebad3944-70d5-4b23-9a38-a83774bf20c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response JSON: {\n",
      "    \"object\": \"list\",\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"created_at\": \"2025-11-07T20:40:33.523564\",\n",
      "            \"updated_at\": \"2025-11-07T20:40:33.523567\",\n",
      "            \"name\": \"llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P\",\n",
      "            \"namespace\": \"arhkp-nemo-helm\",\n",
      "            \"description\": \"None\",\n",
      "            \"spec\": {\n",
      "                \"num_parameters\": 1000000000,\n",
      "                \"context_size\": 4096,\n",
      "                \"num_virtual_tokens\": 0,\n",
      "                \"is_chat\": false\n",
      "            },\n",
      "            \"artifact\": {\n",
      "                \"gpu_arch\": \"Ampere\",\n",
      "                \"precision\": \"bf16-mixed\",\n",
      "                \"tensor_parallelism\": 1,\n",
      "                \"backend_engine\": \"nemo\",\n",
      "                \"status\": \"created\",\n",
      "                \"files_url\": \"hf://arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P\"\n",
      "            },\n",
      "            \"base_model\": \"meta/llama-3.2-1b-instruct\",\n",
      "            \"peft\": {\n",
      "                \"finetuning_type\": \"lora\"\n",
      "            },\n",
      "            \"schema_version\": \"1.0\",\n",
      "            \"custom_fields\": {}\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2025-11-07T19:42:17.167683\",\n",
      "            \"updated_at\": \"2025-11-07T19:42:17.167685\",\n",
      "            \"name\": \"llama-3.2-1b-xlam-run1@cust-6eiBhrm55cog2N6qyszqGj\",\n",
      "            \"namespace\": \"arhkp-nemo-helm\",\n",
      "            \"description\": \"None\",\n",
      "            \"spec\": {\n",
      "                \"num_parameters\": 1000000000,\n",
      "                \"context_size\": 4096,\n",
      "                \"num_virtual_tokens\": 0,\n",
      "                \"is_chat\": true\n",
      "            },\n",
      "            \"artifact\": {\n",
      "                \"gpu_arch\": \"Ampere\",\n",
      "                \"precision\": \"bf16-mixed\",\n",
      "                \"tensor_parallelism\": 1,\n",
      "                \"backend_engine\": \"nemo\",\n",
      "                \"status\": \"upload_completed\",\n",
      "                \"files_url\": \"hf://arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-6eiBhrm55cog2N6qyszqGj\"\n",
      "            },\n",
      "            \"base_model\": \"meta/llama-3.2-1b-instruct\",\n",
      "            \"peft\": {\n",
      "                \"finetuning_type\": \"lora\"\n",
      "            },\n",
      "            \"schema_version\": \"1.0\",\n",
      "            \"custom_fields\": {}\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2025-11-07T18:18:23.700041\",\n",
      "            \"updated_at\": \"2025-11-07T18:18:23.700044\",\n",
      "            \"name\": \"llama-3.2-1b-xlam-run1@cust-NByPmnsbnhzPJFYJK9Cr3K\",\n",
      "            \"namespace\": \"arhkp-nemo-helm\",\n",
      "            \"description\": \"None\",\n",
      "            \"spec\": {\n",
      "                \"num_parameters\": 1000000000,\n",
      "                \"context_size\": 4096,\n",
      "                \"num_virtual_tokens\": 0,\n",
      "                \"is_chat\": true\n",
      "            },\n",
      "            \"artifact\": {\n",
      "                \"gpu_arch\": \"Ampere\",\n",
      "                \"precision\": \"bf16-mixed\",\n",
      "                \"tensor_parallelism\": 1,\n",
      "                \"backend_engine\": \"nemo\",\n",
      "                \"status\": \"upload_completed\",\n",
      "                \"files_url\": \"hf://arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NByPmnsbnhzPJFYJK9Cr3K\"\n",
      "            },\n",
      "            \"base_model\": \"meta/llama-3.2-1b-instruct\",\n",
      "            \"peft\": {\n",
      "                \"finetuning_type\": \"lora\"\n",
      "            },\n",
      "            \"schema_version\": \"1.0\",\n",
      "            \"custom_fields\": {}\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2025-11-07T17:23:16.678540\",\n",
      "            \"updated_at\": \"2025-11-07T17:23:16.678544\",\n",
      "            \"name\": \"llama-3.2-1b-xlam-run1@cust-BJ2vu5qazwWKNC649EniKg\",\n",
      "            \"namespace\": \"arhkp-nemo-helm\",\n",
      "            \"description\": \"None\",\n",
      "            \"spec\": {\n",
      "                \"num_parameters\": 1000000000,\n",
      "                \"context_size\": 4096,\n",
      "                \"num_virtual_tokens\": 0,\n",
      "                \"is_chat\": true\n",
      "            },\n",
      "            \"artifact\": {\n",
      "                \"gpu_arch\": \"Ampere\",\n",
      "                \"precision\": \"bf16-mixed\",\n",
      "                \"tensor_parallelism\": 1,\n",
      "                \"backend_engine\": \"nemo\",\n",
      "                \"status\": \"upload_completed\",\n",
      "                \"files_url\": \"hf://arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-BJ2vu5qazwWKNC649EniKg\"\n",
      "            },\n",
      "            \"base_model\": \"meta/llama-3.2-1b-instruct\",\n",
      "            \"peft\": {\n",
      "                \"finetuning_type\": \"lora\"\n",
      "            },\n",
      "            \"schema_version\": \"1.0\",\n",
      "            \"custom_fields\": {}\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2025-11-07T16:40:06.831782\",\n",
      "            \"updated_at\": \"2025-11-07T16:40:06.831785\",\n",
      "            \"name\": \"llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\",\n",
      "            \"namespace\": \"arhkp-nemo-helm\",\n",
      "            \"description\": \"None\",\n",
      "            \"spec\": {\n",
      "                \"num_parameters\": 1000000000,\n",
      "                \"context_size\": 4096,\n",
      "                \"num_virtual_tokens\": 0,\n",
      "                \"is_chat\": true\n",
      "            },\n",
      "            \"artifact\": {\n",
      "                \"gpu_arch\": \"Ampere\",\n",
      "                \"precision\": \"bf16-mixed\",\n",
      "                \"tensor_parallelism\": 1,\n",
      "                \"backend_engine\": \"nemo\",\n",
      "                \"status\": \"upload_completed\",\n",
      "                \"files_url\": \"hf://arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\"\n",
      "            },\n",
      "            \"base_model\": \"meta/llama-3.2-1b-instruct\",\n",
      "            \"peft\": {\n",
      "                \"finetuning_type\": \"lora\"\n",
      "            },\n",
      "            \"schema_version\": \"1.0\",\n",
      "            \"custom_fields\": {}\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2025-11-07T16:04:07.771555\",\n",
      "            \"updated_at\": \"2025-11-07T16:04:07.771558\",\n",
      "            \"name\": \"llama-3.2-1b-xlam-run1@cust-TZWQBJg89tobeajjUEuwYD\",\n",
      "            \"namespace\": \"arhkp-nemo-helm\",\n",
      "            \"description\": \"None\",\n",
      "            \"spec\": {\n",
      "                \"num_parameters\": 1000000000,\n",
      "                \"context_size\": 4096,\n",
      "                \"num_virtual_tokens\": 0,\n",
      "                \"is_chat\": false\n",
      "            },\n",
      "            \"artifact\": {\n",
      "                \"gpu_arch\": \"Ampere\",\n",
      "                \"precision\": \"bf16-mixed\",\n",
      "                \"tensor_parallelism\": 1,\n",
      "                \"backend_engine\": \"nemo\",\n",
      "                \"status\": \"created\",\n",
      "                \"files_url\": \"hf://arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-TZWQBJg89tobeajjUEuwYD\"\n",
      "            },\n",
      "            \"base_model\": \"meta/llama-3.2-1b-instruct\",\n",
      "            \"peft\": {\n",
      "                \"finetuning_type\": \"lora\"\n",
      "            },\n",
      "            \"schema_version\": \"1.0\",\n",
      "            \"custom_fields\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"pagination\": {\n",
      "        \"page\": 1,\n",
      "        \"page_size\": 1000,\n",
      "        \"current_page_size\": 6,\n",
      "        \"total_pages\": 1,\n",
      "        \"total_results\": 6\n",
      "    },\n",
      "    \"sort\": \"-created_at\",\n",
      "    \"filter\": {\n",
      "        \"namespace\": \"arhkp-nemo-helm\"\n",
      "    }\n",
      "}\n",
      "✅ Job status retrieved\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(f\"{ENTITY_STORE_URL}/v1/models\", params={\"filter[namespace]\": NMS_NAMESPACE, \"sort\" : \"-created_at\"})\n",
    "\n",
    "assert response.status_code == 200, f\"Status Code {response.status_code}: Request failed. Response: {response.text}\"\n",
    "print(\"Response JSON:\", json.dumps(response.json(), indent=4))\n",
    "\n",
    "print_status(\"Job status retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1221f1e-04f6-4ceb-a844-e9ea1e94f0d0",
   "metadata": {},
   "source": [
    "**Tips**:\n",
    "\n",
    "* You can also find the model with its name directly:\n",
    "  ```python\n",
    "    # To get specifically the custom model, you may use the following API -\n",
    "    response = requests.get(f\"{ENTITY_STORE_URL}/v1/models/{CUSTOMIZED_MODEL}\")\n",
    "    \n",
    "    assert response.status_code == 200, f\"Status Code {response.status_code}: Request failed. Response: {response.text}\"\n",
    "    print(\"Response JSON:\", json.dumps(response.json(), indent=4))\n",
    "  ```\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43d7dc-f442-41cb-a743-7fd5efd4bf6c",
   "metadata": {},
   "source": [
    "NVIDIA NIM directly picks up the LoRA adapters from NeMo Entity Store. You can also query the NIM endpoint to look for it, as shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43026f8a-3b98-4aa6-b4c6-7441862863fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 models in namespace 'arhkp-nemo-helm':\n",
      "  - llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P\n",
      "  - llama-3.2-1b-xlam-run1@cust-6eiBhrm55cog2N6qyszqGj\n",
      "  - llama-3.2-1b-xlam-run1@cust-NByPmnsbnhzPJFYJK9Cr3K\n",
      "  - llama-3.2-1b-xlam-run1@cust-BJ2vu5qazwWKNC649EniKg\n",
      "  - llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\n",
      "  - llama-3.2-1b-xlam-run1@cust-TZWQBJg89tobeajjUEuwYD\n",
      "\n",
      "✅ Custom model found in Entity Store!\n",
      "   Full name: arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P\n",
      "   Entity Store name: llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P\n",
      "✅ Custom model availability checked\n"
     ]
    }
   ],
   "source": [
    "# Check if the custom LoRA model is available in Entity Store\n",
    "# Note: Custom LoRA models are registered in Entity Store, not directly in NIM's model list\n",
    "response = requests.get(f\"{ENTITY_STORE_URL}/v1/models\", params={\"filter[namespace]\": NMS_NAMESPACE, \"sort\": \"-created_at\"})\n",
    "\n",
    "assert response.status_code == 200, f\"Status Code {response.status_code}: Request failed. Response: {response.text}\"\n",
    "\n",
    "models_data = response.json().get(\"data\", [])\n",
    "# Extract model names (can be in 'name' or 'id' field)\n",
    "model_names = []\n",
    "for model in models_data:\n",
    "    # Try 'name' first, then 'id'\n",
    "    model_name = model.get(\"name\") or model.get(\"id\", \"\")\n",
    "    if model_name:\n",
    "        model_names.append(model_name)\n",
    "\n",
    "print(f\"Found {len(model_names)} models in namespace '{NMS_NAMESPACE}':\")\n",
    "for name in model_names[:10]:  # Show first 10\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "# Extract just the model name part (without namespace) for comparison\n",
    "# CUSTOMIZED_MODEL format: \"namespace/model-name\" or just \"model-name\"\n",
    "customized_model_name = CUSTOMIZED_MODEL.split(\"/\")[-1] if \"/\" in CUSTOMIZED_MODEL else CUSTOMIZED_MODEL\n",
    "\n",
    "# Check if our custom model is in the list (compare both with and without namespace)\n",
    "model_found = False\n",
    "for model_name in model_names:\n",
    "    # Compare both full name and just the model part (without namespace)\n",
    "    model_name_only = model_name.split(\"/\")[-1] if \"/\" in model_name else model_name\n",
    "    if CUSTOMIZED_MODEL == model_name or customized_model_name == model_name_only:\n",
    "        model_found = True\n",
    "        print(f\"\\n✅ Custom model found in Entity Store!\")\n",
    "        print(f\"   Full name: {CUSTOMIZED_MODEL}\")\n",
    "        print(f\"   Entity Store name: {model_name}\")\n",
    "        break\n",
    "\n",
    "if not model_found:\n",
    "    print(f\"\\n⚠️ Custom model '{CUSTOMIZED_MODEL}' not found in the list.\")\n",
    "    print(\"This is normal if the training job is still running or just completed.\")\n",
    "    print(\"The model will appear in Entity Store once training completes and the model is uploaded.\")\n",
    "    \n",
    "    # Try to get the model directly by name (it might exist but not be in the list)\n",
    "    try:\n",
    "        direct_response = requests.get(f\"{ENTITY_STORE_URL}/v1/models/{CUSTOMIZED_MODEL}\")\n",
    "        if direct_response.status_code == 200:\n",
    "            print(f\"✅ However, the model is accessible directly at: {CUSTOMIZED_MODEL}\")\n",
    "            print(\"This means training completed and the model is available!\")\n",
    "            model_found = True\n",
    "        else:\n",
    "            print(f\"⏳ Model not yet available. Training may still be in progress.\")\n",
    "            print(f\"   Check training job status to see if it's completed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Could not check model directly: {e}\")\n",
    "\n",
    "print_status(\"Custom model availability checked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0f9c5-98b2-476e-aa2f-3af69c5e45f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step-3\"></a>\n",
    "## Step 3: Sanity Test the Customized Model By Running Sample Inference\n",
    "\n",
    "Once the model is customized, its adapter is automatically saved in NeMo Entity Store and is ready to be picked up by NVIDIA NIM.\n",
    "You can test the model by sending a prompt to its NIM endpoint.\n",
    "\n",
    "First, choose one of the examples from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4ada2-2ccb-4f82-bb7c-23134e67a7e0",
   "metadata": {},
   "source": [
    "### 3.1 Get Test Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3f7da82-cbbb-43a4-999b-2adad2cea227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 713 examples in the test set\n",
      "✅ Test data loaded\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl(file_path):\n",
    "    \"\"\"Reads a JSON Lines file and yields parsed JSON objects\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "test_data = list(read_jsonl(test_fp))\n",
    "\n",
    "print(f\"There are {len(test_data)} examples in the test set\")\n",
    "\n",
    "print_status(\"Test data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92f74f62-8427-438e-b1df-15fe53ce330c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test sample inspected\n"
     ]
    }
   ],
   "source": [
    "# Randomly choose\n",
    "test_sample = random.choice(test_data)\n",
    "\n",
    "# Visualize the inputs to the LLM - user query and available tools\n",
    "test_sample['messages'], test_sample['tools']\n",
    "\n",
    "print_status(\"Test sample inspected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8577c4b-e0f6-4596-9bbc-33c47ca424aa",
   "metadata": {},
   "source": [
    "### 3.2 Send an Inference Call to NIM\n",
    "\n",
    "NIM exposes an OpenAI-compatible completions API endpoint, which you can query using the `OpenAI` client library as shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af83f794-f8cc-4cc8-8d42-a031dfb7f9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking if custom model is available in NIM: arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P\n",
      "📋 Available models in NIM: 5\n",
      "   - meta/llama-3.2-1b-instruct\n",
      "   - arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\n",
      "   - arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-BJ2vu5qazwWKNC649EniKg\n",
      "   - arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NByPmnsbnhzPJFYJK9Cr3K\n",
      "   - arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-6eiBhrm55cog2N6qyszqGj\n",
      "\n",
      "⚠️  Warning: Custom model 'arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P' is not yet loaded in NIM\n",
      "Available custom models in NIM:\n",
      "   Found similar models: ['arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe', 'arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-BJ2vu5qazwWKNC649EniKg', 'arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NByPmnsbnhzPJFYJK9Cr3K', 'arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-6eiBhrm55cog2N6qyszqGj']\n",
      "\n",
      "💡 Options:\n",
      "   1. Use one of the available models: arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\n",
      "   2. Wait for the model to be loaded into NIM (this happens automatically)\n",
      "   3. Use the base model for now: meta/llama-3.2-1b-instruct\n",
      "\n",
      "🔄 Using available custom model: arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\n",
      "\n",
      "🚀 Creating inference client and sending request...\n",
      "✅ Inference successful using model: arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\n",
      "📊 Tool calls: 1\n",
      "✅ Custom model inference completed\n"
     ]
    }
   ],
   "source": [
    "# First, check if the custom model is available in NIM\n",
    "print(f\"🔍 Checking if custom model is available in NIM: {CUSTOMIZED_MODEL}\")\n",
    "nim_models_resp = requests.get(f\"{NIM_URL}/v1/models\")\n",
    "if nim_models_resp.status_code == 200:\n",
    "    nim_models = nim_models_resp.json().get(\"data\", [])\n",
    "    nim_model_ids = [m.get(\"id\") for m in nim_models]\n",
    "    print(f\"📋 Available models in NIM: {len(nim_model_ids)}\")\n",
    "    for model_id in nim_model_ids[:5]:  # Show first 5\n",
    "        print(f\"   - {model_id}\")\n",
    "    \n",
    "    if CUSTOMIZED_MODEL not in nim_model_ids:\n",
    "        print(f\"\\n⚠️  Warning: Custom model '{CUSTOMIZED_MODEL}' is not yet loaded in NIM\")\n",
    "        print(\"Available custom models in NIM:\")\n",
    "        custom_models = [m for m in nim_model_ids if CUSTOMIZED_MODEL.split('/')[-1].split('@')[0] in m]\n",
    "        if custom_models:\n",
    "            print(f\"   Found similar models: {custom_models}\")\n",
    "            print(f\"\\n💡 Options:\")\n",
    "            print(f\"   1. Use one of the available models: {custom_models[0] if custom_models else 'None'}\")\n",
    "            print(f\"   2. Wait for the model to be loaded into NIM (this happens automatically)\")\n",
    "            print(f\"   3. Use the base model for now: {BASE_MODEL}\")\n",
    "            \n",
    "            # Try to use the first available custom model if it exists\n",
    "            if custom_models:\n",
    "                print(f\"\\n🔄 Using available custom model: {custom_models[0]}\")\n",
    "                model_to_use = custom_models[0]\n",
    "            else:\n",
    "                print(f\"\\n🔄 Falling back to base model: {BASE_MODEL}\")\n",
    "                model_to_use = BASE_MODEL\n",
    "        else:\n",
    "            print(f\"\\n🔄 Custom model not loaded yet. Using base model: {BASE_MODEL}\")\n",
    "            model_to_use = BASE_MODEL\n",
    "    else:\n",
    "        print(f\"✅ Custom model is available in NIM!\")\n",
    "        model_to_use = CUSTOMIZED_MODEL\n",
    "else:\n",
    "    print(f\"⚠️  Could not check NIM models: {nim_models_resp.status_code}\")\n",
    "    print(f\"   Using requested model: {CUSTOMIZED_MODEL}\")\n",
    "    model_to_use = CUSTOMIZED_MODEL\n",
    "\n",
    "print(f\"\\n🚀 Creating inference client and sending request...\")\n",
    "inference_client = OpenAI(\n",
    "  base_url = f\"{NIM_URL}/v1\",\n",
    "  api_key = \"None\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    completion = inference_client.chat.completions.create(\n",
    "      model = model_to_use,\n",
    "      messages = test_sample[\"messages\"],\n",
    "      tools = test_sample[\"tools\"],\n",
    "      tool_choice = 'auto',\n",
    "      temperature = 0.1,\n",
    "      top_p = 0.7,\n",
    "      max_tokens = 512,\n",
    "      stream = False\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Inference successful using model: {model_to_use}\")\n",
    "    if completion.choices[0].message.tool_calls:\n",
    "        print(f\"📊 Tool calls: {len(completion.choices[0].message.tool_calls)}\")\n",
    "        completion.choices[0].message.tool_calls\n",
    "    else:\n",
    "        print(\"📊 No tool calls in response\")\n",
    "        completion.choices[0].message\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during inference: {e}\")\n",
    "    print(f\"\\n💡 Troubleshooting:\")\n",
    "    print(f\"   1. Check if NIM service is running: curl {NIM_URL}/health\")\n",
    "    print(f\"   2. Verify model is loaded: curl {NIM_URL}/v1/models\")\n",
    "    print(f\"   3. Check if model exists in Entity Store\")\n",
    "    raise\n",
    "\n",
    "print_status(\"Custom model inference completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bb488-3bd9-4092-9c3a-f77f904606e4",
   "metadata": {},
   "source": [
    "Given that the fine-tuning job was successful, you can get an inference result comparable to the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcbdaedf-6fb4-41d6-8297-b7480c907892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ground truth tool calls retrieved\n"
     ]
    }
   ],
   "source": [
    "# The ground truth answer\n",
    "test_sample['tool_calls']\n",
    "\n",
    "print_status(\"Ground truth tool calls retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f0fce4-3169-4ac4-8785-8a8f15959594",
   "metadata": {},
   "source": [
    "### 3.3 Take Note of Your Custom Model Name\n",
    "\n",
    "Take note of your custom model name, as you will use it to run evaluations in the subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36398168-1051-4e54-ac3e-7a3e406f393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of your custom model is: arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P\n",
      "✅ Custom model inference completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name of your custom model is: {CUSTOMIZED_MODEL}\")\n",
    "\n",
    "print_status(\"Custom model inference completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051ba77-9d36-477c-9969-b07c4b776b6f",
   "metadata": {},
   "source": [
    "# Part III: Model Evaluation Using NeMo Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5adb3981-0171-4080-96e8-245954b63dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Part III imports completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from time import sleep, time\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "print_status(\"Part III imports completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f9282-abec-401d-9143-076a3977d9a9",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-1\"></a>\n",
    "## Step 1: Establish Baseline Accuracy Benchmark\n",
    "\n",
    "First, we’ll assess the accuracy of the 'off-the-shelf' base model—pristine, untouched, and blissfully unaware of the transformative magic that is fine-tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147cf266-5e90-4b81-92a5-53b7981c47be",
   "metadata": {},
   "source": [
    "### 1.1: Create an Evaluation Config Object\n",
    "Create an evaluation configuration object for NeMo Evaluator. For more information on various parameters, refer to the [NeMo Evaluator configuration](https://developer.nvidia.com/docs/nemo-microservices/evaluate/evaluation-configs.html) in the NeMo microservices documentation.\n",
    "\n",
    "\n",
    "* The `tasks.custom-tool-calling.dataset.files_url` is used to indicate which test file to use. Note that it's required to upload this to the NeMo Data Store and register with Entity store before using.\n",
    "* The `tasks.dataset.limit` argument below specifies how big a subset of test data to run the evaluation on\n",
    "* The evaluation metric `tasks.metrics.tool-calling-accuracy` reports `function_name_accuracy` and `function_name_and_args_accuracy` numbers, which are as their names imply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84e2e116-ed60-4e88-970b-f0d09d4a258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation configuration created\n"
     ]
    }
   ],
   "source": [
    "simple_tool_calling_eval_config = {\n",
    "    \"type\": \"custom\",\n",
    "    \"tasks\": {\n",
    "        \"custom-tool-calling\": {\n",
    "            \"type\": \"chat-completion\",\n",
    "            \"dataset\": {\n",
    "                \"files_url\": f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}/testing/xlam-test-single.jsonl\",\n",
    "                \"limit\": 50\n",
    "            },\n",
    "            \"params\": {\n",
    "                \"template\": {\n",
    "                    \"messages\": \"{{ item.messages | tojson}}\",\n",
    "                    \"tools\": \"{{ item.tools | tojson }}\",\n",
    "                    \"tool_choice\": \"auto\"\n",
    "                }\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"tool-calling-accuracy\": {\n",
    "                    \"type\": \"tool-calling\",\n",
    "                    \"params\": {\"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print_status(\"Evaluation configuration created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7a49e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  Creating evaluation target with cluster URL: http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\n",
      "   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\n",
      "   (Using /v1/chat/completions endpoint for chat models)\n",
      "Evaluation Target Created:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:40:36.312684\",\n",
      "  \"updated_at\": \"2025-11-07T20:40:36.312684\",\n",
      "  \"name\": \"llama-3-1b-instruct\",\n",
      "  \"namespace\": \"arhkp-nemo-helm\",\n",
      "  \"type\": \"model\",\n",
      "  \"model\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"model-BQa8x9TVNnCcK8kisfv7s7\",\n",
      "    \"type_prefix\": \"model\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"created_at\": \"2025-11-07T20:40:36.312526\",\n",
      "    \"updated_at\": \"2025-11-07T20:40:36.312528\",\n",
      "    \"custom_fields\": {},\n",
      "    \"name\": \"model-BQa8x9TVNnCcK8kisfv7s7\",\n",
      "    \"version_id\": \"main\",\n",
      "    \"version_tags\": [],\n",
      "    \"api_endpoint\": {\n",
      "      \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "      \"model_id\": \"meta/llama-3.2-1b-instruct\",\n",
      "      \"format\": \"nim\"\n",
      "    }\n",
      "  },\n",
      "  \"id\": \"eval-target-V6B17rKsKvtsPYeDebCox8\",\n",
      "  \"custom_fields\": {}\n",
      "}\n",
      "✅ Evaluation target created\n"
     ]
    }
   ],
   "source": [
    "# Delete evaluation target (if it exists)\n",
    "res = requests.delete(f\"{EVALUATOR_URL}/v1/evaluation/targets/{NMS_NAMESPACE}/llama-3-1b-instruct\")\n",
    "# Ignore 404 errors (target might not exist)\n",
    "if res.status_code not in (200, 404):\n",
    "    print(f\"⚠️ Warning: Could not delete existing target: {res.status_code}\")\n",
    "\n",
    "## Create evaluation target\n",
    "# IMPORTANT: Use cluster-internal URL (NIM_URL_CLUSTER) for evaluation targets\n",
    "# because evaluation jobs run inside the cluster and can't access localhost port-forwards\n",
    "# Reload config module to get the latest NIM_URL_CLUSTER value\n",
    "import importlib\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import NIM_URL_CLUSTER\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "data = {\n",
    "    \"type\": \"model\",\n",
    "    \"name\": \"llama-3-1b-instruct\",\n",
    "    \"namespace\": NMS_NAMESPACE,  # Use the correct namespace\n",
    "    \"model\": {\n",
    "        \"api_endpoint\": {\n",
    "            \"url\": f\"{NIM_URL_CLUSTER}/v1/chat/completions\",  # Use cluster URL, not localhost. Note: /v1/chat/completions for chat models\n",
    "            \"model_id\": f\"{BASE_MODEL}\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "print(f\"ℹ️  Creating evaluation target with cluster URL: {NIM_URL_CLUSTER}/v1/chat/completions\")\n",
    "print(f\"   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\")\n",
    "print(f\"   (Using /v1/chat/completions endpoint for chat models)\")\n",
    "res = requests.post(f\"{EVALUATOR_URL}/v1/evaluation/targets\", headers=headers, json=data)\n",
    "target_response = res.json()\n",
    "print(\"Evaluation Target Created:\")\n",
    "print(json.dumps(target_response, indent=2))\n",
    "# Also return it so Jupyter displays it\n",
    "target_response\n",
    "\n",
    "print_status(\"Evaluation target created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8007f17-2eb1-477f-b156-5ed1d17d894b",
   "metadata": {},
   "source": [
    "### 1.2: Launch Evaluation Job "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5fbf88",
   "metadata": {},
   "source": [
    "The following code sends a POST request to the NeMo Evaluator API to launch an evaluation job. It uses the evaluation configuration defined in the previous cell and targets the base model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69c5ec90-a189-47d6-9c07-18162b95130d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Job Created:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:40:36.399983\",\n",
      "  \"updated_at\": \"2025-11-07T20:40:36.399983\",\n",
      "  \"id\": \"eval-96vz7ekunvAxvoUnwEHEJ6\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": null,\n",
      "  \"target\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-target-V6B17rKsKvtsPYeDebCox8\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-target\",\n",
      "    \"namespace\": \"arhkp-nemo-helm\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:40:36.312684\",\n",
      "    \"updated_at\": \"2025-11-07T20:40:36.312684\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"llama-3-1b-instruct\",\n",
      "    \"type\": \"model\",\n",
      "    \"cached_outputs\": null,\n",
      "    \"model\": {\n",
      "      \"schema_version\": \"1.0\",\n",
      "      \"id\": \"model-BQa8x9TVNnCcK8kisfv7s7\",\n",
      "      \"description\": null,\n",
      "      \"type_prefix\": \"model\",\n",
      "      \"namespace\": \"default\",\n",
      "      \"project\": null,\n",
      "      \"created_at\": \"2025-11-07T20:40:36.312526\",\n",
      "      \"updated_at\": \"2025-11-07T20:40:36.312528\",\n",
      "      \"custom_fields\": {},\n",
      "      \"ownership\": null,\n",
      "      \"name\": \"model-BQa8x9TVNnCcK8kisfv7s7\",\n",
      "      \"version_id\": \"main\",\n",
      "      \"version_tags\": [],\n",
      "      \"spec\": null,\n",
      "      \"artifact\": null,\n",
      "      \"base_model\": null,\n",
      "      \"api_endpoint\": {\n",
      "        \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "        \"model_id\": \"meta/llama-3.2-1b-instruct\",\n",
      "        \"api_key\": null,\n",
      "        \"format\": \"nim\"\n",
      "      },\n",
      "      \"peft\": null,\n",
      "      \"prompt\": null,\n",
      "      \"guardrails\": null\n",
      "    },\n",
      "    \"retriever\": null,\n",
      "    \"rag\": null,\n",
      "    \"rows\": null,\n",
      "    \"dataset\": null\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-config-KXAUVpoHv8Ysbgbo1dqotY\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-config\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:40:36.399775\",\n",
      "    \"updated_at\": \"2025-11-07T20:40:36.399777\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"eval-config-KXAUVpoHv8Ysbgbo1dqotY\",\n",
      "    \"type\": \"custom\",\n",
      "    \"params\": null,\n",
      "    \"tasks\": {\n",
      "      \"custom-tool-calling\": {\n",
      "        \"type\": \"chat-completion\",\n",
      "        \"params\": {\n",
      "          \"template\": {\n",
      "            \"messages\": \"{{ item.messages | tojson}}\",\n",
      "            \"tools\": \"{{ item.tools | tojson }}\",\n",
      "            \"tool_choice\": \"auto\"\n",
      "          }\n",
      "        },\n",
      "        \"metrics\": {\n",
      "          \"tool-calling-accuracy\": {\n",
      "            \"type\": \"tool-calling\",\n",
      "            \"params\": {\n",
      "              \"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dataset\": {\n",
      "          \"schema_version\": \"1.0\",\n",
      "          \"id\": \"dataset-UpanFc7aDAC2qmmvXPsoVU\",\n",
      "          \"description\": null,\n",
      "          \"type_prefix\": null,\n",
      "          \"namespace\": \"default\",\n",
      "          \"project\": null,\n",
      "          \"created_at\": \"2025-11-07T20:40:36.399807\",\n",
      "          \"updated_at\": \"2025-11-07T20:40:36.399808\",\n",
      "          \"custom_fields\": {},\n",
      "          \"ownership\": null,\n",
      "          \"name\": \"dataset-UpanFc7aDAC2qmmvXPsoVU\",\n",
      "          \"version_id\": \"main\",\n",
      "          \"version_tags\": [],\n",
      "          \"format\": null,\n",
      "          \"files_url\": \"hf://datasets/arhkp-nemo-helm/xlam-ft-dataset/testing/xlam-test-single.jsonl\",\n",
      "          \"hf_endpoint\": null,\n",
      "          \"split\": null,\n",
      "          \"limit\": 50\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"groups\": null\n",
      "  },\n",
      "  \"result\": null,\n",
      "  \"output_files_url\": null,\n",
      "  \"status_details\": {\n",
      "    \"message\": null,\n",
      "    \"task_status\": {},\n",
      "    \"progress\": null\n",
      "  },\n",
      "  \"status\": \"created\",\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n",
      "\n",
      "Job ID: eval-96vz7ekunvAxvoUnwEHEJ6\n",
      "✅ Base model evaluation job created\n"
     ]
    }
   ],
   "source": [
    "res = requests.post(\n",
    "    f\"{EVALUATOR_URL}/v1/evaluation/jobs\",\n",
    "    json={\n",
    "        \"config\": simple_tool_calling_eval_config,\n",
    "        \"target\": f\"{NMS_NAMESPACE}/llama-3-1b-instruct\"  # Use the correct namespace\n",
    "    }\n",
    ")\n",
    "\n",
    "if res.status_code not in (200, 201):\n",
    "    print(f\"❌ Error creating evaluation job: Status {res.status_code}\")\n",
    "    print(f\"Response: {res.text}\")\n",
    "    raise Exception(f\"Failed to create evaluation job: {res.text}\")\n",
    "\n",
    "job_response = res.json()\n",
    "base_eval_job_id = job_response[\"id\"]\n",
    "\n",
    "print(\"Evaluation Job Created:\")\n",
    "print(json.dumps(job_response, indent=2))\n",
    "print(f\"\\nJob ID: {base_eval_job_id}\")\n",
    "\n",
    "# Also return it so Jupyter displays it\n",
    "base_eval_job_id\n",
    "\n",
    "print_status(\"Base model evaluation job created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40974159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Job Status:\n",
      "{\n",
      "  \"message\": null,\n",
      "  \"task_status\": {\n",
      "    \"custom-tool-calling\": \"running\"\n",
      "  },\n",
      "  \"progress\": 0.0\n",
      "}\n",
      "✅ Evaluation job status retrieved\n"
     ]
    }
   ],
   "source": [
    "# Get Job status\n",
    "res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}/status\")\n",
    "\n",
    "# Check response status\n",
    "if res.status_code != 200:\n",
    "    print(f\"❌ Error: Status {res.status_code}\")\n",
    "    print(f\"Response: {res.text}\")\n",
    "    raise Exception(f\"Failed to get evaluation job status: {res.text}\")\n",
    "\n",
    "# Format and print the response\n",
    "job_status = res.json()\n",
    "print(\"Evaluation Job Status:\")\n",
    "print(json.dumps(job_status, indent=2))\n",
    "\n",
    "# Also return it so Jupyter displays it\n",
    "job_status\n",
    "\n",
    "print_status(\"Evaluation job status retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5133e-076c-4560-815a-1ff71901af01",
   "metadata": {},
   "source": [
    "The following code defines a helper function to poll on job status until it finishes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fa0b694-a699-4eb0-903c-9bac8651f9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation job wait function defined\n"
     ]
    }
   ],
   "source": [
    "def wait_eval_job(job_url: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    \"\"\"Helper for waiting an eval job with improved error handling and logging.\"\"\"\n",
    "    start_time = time()\n",
    "    \n",
    "    # Initial status check\n",
    "    print(f\"🔍 Checking evaluation job status at: {job_url}\")\n",
    "    res = requests.get(job_url)\n",
    "    \n",
    "    if res.status_code != 200:\n",
    "        print(f\"❌ Error: Failed to get job status. HTTP {res.status_code}\")\n",
    "        print(f\"Response: {res.text}\")\n",
    "        raise Exception(f\"Failed to get evaluation job status: HTTP {res.status_code}, Response: {res.text}\")\n",
    "    \n",
    "    try:\n",
    "        job_data = res.json()\n",
    "        status = job_data.get(\"status\", \"unknown\")\n",
    "        print(f\"📊 Initial job status: {status}\")\n",
    "        \n",
    "        # Print full job data for debugging\n",
    "        print(\"\\nInitial Job Data:\")\n",
    "        print(json.dumps(job_data, indent=2))\n",
    "    except (KeyError, ValueError) as e:\n",
    "        print(f\"❌ Error parsing job response: {e}\")\n",
    "        print(f\"Response text: {res.text}\")\n",
    "        raise Exception(f\"Failed to parse job status from response: {e}\")\n",
    "\n",
    "    # Check if job is already in a terminal state (failed, completed, etc.)\n",
    "    if status == \"failed\":\n",
    "        print(f\"\\n❌ Job is already in 'failed' state!\")\n",
    "        print(\"\\nFull job data for debugging:\")\n",
    "        print(json.dumps(job_data, indent=2))\n",
    "        \n",
    "        # Extract error details if available\n",
    "        error_details = job_data.get(\"status_details\", {})\n",
    "        if error_details:\n",
    "            print(\"\\nError Details:\")\n",
    "            print(json.dumps(error_details, indent=2))\n",
    "        \n",
    "        print(\"\\n💡 To investigate the failure, check:\")\n",
    "        print(\"   1. Evaluator service logs:\")\n",
    "        print(\"      oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=200\")\n",
    "        print(\"   2. Evaluation job pods (if any):\")\n",
    "        print(\"      oc get pods -n arhkp-nemo-helm | grep -E 'eval|evaluation'\")\n",
    "        print(\"   3. Evaluator pod status:\")\n",
    "        print(\"      oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "        print(\"   4. Check if the evaluation target/model is accessible:\")\n",
    "        print(\"      oc get nemoevaluator -n arhkp-nemo-helm -o yaml\")\n",
    "        \n",
    "        raise Exception(f\"Evaluation job failed. Status: {status}. Check cluster logs for details.\")\n",
    "    elif status in [\"completed\", \"success\", \"finished\"]:\n",
    "        print(f\"\\n✅ Job is already completed with status: {status}\")\n",
    "        print(f\"Total time: {time() - start_time:.2f}s\")\n",
    "        return res\n",
    "\n",
    "    # Track status changes\n",
    "    last_status = status\n",
    "    status_changes = []\n",
    "    \n",
    "    while (status in [\"pending\", \"created\", \"running\", \"unknown\"]):\n",
    "        # Check for timeout\n",
    "        elapsed = time() - start_time\n",
    "        if elapsed > timeout:\n",
    "            print(f\"\\n⏱️  Timeout: Job took more than {timeout} seconds.\")\n",
    "            print(f\"Final status: {status}\")\n",
    "            print(f\"Status history: {status_changes}\")\n",
    "            raise RuntimeError(f\"Evaluation job timeout after {timeout} seconds. Final status: {status}\")\n",
    "\n",
    "        # Sleep before polling again\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        # Fetch updated status and progress\n",
    "        res = requests.get(job_url)\n",
    "        \n",
    "        if res.status_code != 200:\n",
    "            print(f\"⚠️  Warning: HTTP {res.status_code} when polling job status\")\n",
    "            print(f\"Response: {res.text}\")\n",
    "            # Continue polling - might be a temporary issue\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            job_data = res.json()\n",
    "            status = job_data.get(\"status\", \"unknown\")\n",
    "            \n",
    "            # Track status changes\n",
    "            if status != last_status:\n",
    "                status_changes.append((elapsed, last_status, status))\n",
    "                print(f\"\\n🔄 Status changed: {last_status} → {status} (after {elapsed:.2f}s)\")\n",
    "                last_status = status\n",
    "            \n",
    "            # Progress details\n",
    "            progress = 0\n",
    "            if status == \"running\":\n",
    "                progress = job_data.get(\"status_details\", {}).get(\"progress\", 0)\n",
    "                print(f\"⏳ Job status: {status} | Progress: {progress}% | Elapsed: {elapsed:.2f}s\")\n",
    "            elif status == \"completed\":\n",
    "                progress = 100\n",
    "                print(f\"✅ Job status: {status} | Progress: {progress}% | Elapsed: {elapsed:.2f}s\")\n",
    "            elif status in [\"pending\", \"created\"]:\n",
    "                print(f\"⏳ Job status: {status} | Elapsed: {elapsed:.2f}s\")\n",
    "            elif status == \"failed\":\n",
    "                print(f\"❌ Job status: {status} | Elapsed: {elapsed:.2f}s\")\n",
    "                print(\"\\nFull job data:\")\n",
    "                print(json.dumps(job_data, indent=2))\n",
    "                raise Exception(f\"Evaluation job failed. Check cluster logs for details.\")\n",
    "            else:\n",
    "                print(f\"⚠️  Job status: {status} (unexpected) | Elapsed: {elapsed:.2f}s\")\n",
    "                \n",
    "        except (KeyError, ValueError) as e:\n",
    "            print(f\"⚠️  Warning: Error parsing job response: {e}\")\n",
    "            print(f\"Response text: {res.text}\")\n",
    "            # Continue polling - might be a temporary issue\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n✅ Job completed with status: {status} (total time: {time() - start_time:.2f}s)\")\n",
    "    return res\n",
    "\n",
    "print_status(\"Evaluation job wait function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db71fc",
   "metadata": {},
   "source": [
    "Run the helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48322fdb-8920-435d-863d-9a75158843d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting to poll evaluation job: eval-96vz7ekunvAxvoUnwEHEJ6\n",
      "Job URL: http://localhost:8004/v1/evaluation/jobs/eval-96vz7ekunvAxvoUnwEHEJ6\n",
      "Polling interval: 5 seconds, Timeout: 600 seconds (10 minutes)\n",
      "\n",
      "🔍 Checking evaluation job status at: http://localhost:8004/v1/evaluation/jobs/eval-96vz7ekunvAxvoUnwEHEJ6\n",
      "📊 Initial job status: running\n",
      "\n",
      "Initial Job Data:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:40:36.399983\",\n",
      "  \"updated_at\": \"2025-11-07T20:40:36.424477\",\n",
      "  \"id\": \"eval-96vz7ekunvAxvoUnwEHEJ6\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": null,\n",
      "  \"target\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-target-V6B17rKsKvtsPYeDebCox8\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-target\",\n",
      "    \"namespace\": \"arhkp-nemo-helm\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:40:36.312684\",\n",
      "    \"updated_at\": \"2025-11-07T20:40:36.312684\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"llama-3-1b-instruct\",\n",
      "    \"type\": \"model\",\n",
      "    \"cached_outputs\": null,\n",
      "    \"model\": {\n",
      "      \"schema_version\": \"1.0\",\n",
      "      \"id\": \"model-BQa8x9TVNnCcK8kisfv7s7\",\n",
      "      \"description\": null,\n",
      "      \"type_prefix\": \"model\",\n",
      "      \"namespace\": \"default\",\n",
      "      \"project\": null,\n",
      "      \"created_at\": \"2025-11-07T20:40:36.312526\",\n",
      "      \"updated_at\": \"2025-11-07T20:40:36.312528\",\n",
      "      \"custom_fields\": {},\n",
      "      \"ownership\": null,\n",
      "      \"name\": \"model-BQa8x9TVNnCcK8kisfv7s7\",\n",
      "      \"version_id\": \"main\",\n",
      "      \"version_tags\": [],\n",
      "      \"spec\": null,\n",
      "      \"artifact\": null,\n",
      "      \"base_model\": null,\n",
      "      \"api_endpoint\": {\n",
      "        \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "        \"model_id\": \"meta/llama-3.2-1b-instruct\",\n",
      "        \"api_key\": null,\n",
      "        \"format\": \"nim\"\n",
      "      },\n",
      "      \"peft\": null,\n",
      "      \"prompt\": null,\n",
      "      \"guardrails\": null\n",
      "    },\n",
      "    \"retriever\": null,\n",
      "    \"rag\": null,\n",
      "    \"rows\": null,\n",
      "    \"dataset\": null\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-config-KXAUVpoHv8Ysbgbo1dqotY\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-config\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:40:36.399775\",\n",
      "    \"updated_at\": \"2025-11-07T20:40:36.399777\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"eval-config-KXAUVpoHv8Ysbgbo1dqotY\",\n",
      "    \"type\": \"custom\",\n",
      "    \"params\": null,\n",
      "    \"tasks\": {\n",
      "      \"custom-tool-calling\": {\n",
      "        \"type\": \"chat-completion\",\n",
      "        \"params\": {\n",
      "          \"template\": {\n",
      "            \"messages\": \"{{ item.messages | tojson}}\",\n",
      "            \"tools\": \"{{ item.tools | tojson }}\",\n",
      "            \"tool_choice\": \"auto\"\n",
      "          }\n",
      "        },\n",
      "        \"metrics\": {\n",
      "          \"tool-calling-accuracy\": {\n",
      "            \"type\": \"tool-calling\",\n",
      "            \"params\": {\n",
      "              \"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dataset\": {\n",
      "          \"schema_version\": \"1.0\",\n",
      "          \"id\": \"dataset-UpanFc7aDAC2qmmvXPsoVU\",\n",
      "          \"description\": null,\n",
      "          \"type_prefix\": null,\n",
      "          \"namespace\": \"default\",\n",
      "          \"project\": null,\n",
      "          \"created_at\": \"2025-11-07T20:40:36.399807\",\n",
      "          \"updated_at\": \"2025-11-07T20:40:36.399808\",\n",
      "          \"custom_fields\": {},\n",
      "          \"ownership\": null,\n",
      "          \"name\": \"dataset-UpanFc7aDAC2qmmvXPsoVU\",\n",
      "          \"version_id\": \"main\",\n",
      "          \"version_tags\": [],\n",
      "          \"format\": null,\n",
      "          \"files_url\": \"hf://datasets/arhkp-nemo-helm/xlam-ft-dataset/testing/xlam-test-single.jsonl\",\n",
      "          \"hf_endpoint\": null,\n",
      "          \"split\": null,\n",
      "          \"limit\": 50\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"groups\": null\n",
      "  },\n",
      "  \"result\": \"evaluation_result-5Dq5krbPSjdB6w4AbqUT1R\",\n",
      "  \"output_files_url\": null,\n",
      "  \"status_details\": {\n",
      "    \"message\": null,\n",
      "    \"task_status\": {\n",
      "      \"custom-tool-calling\": \"running\"\n",
      "    },\n",
      "    \"progress\": 0.0\n",
      "  },\n",
      "  \"status\": \"running\",\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n",
      "⏳ Job status: running | Progress: 0.0% | Elapsed: 0.08s\n",
      "⏳ Job status: running | Progress: 0.0% | Elapsed: 5.17s\n",
      "⏳ Job status: running | Progress: 0.0% | Elapsed: 10.26s\n",
      "⏳ Job status: running | Progress: 0.0% | Elapsed: 15.42s\n",
      "⏳ Job status: running | Progress: 0.0% | Elapsed: 20.51s\n",
      "⏳ Job status: running | Progress: 2.0% | Elapsed: 25.61s\n",
      "⏳ Job status: running | Progress: 8.0% | Elapsed: 30.70s\n",
      "⏳ Job status: running | Progress: 8.0% | Elapsed: 35.79s\n",
      "⏳ Job status: running | Progress: 12.0% | Elapsed: 40.87s\n",
      "⏳ Job status: running | Progress: 18.0% | Elapsed: 45.97s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 51.06s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 56.15s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 61.23s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 66.32s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 71.41s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 76.50s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 81.59s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 86.68s\n",
      "⏳ Job status: running | Progress: 32.0% | Elapsed: 91.77s\n",
      "⏳ Job status: running | Progress: 32.0% | Elapsed: 96.86s\n",
      "⏳ Job status: running | Progress: 36.0% | Elapsed: 101.95s\n",
      "⏳ Job status: running | Progress: 38.0% | Elapsed: 107.04s\n",
      "⏳ Job status: running | Progress: 38.0% | Elapsed: 112.12s\n",
      "⏳ Job status: running | Progress: 38.0% | Elapsed: 117.23s\n",
      "⏳ Job status: running | Progress: 38.0% | Elapsed: 122.33s\n",
      "⏳ Job status: running | Progress: 40.0% | Elapsed: 127.41s\n",
      "⏳ Job status: running | Progress: 44.0% | Elapsed: 132.50s\n",
      "⏳ Job status: running | Progress: 50.0% | Elapsed: 137.59s\n",
      "⏳ Job status: running | Progress: 52.0% | Elapsed: 142.69s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 147.78s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 152.88s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 157.97s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 163.06s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 168.15s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 173.24s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 178.33s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 183.42s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 188.51s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 193.60s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 198.69s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 203.78s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 208.87s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 213.96s\n",
      "⏳ Job status: running | Progress: 64.0% | Elapsed: 219.05s\n",
      "⏳ Job status: running | Progress: 64.0% | Elapsed: 224.14s\n",
      "⏳ Job status: running | Progress: 64.0% | Elapsed: 229.22s\n",
      "⏳ Job status: running | Progress: 68.0% | Elapsed: 234.31s\n",
      "⏳ Job status: running | Progress: 70.0% | Elapsed: 239.41s\n",
      "⏳ Job status: running | Progress: 78.0% | Elapsed: 244.50s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 249.59s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 254.68s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 259.78s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 264.87s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 269.95s\n",
      "⏳ Job status: running | Progress: 88.0% | Elapsed: 275.04s\n",
      "⏳ Job status: running | Progress: 88.0% | Elapsed: 280.14s\n",
      "⏳ Job status: running | Progress: 88.0% | Elapsed: 285.23s\n",
      "⏳ Job status: running | Progress: 90.0% | Elapsed: 290.32s\n",
      "⏳ Job status: running | Progress: 92.0% | Elapsed: 295.41s\n",
      "⏳ Job status: running | Progress: 92.0% | Elapsed: 300.50s\n",
      "⏳ Job status: running | Progress: 92.0% | Elapsed: 305.59s\n",
      "⏳ Job status: running | Progress: 92.0% | Elapsed: 310.68s\n",
      "⏳ Job status: running | Progress: 96.0% | Elapsed: 315.77s\n",
      "\n",
      "🔄 Status changed: running → completed (after 320.86s)\n",
      "✅ Job status: completed | Progress: 100% | Elapsed: 320.86s\n",
      "\n",
      "✅ Job completed with status: completed (total time: 325.95s)\n",
      "\n",
      "============================================================\n",
      "📋 Final Evaluation Job Status:\n",
      "============================================================\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:40:36.399983\",\n",
      "  \"updated_at\": \"2025-11-07T20:45:58.900220\",\n",
      "  \"id\": \"eval-96vz7ekunvAxvoUnwEHEJ6\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": null,\n",
      "  \"target\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-target-V6B17rKsKvtsPYeDebCox8\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-target\",\n",
      "    \"namespace\": \"arhkp-nemo-helm\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:40:36.312684\",\n",
      "    \"updated_at\": \"2025-11-07T20:40:36.312684\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"llama-3-1b-instruct\",\n",
      "    \"type\": \"model\",\n",
      "    \"cached_outputs\": null,\n",
      "    \"model\": {\n",
      "      \"schema_version\": \"1.0\",\n",
      "      \"id\": \"model-BQa8x9TVNnCcK8kisfv7s7\",\n",
      "      \"description\": null,\n",
      "      \"type_prefix\": \"model\",\n",
      "      \"namespace\": \"default\",\n",
      "      \"project\": null,\n",
      "      \"created_at\": \"2025-11-07T20:40:36.312526\",\n",
      "      \"updated_at\": \"2025-11-07T20:40:36.312528\",\n",
      "      \"custom_fields\": {},\n",
      "      \"ownership\": null,\n",
      "      \"name\": \"model-BQa8x9TVNnCcK8kisfv7s7\",\n",
      "      \"version_id\": \"main\",\n",
      "      \"version_tags\": [],\n",
      "      \"spec\": null,\n",
      "      \"artifact\": null,\n",
      "      \"base_model\": null,\n",
      "      \"api_endpoint\": {\n",
      "        \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "        \"model_id\": \"meta/llama-3.2-1b-instruct\",\n",
      "        \"api_key\": null,\n",
      "        \"format\": \"nim\"\n",
      "      },\n",
      "      \"peft\": null,\n",
      "      \"prompt\": null,\n",
      "      \"guardrails\": null\n",
      "    },\n",
      "    \"retriever\": null,\n",
      "    \"rag\": null,\n",
      "    \"rows\": null,\n",
      "    \"dataset\": null\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-config-KXAUVpoHv8Ysbgbo1dqotY\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-config\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:40:36.399775\",\n",
      "    \"updated_at\": \"2025-11-07T20:40:36.399777\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"eval-config-KXAUVpoHv8Ysbgbo1dqotY\",\n",
      "    \"type\": \"custom\",\n",
      "    \"params\": null,\n",
      "    \"tasks\": {\n",
      "      \"custom-tool-calling\": {\n",
      "        \"type\": \"chat-completion\",\n",
      "        \"params\": {\n",
      "          \"template\": {\n",
      "            \"messages\": \"{{ item.messages | tojson}}\",\n",
      "            \"tools\": \"{{ item.tools | tojson }}\",\n",
      "            \"tool_choice\": \"auto\"\n",
      "          }\n",
      "        },\n",
      "        \"metrics\": {\n",
      "          \"tool-calling-accuracy\": {\n",
      "            \"type\": \"tool-calling\",\n",
      "            \"params\": {\n",
      "              \"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dataset\": {\n",
      "          \"schema_version\": \"1.0\",\n",
      "          \"id\": \"dataset-UpanFc7aDAC2qmmvXPsoVU\",\n",
      "          \"description\": null,\n",
      "          \"type_prefix\": null,\n",
      "          \"namespace\": \"default\",\n",
      "          \"project\": null,\n",
      "          \"created_at\": \"2025-11-07T20:40:36.399807\",\n",
      "          \"updated_at\": \"2025-11-07T20:40:36.399808\",\n",
      "          \"custom_fields\": {},\n",
      "          \"ownership\": null,\n",
      "          \"name\": \"dataset-UpanFc7aDAC2qmmvXPsoVU\",\n",
      "          \"version_id\": \"main\",\n",
      "          \"version_tags\": [],\n",
      "          \"format\": null,\n",
      "          \"files_url\": \"hf://datasets/arhkp-nemo-helm/xlam-ft-dataset/testing/xlam-test-single.jsonl\",\n",
      "          \"hf_endpoint\": null,\n",
      "          \"split\": null,\n",
      "          \"limit\": 50\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"groups\": null\n",
      "  },\n",
      "  \"result\": \"evaluation_result-5Dq5krbPSjdB6w4AbqUT1R\",\n",
      "  \"output_files_url\": \"hf://datasets/evaluation-results/eval-96vz7ekunvAxvoUnwEHEJ6\",\n",
      "  \"status_details\": {\n",
      "    \"message\": \"Job completed successfully.\",\n",
      "    \"task_status\": {\n",
      "      \"custom-tool-calling\": \"completed\"\n",
      "    },\n",
      "    \"progress\": 100.0\n",
      "  },\n",
      "  \"status\": \"completed\",\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n",
      "============================================================\n",
      "\n",
      "✅ Job completed successfully with status: completed\n",
      "✅ Base model evaluation job completed\n"
     ]
    }
   ],
   "source": [
    "# Poll for evaluation job completion\n",
    "print(f\"🚀 Starting to poll evaluation job: {base_eval_job_id}\")\n",
    "print(f\"Job URL: {EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}\")\n",
    "print(f\"Polling interval: 5 seconds, Timeout: 600 seconds (10 minutes)\\n\")\n",
    "\n",
    "try:\n",
    "    res = wait_eval_job(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}\", polling_interval=5, timeout=600)\n",
    "except Exception as e:\n",
    "    # If wait_eval_job raised an exception (e.g., job failed), try to get final status for debugging\n",
    "    print(f\"\\n⚠️  Exception during polling: {e}\")\n",
    "    print(\"\\nAttempting to fetch final job status for debugging...\")\n",
    "    try:\n",
    "        final_res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}\")\n",
    "        if final_res.status_code == 200:\n",
    "            final_job_data = final_res.json()\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"📋 Final Job Status (for debugging):\")\n",
    "            print(\"=\"*60)\n",
    "            print(json.dumps(final_job_data, indent=2))\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Extract and display error information\n",
    "            status_details = final_job_data.get(\"status_details\", {})\n",
    "            if status_details:\n",
    "                print(\"\\n🔍 Status Details:\")\n",
    "                print(json.dumps(status_details, indent=2))\n",
    "            \n",
    "            # Check for error messages\n",
    "            error_msg = status_details.get(\"error\") or status_details.get(\"message\") or final_job_data.get(\"error\")\n",
    "            if error_msg:\n",
    "                print(f\"\\n❌ Error Message: {error_msg}\")\n",
    "        else:\n",
    "            print(f\"Could not fetch final status: HTTP {final_res.status_code}\")\n",
    "    except Exception as fetch_error:\n",
    "        print(f\"Could not fetch final status: {fetch_error}\")\n",
    "    \n",
    "    # Re-raise the original exception\n",
    "    raise\n",
    "\n",
    "# Check response status\n",
    "if res.status_code != 200:\n",
    "    print(f\"\\n❌ Error: Evaluation job status check failed with status {res.status_code}\")\n",
    "    print(f\"Response: {res.text}\")\n",
    "    print(\"\\n💡 To check cluster logs, run:\")\n",
    "    print(f\"   oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=100\")\n",
    "    print(f\"   oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "    raise Exception(f\"Failed to get evaluation job status: {res.text}\")\n",
    "\n",
    "# Format and print the response\n",
    "job_status = res.json()\n",
    "final_status = job_status.get(\"status\", \"unknown\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📋 Final Evaluation Job Status:\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(job_status, indent=2))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract and display error information if job failed\n",
    "if final_status == \"failed\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"❌ JOB FAILED - Error Analysis:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    status_details = job_status.get(\"status_details\", {})\n",
    "    if status_details:\n",
    "        print(\"\\nStatus Details:\")\n",
    "        print(json.dumps(status_details, indent=2))\n",
    "        \n",
    "        # Look for common error fields\n",
    "        error_fields = [\"error\", \"message\", \"reason\", \"failure_reason\", \"error_message\"]\n",
    "        for field in error_fields:\n",
    "            if field in status_details:\n",
    "                print(f\"\\n🔴 {field.upper()}: {status_details[field]}\")\n",
    "    \n",
    "    # Check for error in top level\n",
    "    if \"error\" in job_status:\n",
    "        print(f\"\\n🔴 Top-level error: {job_status['error']}\")\n",
    "    \n",
    "    print(\"\\n💡 Common causes of evaluation job failures:\")\n",
    "    print(\"   1. Evaluation target (model) is not accessible or not found\")\n",
    "    print(\"   2. Evaluation dataset is not accessible or invalid\")\n",
    "    print(\"   3. Insufficient resources (GPU, memory, etc.)\")\n",
    "    print(\"   4. Network connectivity issues between services\")\n",
    "    print(\"   5. Configuration errors in evaluation config\")\n",
    "    \n",
    "    print(\"\\n💡 To investigate:\")\n",
    "    print(\"   1. Check evaluator service logs:\")\n",
    "    print(\"      oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=200\")\n",
    "    print(\"   2. Check evaluation job pods:\")\n",
    "    print(\"      oc get pods -n arhkp-nemo-helm | grep -E 'eval|evaluation'\")\n",
    "    print(\"   3. Verify evaluation target exists:\")\n",
    "    print(f\"      requests.get(f'{EVALUATOR_URL}/v1/evaluation/targets/{NMS_NAMESPACE}/llama-3-1b-instruct').json()\")\n",
    "    print(\"   4. Check evaluator pod status:\")\n",
    "    print(\"      oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "    print(\"   5. Check evaluator custom resource:\")\n",
    "    print(\"      oc get nemoevaluator -n arhkp-nemo-helm -o yaml\")\n",
    "\n",
    "# Check if job actually completed successfully\n",
    "if final_status not in [\"completed\", \"success\", \"finished\"]:\n",
    "    if final_status != \"failed\":  # Already handled above\n",
    "        print(f\"\\n⚠️  Warning: Job status is '{final_status}', not 'completed'\")\n",
    "        print(\"This might indicate the job is still running, failed, or in an unexpected state.\")\n",
    "        print(\"\\n💡 To check cluster logs and pod status:\")\n",
    "        print(f\"   # Check evaluator pods\")\n",
    "        print(f\"   oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Check evaluator logs\")\n",
    "        print(f\"   oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=100\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Check for evaluation job pods (if any)\")\n",
    "        print(f\"   oc get pods -n arhkp-nemo-helm | grep -E 'eval|evaluation'\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Check job status directly\")\n",
    "        print(f\"   oc get nemoevaluator -n arhkp-nemo-helm\")\n",
    "else:\n",
    "    print(f\"\\n✅ Job completed successfully with status: {final_status}\")\n",
    "\n",
    "# Also return it so Jupyter displays it\n",
    "job_status\n",
    "\n",
    "print_status(\"Base model evaluation job completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de58a76-1775-4c93-8798-1ec89c8eeaff",
   "metadata": {},
   "source": [
    "### 1.3 Review Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb6220",
   "metadata": {},
   "source": [
    "The following code sends a GET request to retrieve the evaluation results for the base evaluation job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec04c15a-62a9-4271-8a7f-9a7e8ec7884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking evaluation job status...\n",
      "\n",
      "Full status response:\n",
      "{\n",
      "  \"message\": \"Job completed successfully.\",\n",
      "  \"task_status\": {\n",
      "    \"custom-tool-calling\": \"completed\"\n",
      "  },\n",
      "  \"progress\": 100.0\n",
      "}\n",
      "\n",
      "📊 Inferred job status: completed\n",
      "   Message: Job completed successfully.\n",
      "   Progress: 100.0%\n",
      "   Task status: {'custom-tool-calling': 'completed'}\n",
      "✅ Job is completed (status: completed)\n",
      "\n",
      "Retrieving evaluation results...\n",
      "\n",
      "Evaluation Results:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:40:36.428309\",\n",
      "  \"updated_at\": \"2025-11-07T20:40:36.428310\",\n",
      "  \"id\": \"evaluation_result-5Dq5krbPSjdB6w4AbqUT1R\",\n",
      "  \"job\": \"eval-96vz7ekunvAxvoUnwEHEJ6\",\n",
      "  \"tasks\": {\n",
      "    \"custom-tool-calling\": {\n",
      "      \"metrics\": {\n",
      "        \"tool-calling-accuracy\": {\n",
      "          \"scores\": {\n",
      "            \"function_name_accuracy\": {\n",
      "              \"value\": 0.12,\n",
      "              \"stats\": {\n",
      "                \"count\": 50,\n",
      "                \"sum\": 6.0,\n",
      "                \"mean\": 0.12\n",
      "              }\n",
      "            },\n",
      "            \"function_name_and_args_accuracy\": {\n",
      "              \"value\": 0.06,\n",
      "              \"stats\": {\n",
      "                \"count\": 50,\n",
      "                \"sum\": 3.0,\n",
      "                \"mean\": 0.06\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"groups\": {},\n",
      "  \"namespace\": \"default\",\n",
      "  \"custom_fields\": {}\n",
      "}\n",
      "✅ Base model evaluation results retrieved\n"
     ]
    }
   ],
   "source": [
    "# First, check the job status to ensure it's completed\n",
    "print(\"Checking evaluation job status...\")\n",
    "status_res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}/status\")\n",
    "\n",
    "if status_res.status_code != 200:\n",
    "    print(f\"⚠️ Warning: Could not check job status (Status {status_res.status_code})\")\n",
    "    print(f\"Response: {status_res.text}\")\n",
    "    print(\"\\nAttempting to retrieve results anyway (the job might still be accessible)...\")\n",
    "else:\n",
    "    status_data = status_res.json()\n",
    "    \n",
    "    # Print full status for debugging\n",
    "    print(\"\\nFull status response:\")\n",
    "    print(json.dumps(status_data, indent=2))\n",
    "    \n",
    "    # The /status endpoint returns a different structure than the full job endpoint\n",
    "    # It has \"message\" and \"task_status\" instead of a top-level \"status\" field\n",
    "    job_status = status_data.get(\"status\")\n",
    "    \n",
    "    # If no \"status\" field, infer from message and task_status\n",
    "    if job_status is None:\n",
    "        message = status_data.get(\"message\", \"\").lower()\n",
    "        task_status = status_data.get(\"task_status\", {})\n",
    "        progress = status_data.get(\"progress\", 0)\n",
    "        \n",
    "        # Infer status from message and task status\n",
    "        if \"completed successfully\" in message or \"success\" in message:\n",
    "            # Check if all tasks are completed\n",
    "            if task_status:\n",
    "                all_tasks_completed = all(\n",
    "                    status.lower() in [\"completed\", \"success\", \"finished\"] \n",
    "                    for status in task_status.values()\n",
    "                )\n",
    "                if all_tasks_completed and progress >= 100:\n",
    "                    job_status = \"completed\"\n",
    "                elif all_tasks_completed:\n",
    "                    job_status = \"completed\"  # Progress might not be exactly 100\n",
    "                else:\n",
    "                    job_status = \"running\"  # Some tasks still in progress\n",
    "            elif progress >= 100:\n",
    "                job_status = \"completed\"\n",
    "            else:\n",
    "                job_status = \"running\"\n",
    "        elif \"failed\" in message or \"error\" in message:\n",
    "            job_status = \"failed\"\n",
    "        elif \"running\" in message or progress > 0:\n",
    "            job_status = \"running\"\n",
    "        else:\n",
    "            job_status = \"unknown\"\n",
    "        \n",
    "        print(f\"\\n📊 Inferred job status: {job_status}\")\n",
    "        print(f\"   Message: {status_data.get('message', 'N/A')}\")\n",
    "        print(f\"   Progress: {progress}%\")\n",
    "        if task_status:\n",
    "            print(f\"   Task status: {task_status}\")\n",
    "    else:\n",
    "        print(f\"Job status: {job_status}\")\n",
    "    \n",
    "    # Valid completion statuses\n",
    "    completed_statuses = [\"completed\", \"success\", \"finished\", \"done\"]\n",
    "    \n",
    "    if job_status in completed_statuses:\n",
    "        print(f\"✅ Job is completed (status: {job_status})\")\n",
    "    elif job_status == \"unknown\":\n",
    "        print(\"⚠️ Warning: Job status is 'unknown'\")\n",
    "        print(\"This could mean:\")\n",
    "        print(\"  - The job doesn't exist or was deleted\")\n",
    "        print(\"  - The status endpoint returned an unexpected format\")\n",
    "        print(\"  - The job is in an intermediate state\")\n",
    "        print(\"\\nAttempting to retrieve results anyway...\")\n",
    "    elif job_status == \"failed\":\n",
    "        print(f\"❌ Job has failed (status: {job_status})\")\n",
    "        print(\"Check the status details above for error information.\")\n",
    "        print(\"\\nAttempting to retrieve results anyway (may contain error details)...\")\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Evaluation job is not completed yet. Status: {job_status}\")\n",
    "        print(\"Valid completion statuses:\", completed_statuses)\n",
    "        print(\"\\nYou can check the status again with:\")\n",
    "        print(f'  requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}/status\").json()')\n",
    "        print(\"\\nAttempting to retrieve results anyway (the job might have results even if status is not 'completed')...\")\n",
    "\n",
    "# Now retrieve the results (try even if status check failed or status is unknown)\n",
    "print(\"\\nRetrieving evaluation results...\")\n",
    "res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}/results\")\n",
    "\n",
    "# Check response status\n",
    "if res.status_code != 200:\n",
    "    print(f\"❌ Error retrieving results: Status {res.status_code}\")\n",
    "    print(f\"Response: {res.text}\")\n",
    "    raise Exception(f\"Failed to retrieve evaluation results: {res.text}\")\n",
    "\n",
    "# Explicitly print the results\n",
    "results = res.json()\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(json.dumps(results, indent=2))\n",
    "\n",
    "# Check if tasks are empty\n",
    "if not results.get(\"tasks\") or len(results.get(\"tasks\", {})) == 0:\n",
    "    print(\"\\n⚠️ WARNING: Evaluation results have no tasks!\")\n",
    "    print(\"This could mean:\")\n",
    "    print(\"  1. The evaluation job completed but produced no results\")\n",
    "    print(\"  2. There was an error during evaluation\")\n",
    "    print(\"  3. The evaluation configuration was incorrect\")\n",
    "    print(\"\\nPlease check the evaluation job logs or status for more details.\")\n",
    "    print(f\"Job ID: {base_eval_job_id}\")\n",
    "\n",
    "# Also return it so Jupyter displays it\n",
    "results\n",
    "\n",
    "print_status(\"Base model evaluation results retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b28813",
   "metadata": {},
   "source": [
    "The following code extracts and prints the accuracy scores for the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2129c739-8980-4d28-ab72-331e00f0c2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: function_name_accuracy: 0.12\n",
      "Base model: function_name_and_args_accuracy: 0.06\n",
      "✅ Base model accuracy scores extracted\n"
     ]
    }
   ],
   "source": [
    "# Extract function name accuracy score\n",
    "# Handle different possible task names and structures\n",
    "# Note: 'res' should be set from the previous cell (cell 102)\n",
    "if 'res' not in locals() and 'res' not in globals():\n",
    "    raise NameError(\"Variable 'res' not found. Please run the previous cell to retrieve evaluation results first.\")\n",
    "\n",
    "result_data = res.json()\n",
    "tasks = result_data.get(\"tasks\", {})\n",
    "\n",
    "# Check if tasks are empty\n",
    "if not tasks or len(tasks) == 0:\n",
    "    print(\"❌ Error: Evaluation results have no tasks!\")\n",
    "    print(\"This means the evaluation job completed but produced no results.\")\n",
    "    print(\"\\nPossible causes:\")\n",
    "    print(\"  1. The evaluation dataset was empty or invalid\")\n",
    "    print(\"  2. The evaluation job failed silently\")\n",
    "    print(\"  3. The evaluation configuration was incorrect\")\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(f\"  - Evaluation job status: requests.get(f'{EVALUATOR_URL}/v1/evaluation/jobs/{base_eval_job_id}/status').json()\")\n",
    "    print(f\"  - Evaluation job logs in the cluster\")\n",
    "    print(f\"  - The evaluation dataset and configuration\")\n",
    "    print(\"\\nFull results structure:\")\n",
    "    print(json.dumps(result_data, indent=2))\n",
    "    raise ValueError(\"Evaluation results have no tasks. Please check the evaluation job status and logs.\")\n",
    "\n",
    "# Find the task (could be 'custom-tool-calling' or another name)\n",
    "task_name = None\n",
    "if \"custom-tool-calling\" in tasks:\n",
    "    task_name = \"custom-tool-calling\"\n",
    "elif len(tasks) > 0:\n",
    "    # Use the first task if 'custom-tool-calling' is not found\n",
    "    task_name = list(tasks.keys())[0]\n",
    "    print(f\"⚠️ Note: Using task '{task_name}' instead of 'custom-tool-calling'\")\n",
    "\n",
    "if not task_name or task_name not in tasks:\n",
    "    print(\"❌ Error: Could not find evaluation task in results\")\n",
    "    print(f\"Available tasks: {list(tasks.keys())}\")\n",
    "    print(f\"\\nFull results structure:\")\n",
    "    print(json.dumps(result_data, indent=2))\n",
    "    raise KeyError(f\"Task 'custom-tool-calling' not found. Available tasks: {list(tasks.keys())}\")\n",
    "\n",
    "# Extract metrics\n",
    "task_data = tasks[task_name]\n",
    "metrics = task_data.get(\"metrics\", {})\n",
    "tool_calling_metrics = metrics.get(\"tool-calling-accuracy\", {})\n",
    "scores = tool_calling_metrics.get(\"scores\", {})\n",
    "\n",
    "base_function_name_accuracy_score = scores.get(\"function_name_accuracy\", {}).get(\"value\")\n",
    "base_function_name_and_args_accuracy = scores.get(\"function_name_and_args_accuracy\", {}).get(\"value\")\n",
    "\n",
    "if base_function_name_accuracy_score is None or base_function_name_and_args_accuracy is None:\n",
    "    print(\"⚠️ Warning: Some accuracy scores are missing\")\n",
    "    print(f\"Available scores: {list(scores.keys())}\")\n",
    "    print(f\"\\nFull metrics structure:\")\n",
    "    print(json.dumps(metrics, indent=2))\n",
    "    print(f\"\\nFull task data:\")\n",
    "    print(json.dumps(task_data, indent=2))\n",
    "\n",
    "print(f\"Base model: function_name_accuracy: {base_function_name_accuracy_score}\")\n",
    "print(f\"Base model: function_name_and_args_accuracy: {base_function_name_and_args_accuracy}\")\n",
    "\n",
    "print_status(\"Base model accuracy scores extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9fcb78-0e23-45f6-988a-8be6e33c2cfc",
   "metadata": {},
   "source": [
    "Without any finetuning, the `meta/llama-3.2-1b-instruct` model should score in the ballpark of about 12% in `function_name_accuracy`, and 8% in `function_name_and_args_accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c7ab4-bb3c-46c3-a51e-9e25509a7781",
   "metadata": {},
   "source": [
    "### (Optional) 1.4 Download and Inspect Results\n",
    "\n",
    "To take a deeper look into the model's generated outputs, you can download and review the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36bf02e0-2383-46d5-ad47-3edc1e1dfdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation results download function defined\n"
     ]
    }
   ],
   "source": [
    "def download_evaluation_results(eval_url, eval_job_id, output_file):\n",
    "    \"\"\"Downloads evaluation results for a given job ID from the NeMo server.\"\"\"\n",
    "    \n",
    "    download_response = requests.get(f\"{eval_url}/v1/evaluation/jobs/{eval_job_id}/download-results\")\n",
    "    \n",
    "    # Check the response status\n",
    "    if download_response.status_code == 200:\n",
    "        # Save the results to a file\n",
    "        with open(output_file, \"wb\") as file:\n",
    "            file.write(download_response.content)\n",
    "        print(f\"Evaluation results for job {eval_job_id} downloaded successfully to {output_file}.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Failed to download evaluation results. Status code: {download_response.status_code}\")\n",
    "        print('Response:', download_response.text)\n",
    "        return False\n",
    "\n",
    "print_status(\"Evaluation results download function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da8ec595-8edd-4d8c-a2a0-29f830710c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for job eval-96vz7ekunvAxvoUnwEHEJ6 downloaded successfully to eval-96vz7ekunvAxvoUnwEHEJ6.json.\n",
      "✅ Base model evaluation results downloaded\n"
     ]
    }
   ],
   "source": [
    "output_file = f\"{base_eval_job_id}.json\"\n",
    "\n",
    "# Assertion fails if download fails\n",
    "assert download_evaluation_results(eval_url=EVALUATOR_URL, eval_job_id=base_eval_job_id, output_file=output_file) == True\n",
    "\n",
    "print_status(\"Base model evaluation results downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f633d-5b20-4a28-8962-970a54b91f40",
   "metadata": {},
   "source": [
    "You can inspect the downloaded results file to observe places where the base model errors. Without any fine-tuning, some models not only return inaccurate function names and arguments, but they may not adhere to a consistent structured / predictable output schema. This makes it difficult to automatically parse these outputs, deterring integration with external systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79229ce6-4ce4-4f82-b0c9-15be351a2291",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-2\"></a>\n",
    "## Step 2: Evaluate the LoRA Customized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcdeba8-6800-419f-b5c5-0dc34bf6e0f5",
   "metadata": {},
   "source": [
    "### 2.1 Launch Evaluation Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb900e7-2ec8-417a-9266-2ce682f655e5",
   "metadata": {},
   "source": [
    "Run another evaluation job with the same evaluation config but with the customized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7bbfea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking if custom model is available in NIM: arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P\n",
      "   (NIM synchronizes custom models every 3 minutes, so this may take a few minutes)\n",
      "⚠️  Custom model 'arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NA7zfXrZXvECNy62ijNM4P' not yet in NIM, but found similar models:\n",
      "   - arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\n",
      "   - arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-BJ2vu5qazwWKNC649EniKg\n",
      "   - arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-NByPmnsbnhzPJFYJK9Cr3K\n",
      "   - arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-6eiBhrm55cog2N6qyszqGj\n",
      "   Using the latest similar model: arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\n",
      "\n",
      "ℹ️  Creating evaluation target with cluster URL: http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\n",
      "   Model ID: arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\n",
      "   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\n",
      "   (Using /v1/chat/completions endpoint for chat models)\n",
      "\n",
      "✅ Evaluation Target Created:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:53:12.442155\",\n",
      "  \"updated_at\": \"2025-11-07T20:53:12.442155\",\n",
      "  \"name\": \"llama-3-1b-instruct-customized\",\n",
      "  \"namespace\": \"arhkp-nemo-helm\",\n",
      "  \"type\": \"model\",\n",
      "  \"model\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "    \"type_prefix\": \"model\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"created_at\": \"2025-11-07T20:53:12.441967\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:12.441970\",\n",
      "    \"custom_fields\": {},\n",
      "    \"name\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "    \"version_id\": \"main\",\n",
      "    \"version_tags\": [],\n",
      "    \"api_endpoint\": {\n",
      "      \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "      \"model_id\": \"arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\",\n",
      "      \"format\": \"nim\"\n",
      "    }\n",
      "  },\n",
      "  \"id\": \"eval-target-PVVk5vqrqtXgLf28zu37WG\",\n",
      "  \"custom_fields\": {}\n",
      "}\n",
      "✅ Custom model evaluation target created\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Wait for the custom model to be available in NIM before creating evaluation target\n",
    "# NIM synchronizes custom models from Entity Store every 3 minutes, so we need to wait\n",
    "print(f\"🔍 Checking if custom model is available in NIM: {CUSTOMIZED_MODEL}\")\n",
    "print(\"   (NIM synchronizes custom models every 3 minutes, so this may take a few minutes)\")\n",
    "\n",
    "from time import sleep, time\n",
    "max_wait_time = 600  # 10 minutes max wait\n",
    "poll_interval = 10  # Check every 10 seconds\n",
    "start_time = time()\n",
    "model_available = False\n",
    "model_to_use = CUSTOMIZED_MODEL\n",
    "\n",
    "while (time() - start_time) < max_wait_time:\n",
    "    nim_models_resp = requests.get(f\"{NIM_URL}/v1/models\")\n",
    "    if nim_models_resp.status_code == 200:\n",
    "        nim_models = nim_models_resp.json().get(\"data\", [])\n",
    "        nim_model_ids = [m.get(\"id\") for m in nim_models]\n",
    "        \n",
    "        if CUSTOMIZED_MODEL in nim_model_ids:\n",
    "            print(f\"✅ Custom model '{CUSTOMIZED_MODEL}' is now available in NIM!\")\n",
    "            model_available = True\n",
    "            model_to_use = CUSTOMIZED_MODEL\n",
    "            break\n",
    "        else:\n",
    "            # Check if a similar model is available (same base name, different version)\n",
    "            customized_model_name = CUSTOMIZED_MODEL.split('/')[-1].split('@')[0]\n",
    "            similar_models = [m for m in nim_model_ids if customized_model_name in m]\n",
    "            if similar_models:\n",
    "                print(f\"⚠️  Custom model '{CUSTOMIZED_MODEL}' not yet in NIM, but found similar models:\")\n",
    "                for m in similar_models:\n",
    "                    print(f\"   - {m}\")\n",
    "                print(f\"   Using the latest similar model: {similar_models[0]}\")\n",
    "                model_to_use = similar_models[0]\n",
    "                model_available = True\n",
    "                break\n",
    "    \n",
    "    elapsed = time() - start_time\n",
    "    print(f\"⏳ Waiting for model to sync... ({elapsed:.0f}s elapsed, checking every {poll_interval}s)\")\n",
    "    sleep(poll_interval)\n",
    "\n",
    "if not model_available:\n",
    "    print(f\"\\n⚠️  Warning: Custom model '{CUSTOMIZED_MODEL}' is still not available in NIM after {max_wait_time}s\")\n",
    "    print(\"   This could mean:\")\n",
    "    print(\"   1. The model hasn't been synchronized yet (NIM syncs every 3 minutes)\")\n",
    "    print(\"   2. There's an issue with model synchronization\")\n",
    "    print(\"   3. The model ID is incorrect\")\n",
    "    print(\"\\n   Attempting to use the model anyway (it might work if sync happens during evaluation)...\")\n",
    "    model_to_use = CUSTOMIZED_MODEL\n",
    "\n",
    "# Delete evaluation target (if it exists)\n",
    "res = requests.delete(f\"{EVALUATOR_URL}/v1/evaluation/targets/{NMS_NAMESPACE}/llama-3-1b-instruct-customized\")\n",
    "# Ignore 404 errors (target might not exist)\n",
    "if res.status_code not in (200, 404):\n",
    "    print(f\"⚠️ Warning: Could not delete existing target: {res.status_code}\")\n",
    "\n",
    "## Create evaluation target\n",
    "# IMPORTANT: Use cluster-internal URL (NIM_URL_CLUSTER) for evaluation targets\n",
    "# because evaluation jobs run inside the cluster and can't access localhost port-forwards\n",
    "# Reload config module to get the latest NIM_URL_CLUSTER value\n",
    "import importlib\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import NIM_URL_CLUSTER\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "data = {\n",
    "    \"type\": \"model\",\n",
    "    \"name\": \"llama-3-1b-instruct-customized\",\n",
    "    \"namespace\": NMS_NAMESPACE,  # Use the correct namespace\n",
    "    \"model\": {\n",
    "        \"api_endpoint\": {\n",
    "            \"url\": f\"{NIM_URL_CLUSTER}/v1/chat/completions\",  # Use cluster URL, not localhost. Note: /v1/chat/completions for chat models\n",
    "            \"model_id\": f\"{model_to_use}\"  # Use the model that's actually available in NIM\n",
    "        }\n",
    "    }\n",
    "}\n",
    "print(f\"\\nℹ️  Creating evaluation target with cluster URL: {NIM_URL_CLUSTER}/v1/chat/completions\")\n",
    "print(f\"   Model ID: {model_to_use}\")\n",
    "print(f\"   (Evaluation jobs run inside cluster and need cluster service URL, not localhost)\")\n",
    "print(f\"   (Using /v1/chat/completions endpoint for chat models)\")\n",
    "res = requests.post(f\"{EVALUATOR_URL}/v1/evaluation/targets\", headers=headers, json=data)\n",
    "\n",
    "if res.status_code not in (200, 201):\n",
    "    print(f\"❌ Error creating evaluation target: Status {res.status_code}\")\n",
    "    print(f\"Response: {res.text}\")\n",
    "    raise Exception(f\"Failed to create evaluation target: Status {res.status_code}, Response: {res.text}\")\n",
    "\n",
    "target_response = res.json()\n",
    "print(\"\\n✅ Evaluation Target Created:\")\n",
    "print(json.dumps(target_response, indent=2))\n",
    "# Also return it so Jupyter displays it\n",
    "target_response\n",
    "\n",
    "print_status(\"Custom model evaluation target created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5438608-e708-4421-bf45-da39fbe506ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Job Created:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:53:18.714201\",\n",
      "  \"updated_at\": \"2025-11-07T20:53:18.714202\",\n",
      "  \"id\": \"eval-8gdLqUJt3HoNvLiuFvAjrU\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": null,\n",
      "  \"target\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-target-PVVk5vqrqtXgLf28zu37WG\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-target\",\n",
      "    \"namespace\": \"arhkp-nemo-helm\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"llama-3-1b-instruct-customized\",\n",
      "    \"type\": \"model\",\n",
      "    \"cached_outputs\": null,\n",
      "    \"model\": {\n",
      "      \"schema_version\": \"1.0\",\n",
      "      \"id\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"description\": null,\n",
      "      \"type_prefix\": \"model\",\n",
      "      \"namespace\": \"default\",\n",
      "      \"project\": null,\n",
      "      \"created_at\": \"2025-11-07T20:53:12.441967\",\n",
      "      \"updated_at\": \"2025-11-07T20:53:12.441970\",\n",
      "      \"custom_fields\": {},\n",
      "      \"ownership\": null,\n",
      "      \"name\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"version_id\": \"main\",\n",
      "      \"version_tags\": [],\n",
      "      \"spec\": null,\n",
      "      \"artifact\": null,\n",
      "      \"base_model\": null,\n",
      "      \"api_endpoint\": {\n",
      "        \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "        \"model_id\": \"arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\",\n",
      "        \"api_key\": null,\n",
      "        \"format\": \"nim\"\n",
      "      },\n",
      "      \"peft\": null,\n",
      "      \"prompt\": null,\n",
      "      \"guardrails\": null\n",
      "    },\n",
      "    \"retriever\": null,\n",
      "    \"rag\": null,\n",
      "    \"rows\": null,\n",
      "    \"dataset\": null\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-config\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:18.713924\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:18.713927\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"type\": \"custom\",\n",
      "    \"params\": null,\n",
      "    \"tasks\": {\n",
      "      \"custom-tool-calling\": {\n",
      "        \"type\": \"chat-completion\",\n",
      "        \"params\": {\n",
      "          \"template\": {\n",
      "            \"messages\": \"{{ item.messages | tojson}}\",\n",
      "            \"tools\": \"{{ item.tools | tojson }}\",\n",
      "            \"tool_choice\": \"auto\"\n",
      "          }\n",
      "        },\n",
      "        \"metrics\": {\n",
      "          \"tool-calling-accuracy\": {\n",
      "            \"type\": \"tool-calling\",\n",
      "            \"params\": {\n",
      "              \"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dataset\": {\n",
      "          \"schema_version\": \"1.0\",\n",
      "          \"id\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"description\": null,\n",
      "          \"type_prefix\": null,\n",
      "          \"namespace\": \"default\",\n",
      "          \"project\": null,\n",
      "          \"created_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"updated_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"custom_fields\": {},\n",
      "          \"ownership\": null,\n",
      "          \"name\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"version_id\": \"main\",\n",
      "          \"version_tags\": [],\n",
      "          \"format\": null,\n",
      "          \"files_url\": \"hf://datasets/arhkp-nemo-helm/xlam-ft-dataset/testing/xlam-test-single.jsonl\",\n",
      "          \"hf_endpoint\": null,\n",
      "          \"split\": null,\n",
      "          \"limit\": 50\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"groups\": null\n",
      "  },\n",
      "  \"result\": null,\n",
      "  \"output_files_url\": null,\n",
      "  \"status_details\": {\n",
      "    \"message\": null,\n",
      "    \"task_status\": {},\n",
      "    \"progress\": null\n",
      "  },\n",
      "  \"status\": \"created\",\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n",
      "\n",
      "Job ID: eval-8gdLqUJt3HoNvLiuFvAjrU\n",
      "✅ Custom model evaluation job created\n"
     ]
    }
   ],
   "source": [
    "res = requests.post(\n",
    "    f\"{EVALUATOR_URL}/v1/evaluation/jobs\",\n",
    "    json={\n",
    "        \"config\": simple_tool_calling_eval_config,\n",
    "        \"target\": f\"{NMS_NAMESPACE}/llama-3-1b-instruct-customized\"  # Use the correct namespace\n",
    "    },\n",
    ")\n",
    "\n",
    "if res.status_code not in (200, 201):\n",
    "    print(f\"❌ Error creating evaluation job: Status {res.status_code}\")\n",
    "    print(f\"Response: {res.text}\")\n",
    "    raise Exception(f\"Failed to create evaluation job: {res.text}\")\n",
    "\n",
    "job_response = res.json()\n",
    "ft_eval_job_id = job_response[\"id\"]\n",
    "\n",
    "print(\"Evaluation Job Created:\")\n",
    "print(json.dumps(job_response, indent=2))\n",
    "print(f\"\\nJob ID: {ft_eval_job_id}\")\n",
    "\n",
    "# Also return it so Jupyter displays it\n",
    "ft_eval_job_id\n",
    "\n",
    "print_status(\"Custom model evaluation job created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86003db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting to poll evaluation job: eval-8gdLqUJt3HoNvLiuFvAjrU\n",
      "Job URL: http://localhost:8004/v1/evaluation/jobs/eval-8gdLqUJt3HoNvLiuFvAjrU\n",
      "Polling interval: 5 seconds, Timeout: 600 seconds (10 minutes)\n",
      "\n",
      "🔍 Checking evaluation job status at: http://localhost:8004/v1/evaluation/jobs/eval-8gdLqUJt3HoNvLiuFvAjrU\n",
      "📊 Initial job status: running\n",
      "\n",
      "Initial Job Data:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:53:18.714201\",\n",
      "  \"updated_at\": \"2025-11-07T20:53:18.738943\",\n",
      "  \"id\": \"eval-8gdLqUJt3HoNvLiuFvAjrU\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": null,\n",
      "  \"target\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-target-PVVk5vqrqtXgLf28zu37WG\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-target\",\n",
      "    \"namespace\": \"arhkp-nemo-helm\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"llama-3-1b-instruct-customized\",\n",
      "    \"type\": \"model\",\n",
      "    \"cached_outputs\": null,\n",
      "    \"model\": {\n",
      "      \"schema_version\": \"1.0\",\n",
      "      \"id\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"description\": null,\n",
      "      \"type_prefix\": \"model\",\n",
      "      \"namespace\": \"default\",\n",
      "      \"project\": null,\n",
      "      \"created_at\": \"2025-11-07T20:53:12.441967\",\n",
      "      \"updated_at\": \"2025-11-07T20:53:12.441970\",\n",
      "      \"custom_fields\": {},\n",
      "      \"ownership\": null,\n",
      "      \"name\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"version_id\": \"main\",\n",
      "      \"version_tags\": [],\n",
      "      \"spec\": null,\n",
      "      \"artifact\": null,\n",
      "      \"base_model\": null,\n",
      "      \"api_endpoint\": {\n",
      "        \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "        \"model_id\": \"arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\",\n",
      "        \"api_key\": null,\n",
      "        \"format\": \"nim\"\n",
      "      },\n",
      "      \"peft\": null,\n",
      "      \"prompt\": null,\n",
      "      \"guardrails\": null\n",
      "    },\n",
      "    \"retriever\": null,\n",
      "    \"rag\": null,\n",
      "    \"rows\": null,\n",
      "    \"dataset\": null\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-config\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:18.713924\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:18.713927\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"type\": \"custom\",\n",
      "    \"params\": null,\n",
      "    \"tasks\": {\n",
      "      \"custom-tool-calling\": {\n",
      "        \"type\": \"chat-completion\",\n",
      "        \"params\": {\n",
      "          \"template\": {\n",
      "            \"messages\": \"{{ item.messages | tojson}}\",\n",
      "            \"tools\": \"{{ item.tools | tojson }}\",\n",
      "            \"tool_choice\": \"auto\"\n",
      "          }\n",
      "        },\n",
      "        \"metrics\": {\n",
      "          \"tool-calling-accuracy\": {\n",
      "            \"type\": \"tool-calling\",\n",
      "            \"params\": {\n",
      "              \"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dataset\": {\n",
      "          \"schema_version\": \"1.0\",\n",
      "          \"id\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"description\": null,\n",
      "          \"type_prefix\": null,\n",
      "          \"namespace\": \"default\",\n",
      "          \"project\": null,\n",
      "          \"created_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"updated_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"custom_fields\": {},\n",
      "          \"ownership\": null,\n",
      "          \"name\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"version_id\": \"main\",\n",
      "          \"version_tags\": [],\n",
      "          \"format\": null,\n",
      "          \"files_url\": \"hf://datasets/arhkp-nemo-helm/xlam-ft-dataset/testing/xlam-test-single.jsonl\",\n",
      "          \"hf_endpoint\": null,\n",
      "          \"split\": null,\n",
      "          \"limit\": 50\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"groups\": null\n",
      "  },\n",
      "  \"result\": \"evaluation_result-Kvh7oWULYPMLk5KjM3YUik\",\n",
      "  \"output_files_url\": null,\n",
      "  \"status_details\": {\n",
      "    \"message\": null,\n",
      "    \"task_status\": {\n",
      "      \"custom-tool-calling\": \"running\"\n",
      "    },\n",
      "    \"progress\": 0.0\n",
      "  },\n",
      "  \"status\": \"running\",\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n",
      "⏳ Job status: running | Progress: 0.0% | Elapsed: 0.08s\n",
      "⏳ Job status: running | Progress: 0.0% | Elapsed: 5.18s\n",
      "⏳ Job status: running | Progress: 0.0% | Elapsed: 10.27s\n",
      "⏳ Job status: running | Progress: 0.0% | Elapsed: 15.37s\n",
      "⏳ Job status: running | Progress: 4.0% | Elapsed: 20.45s\n",
      "⏳ Job status: running | Progress: 8.0% | Elapsed: 25.55s\n",
      "⏳ Job status: running | Progress: 12.0% | Elapsed: 30.64s\n",
      "⏳ Job status: running | Progress: 12.0% | Elapsed: 35.73s\n",
      "⏳ Job status: running | Progress: 20.0% | Elapsed: 40.82s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 45.91s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 51.01s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 56.10s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 61.20s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 66.29s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 71.38s\n",
      "⏳ Job status: running | Progress: 26.0% | Elapsed: 76.48s\n",
      "⏳ Job status: running | Progress: 30.0% | Elapsed: 81.57s\n",
      "⏳ Job status: running | Progress: 32.0% | Elapsed: 86.67s\n",
      "⏳ Job status: running | Progress: 32.0% | Elapsed: 91.76s\n",
      "⏳ Job status: running | Progress: 38.0% | Elapsed: 96.85s\n",
      "⏳ Job status: running | Progress: 38.0% | Elapsed: 101.94s\n",
      "⏳ Job status: running | Progress: 38.0% | Elapsed: 107.03s\n",
      "⏳ Job status: running | Progress: 38.0% | Elapsed: 112.12s\n",
      "⏳ Job status: running | Progress: 40.0% | Elapsed: 117.21s\n",
      "⏳ Job status: running | Progress: 40.0% | Elapsed: 122.30s\n",
      "⏳ Job status: running | Progress: 48.0% | Elapsed: 127.39s\n",
      "⏳ Job status: running | Progress: 50.0% | Elapsed: 132.48s\n",
      "⏳ Job status: running | Progress: 56.0% | Elapsed: 137.58s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 142.67s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 147.76s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 152.85s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 157.94s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 163.03s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 168.12s\n",
      "⏳ Job status: running | Progress: 60.0% | Elapsed: 173.21s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 178.30s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 183.39s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 188.49s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 193.57s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 198.67s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 203.76s\n",
      "⏳ Job status: running | Progress: 62.0% | Elapsed: 208.85s\n",
      "⏳ Job status: running | Progress: 64.0% | Elapsed: 213.94s\n",
      "⏳ Job status: running | Progress: 64.0% | Elapsed: 219.03s\n",
      "⏳ Job status: running | Progress: 66.0% | Elapsed: 224.13s\n",
      "⏳ Job status: running | Progress: 68.0% | Elapsed: 229.21s\n",
      "⏳ Job status: running | Progress: 74.0% | Elapsed: 234.30s\n",
      "⏳ Job status: running | Progress: 82.0% | Elapsed: 239.39s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 244.48s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 249.57s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 254.66s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 259.75s\n",
      "⏳ Job status: running | Progress: 84.0% | Elapsed: 264.85s\n",
      "⏳ Job status: running | Progress: 88.0% | Elapsed: 269.93s\n",
      "⏳ Job status: running | Progress: 88.0% | Elapsed: 275.02s\n",
      "⏳ Job status: running | Progress: 88.0% | Elapsed: 280.11s\n",
      "⏳ Job status: running | Progress: 92.0% | Elapsed: 285.21s\n",
      "⏳ Job status: running | Progress: 92.0% | Elapsed: 290.30s\n",
      "⏳ Job status: running | Progress: 92.0% | Elapsed: 295.40s\n",
      "⏳ Job status: running | Progress: 92.0% | Elapsed: 300.49s\n",
      "⏳ Job status: running | Progress: 96.0% | Elapsed: 305.59s\n",
      "\n",
      "🔄 Status changed: running → completed (after 310.68s)\n",
      "✅ Job status: completed | Progress: 100% | Elapsed: 310.68s\n",
      "\n",
      "✅ Job completed with status: completed (total time: 315.77s)\n",
      "\n",
      "============================================================\n",
      "📋 Final Evaluation Job Status:\n",
      "============================================================\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:53:18.714201\",\n",
      "  \"updated_at\": \"2025-11-07T20:58:37.228132\",\n",
      "  \"id\": \"eval-8gdLqUJt3HoNvLiuFvAjrU\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": null,\n",
      "  \"target\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-target-PVVk5vqrqtXgLf28zu37WG\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-target\",\n",
      "    \"namespace\": \"arhkp-nemo-helm\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"llama-3-1b-instruct-customized\",\n",
      "    \"type\": \"model\",\n",
      "    \"cached_outputs\": null,\n",
      "    \"model\": {\n",
      "      \"schema_version\": \"1.0\",\n",
      "      \"id\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"description\": null,\n",
      "      \"type_prefix\": \"model\",\n",
      "      \"namespace\": \"default\",\n",
      "      \"project\": null,\n",
      "      \"created_at\": \"2025-11-07T20:53:12.441967\",\n",
      "      \"updated_at\": \"2025-11-07T20:53:12.441970\",\n",
      "      \"custom_fields\": {},\n",
      "      \"ownership\": null,\n",
      "      \"name\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"version_id\": \"main\",\n",
      "      \"version_tags\": [],\n",
      "      \"spec\": null,\n",
      "      \"artifact\": null,\n",
      "      \"base_model\": null,\n",
      "      \"api_endpoint\": {\n",
      "        \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "        \"model_id\": \"arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\",\n",
      "        \"api_key\": null,\n",
      "        \"format\": \"nim\"\n",
      "      },\n",
      "      \"peft\": null,\n",
      "      \"prompt\": null,\n",
      "      \"guardrails\": null\n",
      "    },\n",
      "    \"retriever\": null,\n",
      "    \"rag\": null,\n",
      "    \"rows\": null,\n",
      "    \"dataset\": null\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-config\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:18.713924\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:18.713927\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"type\": \"custom\",\n",
      "    \"params\": null,\n",
      "    \"tasks\": {\n",
      "      \"custom-tool-calling\": {\n",
      "        \"type\": \"chat-completion\",\n",
      "        \"params\": {\n",
      "          \"template\": {\n",
      "            \"messages\": \"{{ item.messages | tojson}}\",\n",
      "            \"tools\": \"{{ item.tools | tojson }}\",\n",
      "            \"tool_choice\": \"auto\"\n",
      "          }\n",
      "        },\n",
      "        \"metrics\": {\n",
      "          \"tool-calling-accuracy\": {\n",
      "            \"type\": \"tool-calling\",\n",
      "            \"params\": {\n",
      "              \"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dataset\": {\n",
      "          \"schema_version\": \"1.0\",\n",
      "          \"id\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"description\": null,\n",
      "          \"type_prefix\": null,\n",
      "          \"namespace\": \"default\",\n",
      "          \"project\": null,\n",
      "          \"created_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"updated_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"custom_fields\": {},\n",
      "          \"ownership\": null,\n",
      "          \"name\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"version_id\": \"main\",\n",
      "          \"version_tags\": [],\n",
      "          \"format\": null,\n",
      "          \"files_url\": \"hf://datasets/arhkp-nemo-helm/xlam-ft-dataset/testing/xlam-test-single.jsonl\",\n",
      "          \"hf_endpoint\": null,\n",
      "          \"split\": null,\n",
      "          \"limit\": 50\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"groups\": null\n",
      "  },\n",
      "  \"result\": \"evaluation_result-Kvh7oWULYPMLk5KjM3YUik\",\n",
      "  \"output_files_url\": \"hf://datasets/evaluation-results/eval-8gdLqUJt3HoNvLiuFvAjrU\",\n",
      "  \"status_details\": {\n",
      "    \"message\": \"Job completed successfully.\",\n",
      "    \"task_status\": {\n",
      "      \"custom-tool-calling\": \"completed\"\n",
      "    },\n",
      "    \"progress\": 100.0\n",
      "  },\n",
      "  \"status\": \"completed\",\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n",
      "============================================================\n",
      "\n",
      "✅ Job completed successfully with status: completed\n",
      "✅ Custom model evaluation job completed\n"
     ]
    }
   ],
   "source": [
    "# Poll for evaluation job completion\n",
    "print(f\"🚀 Starting to poll evaluation job: {ft_eval_job_id}\")\n",
    "print(f\"Job URL: {EVALUATOR_URL}/v1/evaluation/jobs/{ft_eval_job_id}\")\n",
    "print(f\"Polling interval: 5 seconds, Timeout: 600 seconds (10 minutes)\\n\")\n",
    "\n",
    "try:\n",
    "    res = wait_eval_job(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{ft_eval_job_id}\", polling_interval=5, timeout=600)\n",
    "except Exception as e:\n",
    "    # If wait_eval_job raised an exception (e.g., job failed), try to get final status for debugging\n",
    "    print(f\"\\n⚠️  Exception during polling: {e}\")\n",
    "    print(\"\\nAttempting to fetch final job status for debugging...\")\n",
    "    try:\n",
    "        final_res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{ft_eval_job_id}\")\n",
    "        if final_res.status_code == 200:\n",
    "            final_job_data = final_res.json()\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"📋 Final Job Status (for debugging):\")\n",
    "            print(\"=\"*60)\n",
    "            print(json.dumps(final_job_data, indent=2))\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Extract and display error information\n",
    "            status_details = final_job_data.get(\"status_details\", {})\n",
    "            if status_details:\n",
    "                print(\"\\n🔍 Status Details:\")\n",
    "                print(json.dumps(status_details, indent=2))\n",
    "            \n",
    "            # Check for error messages\n",
    "            error_msg = status_details.get(\"error\") or status_details.get(\"message\") or final_job_data.get(\"error\")\n",
    "            if error_msg:\n",
    "                print(f\"\\n❌ Error Message: {error_msg}\")\n",
    "        else:\n",
    "            print(f\"Could not fetch final status: HTTP {final_res.status_code}\")\n",
    "    except Exception as fetch_error:\n",
    "        print(f\"Could not fetch final status: {fetch_error}\")\n",
    "    \n",
    "    # Re-raise the original exception\n",
    "    raise\n",
    "\n",
    "# Check response status\n",
    "if res.status_code != 200:\n",
    "    print(f\"\\n❌ Error: Evaluation job status check failed with status {res.status_code}\")\n",
    "    print(f\"Response: {res.text}\")\n",
    "    print(\"\\n💡 To check cluster logs, run:\")\n",
    "    print(f\"   oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=100\")\n",
    "    print(f\"   oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "    raise Exception(f\"Failed to get evaluation job status: {res.text}\")\n",
    "\n",
    "# Format and print the response\n",
    "job_status = res.json()\n",
    "final_status = job_status.get(\"status\", \"unknown\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📋 Final Evaluation Job Status:\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(job_status, indent=2))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract and display error information if job failed\n",
    "if final_status == \"failed\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"❌ JOB FAILED - Error Analysis:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    status_details = job_status.get(\"status_details\", {})\n",
    "    if status_details:\n",
    "        print(\"\\nStatus Details:\")\n",
    "        print(json.dumps(status_details, indent=2))\n",
    "        \n",
    "        # Look for common error fields\n",
    "        error_fields = [\"error\", \"message\", \"reason\", \"failure_reason\", \"error_message\"]\n",
    "        for field in error_fields:\n",
    "            if field in status_details:\n",
    "                print(f\"\\n🔴 {field.upper()}: {status_details[field]}\")\n",
    "    \n",
    "    # Check for error in top level\n",
    "    if \"error\" in job_status:\n",
    "        print(f\"\\n🔴 Top-level error: {job_status['error']}\")\n",
    "    \n",
    "    print(\"\\n💡 Common causes of evaluation job failures:\")\n",
    "    print(\"   1. Evaluation target (model) is not accessible or not found\")\n",
    "    print(\"   2. Evaluation dataset is not accessible or invalid\")\n",
    "    print(\"   3. Insufficient resources (GPU, memory, etc.)\")\n",
    "    print(\"   4. Network connectivity issues between services\")\n",
    "    print(\"   5. Configuration errors in evaluation config\")\n",
    "    \n",
    "    print(\"\\n💡 To investigate:\")\n",
    "    print(\"   1. Check evaluator service logs:\")\n",
    "    print(\"      oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=200\")\n",
    "    print(\"   2. Check evaluation job pods:\")\n",
    "    print(\"      oc get pods -n arhkp-nemo-helm | grep -E 'eval|evaluation'\")\n",
    "    print(\"   3. Verify evaluation target exists:\")\n",
    "    print(f\"      requests.get(f'{EVALUATOR_URL}/v1/evaluation/targets/{NMS_NAMESPACE}/llama-3-1b-instruct-customized').json()\")\n",
    "    print(\"   4. Check evaluator pod status:\")\n",
    "    print(\"      oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "    print(\"   5. Check evaluator custom resource:\")\n",
    "    print(\"      oc get nemoevaluator -n arhkp-nemo-helm -o yaml\")\n",
    "\n",
    "# Check if job actually completed successfully\n",
    "if final_status not in [\"completed\", \"success\", \"finished\"]:\n",
    "    if final_status != \"failed\":  # Already handled above\n",
    "        print(f\"\\n⚠️  Warning: Job status is '{final_status}', not 'completed'\")\n",
    "        print(\"This might indicate the job is still running, failed, or in an unexpected state.\")\n",
    "        print(\"\\n💡 To check cluster logs and pod status:\")\n",
    "        print(f\"   # Check evaluator pods\")\n",
    "        print(f\"   oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Check evaluator logs\")\n",
    "        print(f\"   oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=100\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Check for evaluation job pods (if any)\")\n",
    "        print(f\"   oc get pods -n arhkp-nemo-helm | grep -E 'eval|evaluation'\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Check job status directly\")\n",
    "        print(f\"   oc get nemoevaluator -n arhkp-nemo-helm\")\n",
    "else:\n",
    "    print(f\"\\n✅ Job completed successfully with status: {final_status}\")\n",
    "\n",
    "# Also return it so Jupyter displays it\n",
    "job_status\n",
    "\n",
    "print_status(\"Custom model evaluation job completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7409f25-23c1-4574-9392-051f3da0498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting to poll evaluation job: eval-8gdLqUJt3HoNvLiuFvAjrU\n",
      "Job URL: http://localhost:8004/v1/evaluation/jobs/eval-8gdLqUJt3HoNvLiuFvAjrU\n",
      "Polling interval: 5 seconds, Timeout: 600 seconds (10 minutes)\n",
      "\n",
      "🔍 Checking evaluation job status at: http://localhost:8004/v1/evaluation/jobs/eval-8gdLqUJt3HoNvLiuFvAjrU\n",
      "📊 Initial job status: completed\n",
      "\n",
      "Initial Job Data:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:53:18.714201\",\n",
      "  \"updated_at\": \"2025-11-07T20:58:37.228132\",\n",
      "  \"id\": \"eval-8gdLqUJt3HoNvLiuFvAjrU\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": null,\n",
      "  \"target\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-target-PVVk5vqrqtXgLf28zu37WG\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-target\",\n",
      "    \"namespace\": \"arhkp-nemo-helm\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"llama-3-1b-instruct-customized\",\n",
      "    \"type\": \"model\",\n",
      "    \"cached_outputs\": null,\n",
      "    \"model\": {\n",
      "      \"schema_version\": \"1.0\",\n",
      "      \"id\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"description\": null,\n",
      "      \"type_prefix\": \"model\",\n",
      "      \"namespace\": \"default\",\n",
      "      \"project\": null,\n",
      "      \"created_at\": \"2025-11-07T20:53:12.441967\",\n",
      "      \"updated_at\": \"2025-11-07T20:53:12.441970\",\n",
      "      \"custom_fields\": {},\n",
      "      \"ownership\": null,\n",
      "      \"name\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"version_id\": \"main\",\n",
      "      \"version_tags\": [],\n",
      "      \"spec\": null,\n",
      "      \"artifact\": null,\n",
      "      \"base_model\": null,\n",
      "      \"api_endpoint\": {\n",
      "        \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "        \"model_id\": \"arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\",\n",
      "        \"api_key\": null,\n",
      "        \"format\": \"nim\"\n",
      "      },\n",
      "      \"peft\": null,\n",
      "      \"prompt\": null,\n",
      "      \"guardrails\": null\n",
      "    },\n",
      "    \"retriever\": null,\n",
      "    \"rag\": null,\n",
      "    \"rows\": null,\n",
      "    \"dataset\": null\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-config\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:18.713924\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:18.713927\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"type\": \"custom\",\n",
      "    \"params\": null,\n",
      "    \"tasks\": {\n",
      "      \"custom-tool-calling\": {\n",
      "        \"type\": \"chat-completion\",\n",
      "        \"params\": {\n",
      "          \"template\": {\n",
      "            \"messages\": \"{{ item.messages | tojson}}\",\n",
      "            \"tools\": \"{{ item.tools | tojson }}\",\n",
      "            \"tool_choice\": \"auto\"\n",
      "          }\n",
      "        },\n",
      "        \"metrics\": {\n",
      "          \"tool-calling-accuracy\": {\n",
      "            \"type\": \"tool-calling\",\n",
      "            \"params\": {\n",
      "              \"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dataset\": {\n",
      "          \"schema_version\": \"1.0\",\n",
      "          \"id\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"description\": null,\n",
      "          \"type_prefix\": null,\n",
      "          \"namespace\": \"default\",\n",
      "          \"project\": null,\n",
      "          \"created_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"updated_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"custom_fields\": {},\n",
      "          \"ownership\": null,\n",
      "          \"name\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"version_id\": \"main\",\n",
      "          \"version_tags\": [],\n",
      "          \"format\": null,\n",
      "          \"files_url\": \"hf://datasets/arhkp-nemo-helm/xlam-ft-dataset/testing/xlam-test-single.jsonl\",\n",
      "          \"hf_endpoint\": null,\n",
      "          \"split\": null,\n",
      "          \"limit\": 50\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"groups\": null\n",
      "  },\n",
      "  \"result\": \"evaluation_result-Kvh7oWULYPMLk5KjM3YUik\",\n",
      "  \"output_files_url\": \"hf://datasets/evaluation-results/eval-8gdLqUJt3HoNvLiuFvAjrU\",\n",
      "  \"status_details\": {\n",
      "    \"message\": \"Job completed successfully.\",\n",
      "    \"task_status\": {\n",
      "      \"custom-tool-calling\": \"completed\"\n",
      "    },\n",
      "    \"progress\": 100.0\n",
      "  },\n",
      "  \"status\": \"completed\",\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n",
      "\n",
      "✅ Job is already completed with status: completed\n",
      "Total time: 0.08s\n",
      "\n",
      "============================================================\n",
      "📋 Final Evaluation Job Status:\n",
      "============================================================\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:53:18.714201\",\n",
      "  \"updated_at\": \"2025-11-07T20:58:37.228132\",\n",
      "  \"id\": \"eval-8gdLqUJt3HoNvLiuFvAjrU\",\n",
      "  \"namespace\": \"default\",\n",
      "  \"description\": null,\n",
      "  \"target\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-target-PVVk5vqrqtXgLf28zu37WG\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-target\",\n",
      "    \"namespace\": \"arhkp-nemo-helm\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:12.442155\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"llama-3-1b-instruct-customized\",\n",
      "    \"type\": \"model\",\n",
      "    \"cached_outputs\": null,\n",
      "    \"model\": {\n",
      "      \"schema_version\": \"1.0\",\n",
      "      \"id\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"description\": null,\n",
      "      \"type_prefix\": \"model\",\n",
      "      \"namespace\": \"default\",\n",
      "      \"project\": null,\n",
      "      \"created_at\": \"2025-11-07T20:53:12.441967\",\n",
      "      \"updated_at\": \"2025-11-07T20:53:12.441970\",\n",
      "      \"custom_fields\": {},\n",
      "      \"ownership\": null,\n",
      "      \"name\": \"model-R7gx9g8ic2pKCcKcEFgVfe\",\n",
      "      \"version_id\": \"main\",\n",
      "      \"version_tags\": [],\n",
      "      \"spec\": null,\n",
      "      \"artifact\": null,\n",
      "      \"base_model\": null,\n",
      "      \"api_endpoint\": {\n",
      "        \"url\": \"http://meta-llama3-1b-instruct.arhkp-nemo-helm.svc.cluster.local:8000/v1/chat/completions\",\n",
      "        \"model_id\": \"arhkp-nemo-helm/llama-3.2-1b-xlam-run1@cust-4qKEg1LSagjMSNRDe62yVe\",\n",
      "        \"api_key\": null,\n",
      "        \"format\": \"nim\"\n",
      "      },\n",
      "      \"peft\": null,\n",
      "      \"prompt\": null,\n",
      "      \"guardrails\": null\n",
      "    },\n",
      "    \"retriever\": null,\n",
      "    \"rag\": null,\n",
      "    \"rows\": null,\n",
      "    \"dataset\": null\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"schema_version\": \"1.0\",\n",
      "    \"id\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"description\": null,\n",
      "    \"type_prefix\": \"eval-config\",\n",
      "    \"namespace\": \"default\",\n",
      "    \"project\": null,\n",
      "    \"created_at\": \"2025-11-07T20:53:18.713924\",\n",
      "    \"updated_at\": \"2025-11-07T20:53:18.713927\",\n",
      "    \"custom_fields\": {},\n",
      "    \"ownership\": null,\n",
      "    \"name\": \"eval-config-A1Jusd8666tAYDZSvgc8hN\",\n",
      "    \"type\": \"custom\",\n",
      "    \"params\": null,\n",
      "    \"tasks\": {\n",
      "      \"custom-tool-calling\": {\n",
      "        \"type\": \"chat-completion\",\n",
      "        \"params\": {\n",
      "          \"template\": {\n",
      "            \"messages\": \"{{ item.messages | tojson}}\",\n",
      "            \"tools\": \"{{ item.tools | tojson }}\",\n",
      "            \"tool_choice\": \"auto\"\n",
      "          }\n",
      "        },\n",
      "        \"metrics\": {\n",
      "          \"tool-calling-accuracy\": {\n",
      "            \"type\": \"tool-calling\",\n",
      "            \"params\": {\n",
      "              \"tool_calls_ground_truth\": \"{{ item.tool_calls | tojson }}\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dataset\": {\n",
      "          \"schema_version\": \"1.0\",\n",
      "          \"id\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"description\": null,\n",
      "          \"type_prefix\": null,\n",
      "          \"namespace\": \"default\",\n",
      "          \"project\": null,\n",
      "          \"created_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"updated_at\": \"2025-11-07T20:53:18.713966\",\n",
      "          \"custom_fields\": {},\n",
      "          \"ownership\": null,\n",
      "          \"name\": \"dataset-Eh2PHUCjNd2RSCW22xXCe1\",\n",
      "          \"version_id\": \"main\",\n",
      "          \"version_tags\": [],\n",
      "          \"format\": null,\n",
      "          \"files_url\": \"hf://datasets/arhkp-nemo-helm/xlam-ft-dataset/testing/xlam-test-single.jsonl\",\n",
      "          \"hf_endpoint\": null,\n",
      "          \"split\": null,\n",
      "          \"limit\": 50\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"groups\": null\n",
      "  },\n",
      "  \"result\": \"evaluation_result-Kvh7oWULYPMLk5KjM3YUik\",\n",
      "  \"output_files_url\": \"hf://datasets/evaluation-results/eval-8gdLqUJt3HoNvLiuFvAjrU\",\n",
      "  \"status_details\": {\n",
      "    \"message\": \"Job completed successfully.\",\n",
      "    \"task_status\": {\n",
      "      \"custom-tool-calling\": \"completed\"\n",
      "    },\n",
      "    \"progress\": 100.0\n",
      "  },\n",
      "  \"status\": \"completed\",\n",
      "  \"project\": null,\n",
      "  \"custom_fields\": {},\n",
      "  \"ownership\": null\n",
      "}\n",
      "============================================================\n",
      "\n",
      "✅ Job completed successfully with status: completed\n",
      "✅ Custom model evaluation job completed\n"
     ]
    }
   ],
   "source": [
    "# Poll for evaluation job completion\n",
    "# NOTE: Using localhost (port-forward) is CORRECT for the notebook\n",
    "# The notebook runs locally and accesses services via port-forward\n",
    "print(f\"🚀 Starting to poll evaluation job: {ft_eval_job_id}\")\n",
    "print(f\"Job URL: {EVALUATOR_URL}/v1/evaluation/jobs/{ft_eval_job_id}\")\n",
    "print(f\"Polling interval: 5 seconds, Timeout: 600 seconds (10 minutes)\\n\")\n",
    "\n",
    "try:\n",
    "    res = wait_eval_job(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{ft_eval_job_id}\", polling_interval=5, timeout=600)\n",
    "except Exception as e:\n",
    "    # If wait_eval_job raised an exception (e.g., job failed), fetch final status for analysis\n",
    "    # Don't re-raise - instead, fetch the job status and continue with error analysis\n",
    "    print(f\"\\n⚠️  Job failed or exception during polling: {e}\")\n",
    "    print(\"\\nFetching final job status for analysis...\")\n",
    "    try:\n",
    "        final_res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{ft_eval_job_id}\")\n",
    "        if final_res.status_code == 200:\n",
    "            # Use this response as 'res' so the rest of the cell can process it\n",
    "            res = final_res\n",
    "            print(\"✅ Fetched final job status - continuing with error analysis...\\n\")\n",
    "        else:\n",
    "            print(f\"❌ Could not fetch final status: HTTP {final_res.status_code}\")\n",
    "            print(f\"Response: {final_res.text}\")\n",
    "            raise Exception(f\"Failed to fetch job status: HTTP {final_res.status_code}\")\n",
    "    except Exception as fetch_error:\n",
    "        print(f\"❌ Could not fetch final status: {fetch_error}\")\n",
    "        raise\n",
    "\n",
    "# Check response status\n",
    "if res.status_code != 200:\n",
    "    print(f\"\\n❌ Error: Evaluation job status check failed with status {res.status_code}\")\n",
    "    print(f\"Response: {res.text}\")\n",
    "    print(\"\\n💡 To check cluster logs, run:\")\n",
    "    print(f\"   oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=100\")\n",
    "    print(f\"   oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "    raise Exception(f\"Failed to get evaluation job status: {res.text}\")\n",
    "\n",
    "# Format and print the response\n",
    "job_status = res.json()\n",
    "final_status = job_status.get(\"status\", \"unknown\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📋 Final Evaluation Job Status:\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(job_status, indent=2))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract and display error information if job failed\n",
    "if final_status == \"failed\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"❌ JOB FAILED - Error Analysis:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    status_details = job_status.get(\"status_details\", {})\n",
    "    if status_details:\n",
    "        print(\"\\nStatus Details:\")\n",
    "        print(json.dumps(status_details, indent=2))\n",
    "        \n",
    "        # Look for common error fields\n",
    "        error_fields = [\"error\", \"message\", \"reason\", \"failure_reason\", \"error_message\"]\n",
    "        for field in error_fields:\n",
    "            if field in status_details:\n",
    "                print(f\"\\n🔴 {field.upper()}: {status_details[field]}\")\n",
    "    \n",
    "    # Check for error in top level\n",
    "    if \"error\" in job_status:\n",
    "        print(f\"\\n🔴 Top-level error: {job_status['error']}\")\n",
    "    \n",
    "    print(\"\\n💡 Common causes of evaluation job failures:\")\n",
    "    print(\"   1. Evaluation target (model) is not accessible or not found\")\n",
    "    print(\"   2. Evaluation dataset is not accessible or invalid\")\n",
    "    print(\"   3. Insufficient resources (GPU, memory, etc.)\")\n",
    "    print(\"   4. Network connectivity issues between services\")\n",
    "    print(\"   5. Configuration errors in evaluation config\")\n",
    "    \n",
    "    print(\"\\n💡 To investigate:\")\n",
    "    print(\"   1. Check evaluator service logs:\")\n",
    "    print(\"      oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=200\")\n",
    "    print(\"   2. Check evaluation job pods:\")\n",
    "    print(\"      oc get pods -n arhkp-nemo-helm | grep -E 'eval|evaluation'\")\n",
    "    print(\"   3. Verify evaluation target exists:\")\n",
    "    print(f\"      requests.get(f'{EVALUATOR_URL}/v1/evaluation/targets/{NMS_NAMESPACE}/llama-3-1b-instruct-customized').json()\")\n",
    "    print(\"   4. Check evaluator pod status:\")\n",
    "    print(\"      oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "    print(\"   5. Check evaluator custom resource:\")\n",
    "    print(\"      oc get nemoevaluator -n arhkp-nemo-helm -o yaml\")\n",
    "\n",
    "# Check if job actually completed successfully\n",
    "if final_status not in [\"completed\", \"success\", \"finished\"]:\n",
    "    print(f\"\\n⚠️  Warning: Job status is '{final_status}', not 'completed'\")\n",
    "    print(\"This might indicate the job is still running, failed, or in an unexpected state.\")\n",
    "    print(\"\\n💡 To check cluster logs and pod status:\")\n",
    "    print(f\"   # Check evaluator pods\")\n",
    "    print(f\"   oc get pods -n arhkp-nemo-helm | grep evaluator\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   # Check evaluator logs\")\n",
    "    print(f\"   oc logs -n arhkp-nemo-helm -l app=nemoevaluator --tail=100\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   # Check for evaluation job pods (if any)\")\n",
    "    print(f\"   oc get pods -n arhkp-nemo-helm | grep -E 'eval|evaluation'\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   # Check job status directly\")\n",
    "    print(f\"   oc get nemoevaluator -n arhkp-nemo-helm\")\n",
    "else:\n",
    "    print(f\"\\n✅ Job completed successfully with status: {final_status}\")\n",
    "\n",
    "# Also return it so Jupyter displays it\n",
    "job_status\n",
    "\n",
    "print_status(\"Custom model evaluation job completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3706c060-8b37-40e2-b0e6-636d130260e7",
   "metadata": {},
   "source": [
    "### 2.2 Review Evaluation Metrics\n",
    "The following code sends a GET request to retrieve the evaluation results for the fine-tuned model evaluation job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d2ffdb8-8e8e-403e-a836-8bcd93778814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking evaluation job status...\n",
      "\n",
      "Full status response:\n",
      "{\n",
      "  \"message\": \"Job completed successfully.\",\n",
      "  \"task_status\": {\n",
      "    \"custom-tool-calling\": \"completed\"\n",
      "  },\n",
      "  \"progress\": 100.0\n",
      "}\n",
      "\n",
      "📊 Inferred job status: completed\n",
      "   Message: Job completed successfully.\n",
      "   Progress: 100.0%\n",
      "   Task status: {'custom-tool-calling': 'completed'}\n",
      "✅ Job is completed (status: completed)\n",
      "\n",
      "Retrieving evaluation results...\n",
      "\n",
      "Evaluation Results:\n",
      "{\n",
      "  \"created_at\": \"2025-11-07T20:53:18.742768\",\n",
      "  \"updated_at\": \"2025-11-07T20:53:18.742769\",\n",
      "  \"id\": \"evaluation_result-Kvh7oWULYPMLk5KjM3YUik\",\n",
      "  \"job\": \"eval-8gdLqUJt3HoNvLiuFvAjrU\",\n",
      "  \"tasks\": {\n",
      "    \"custom-tool-calling\": {\n",
      "      \"metrics\": {\n",
      "        \"tool-calling-accuracy\": {\n",
      "          \"scores\": {\n",
      "            \"function_name_accuracy\": {\n",
      "              \"value\": 0.94,\n",
      "              \"stats\": {\n",
      "                \"count\": 50,\n",
      "                \"sum\": 47.0,\n",
      "                \"mean\": 0.94\n",
      "              }\n",
      "            },\n",
      "            \"function_name_and_args_accuracy\": {\n",
      "              \"value\": 0.74,\n",
      "              \"stats\": {\n",
      "                \"count\": 50,\n",
      "                \"sum\": 37.0,\n",
      "                \"mean\": 0.74\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"groups\": {},\n",
      "  \"namespace\": \"default\",\n",
      "  \"custom_fields\": {}\n",
      "}\n",
      "✅ Custom model evaluation results retrieved\n"
     ]
    }
   ],
   "source": [
    "# First, check the job status to ensure it's completed\n",
    "print(\"Checking evaluation job status...\")\n",
    "status_res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{ft_eval_job_id}/status\")\n",
    "\n",
    "if status_res.status_code != 200:\n",
    "    print(f\"⚠️ Warning: Could not check job status (Status {status_res.status_code})\")\n",
    "    print(f\"Response: {status_res.text}\")\n",
    "    print(\"\\nAttempting to retrieve results anyway (the job might still be accessible)...\")\n",
    "else:\n",
    "    status_data = status_res.json()\n",
    "    \n",
    "    # Print full status for debugging\n",
    "    print(\"\\nFull status response:\")\n",
    "    print(json.dumps(status_data, indent=2))\n",
    "    \n",
    "    # The /status endpoint returns a different structure than the full job endpoint\n",
    "    # It has \"message\" and \"task_status\" instead of a top-level \"status\" field\n",
    "    job_status = status_data.get(\"status\")\n",
    "    \n",
    "    # If no \"status\" field, infer from message and task_status\n",
    "    if job_status is None:\n",
    "        message = status_data.get(\"message\", \"\").lower()\n",
    "        task_status = status_data.get(\"task_status\", {})\n",
    "        progress = status_data.get(\"progress\", 0)\n",
    "        \n",
    "        # Infer status from message and task status\n",
    "        if \"completed successfully\" in message or \"success\" in message:\n",
    "            # Check if all tasks are completed\n",
    "            if task_status:\n",
    "                all_tasks_completed = all(\n",
    "                    status.lower() in [\"completed\", \"success\", \"finished\"] \n",
    "                    for status in task_status.values()\n",
    "                )\n",
    "                if all_tasks_completed and progress >= 100:\n",
    "                    job_status = \"completed\"\n",
    "                elif all_tasks_completed:\n",
    "                    job_status = \"completed\"  # Progress might not be exactly 100\n",
    "                else:\n",
    "                    job_status = \"running\"  # Some tasks still in progress\n",
    "            elif progress >= 100:\n",
    "                job_status = \"completed\"\n",
    "            else:\n",
    "                job_status = \"running\"\n",
    "        elif \"failed\" in message or \"error\" in message:\n",
    "            job_status = \"failed\"\n",
    "        elif \"running\" in message or progress > 0:\n",
    "            job_status = \"running\"\n",
    "        else:\n",
    "            job_status = \"unknown\"\n",
    "        \n",
    "        print(f\"\\n📊 Inferred job status: {job_status}\")\n",
    "        print(f\"   Message: {status_data.get('message', 'N/A')}\")\n",
    "        print(f\"   Progress: {progress}%\")\n",
    "        if task_status:\n",
    "            print(f\"   Task status: {task_status}\")\n",
    "    else:\n",
    "        print(f\"Job status: {job_status}\")\n",
    "    \n",
    "    # Valid completion statuses\n",
    "    completed_statuses = [\"completed\", \"success\", \"finished\", \"done\"]\n",
    "    \n",
    "    if job_status in completed_statuses:\n",
    "        print(f\"✅ Job is completed (status: {job_status})\")\n",
    "    elif job_status == \"unknown\":\n",
    "        print(\"⚠️ Warning: Job status is 'unknown'\")\n",
    "        print(\"This could mean:\")\n",
    "        print(\"  - The job doesn't exist or was deleted\")\n",
    "        print(\"  - The status endpoint returned an unexpected format\")\n",
    "        print(\"  - The job is in an intermediate state\")\n",
    "        print(\"\\nAttempting to retrieve results anyway...\")\n",
    "    elif job_status == \"failed\":\n",
    "        print(f\"❌ Job has failed (status: {job_status})\")\n",
    "        print(\"Check the status details above for error information.\")\n",
    "        print(\"\\nAttempting to retrieve results anyway (may contain error details)...\")\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Evaluation job is not completed yet. Status: {job_status}\")\n",
    "        print(\"Valid completion statuses:\", completed_statuses)\n",
    "        print(\"\\nYou can check the status again with:\")\n",
    "        print(f'  requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{ft_eval_job_id}/status\").json()')\n",
    "        print(\"\\nAttempting to retrieve results anyway (the job might have results even if status is not 'completed')...\")\n",
    "\n",
    "# Now retrieve the results (try even if status check failed or status is unknown)\n",
    "print(\"\\nRetrieving evaluation results...\")\n",
    "res = requests.get(f\"{EVALUATOR_URL}/v1/evaluation/jobs/{ft_eval_job_id}/results\")\n",
    "\n",
    "# Check response status\n",
    "if res.status_code != 200:\n",
    "    print(f\"❌ Error retrieving results: Status {res.status_code}\")\n",
    "    print(f\"Response: {res.text}\")\n",
    "    raise Exception(f\"Failed to retrieve evaluation results: {res.text}\")\n",
    "\n",
    "# Explicitly print the results\n",
    "results = res.json()\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(json.dumps(results, indent=2))\n",
    "\n",
    "# Check if tasks are empty\n",
    "if not results.get(\"tasks\") or len(results.get(\"tasks\", {})) == 0:\n",
    "    print(\"\\n⚠️ WARNING: Evaluation results have no tasks!\")\n",
    "    print(\"This could mean:\")\n",
    "    print(\"  1. The evaluation job completed but produced no results\")\n",
    "    print(\"  2. There was an error during evaluation\")\n",
    "    print(\"  3. The evaluation configuration was incorrect\")\n",
    "    print(\"\\nPlease check the evaluation job logs or status for more details.\")\n",
    "    print(f\"Job ID: {ft_eval_job_id}\")\n",
    "\n",
    "# Also return it so Jupyter displays it\n",
    "results\n",
    "\n",
    "print_status(\"Custom model evaluation results retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adb03140-21ad-445b-b173-7aebdfb0b703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model: function_name_accuracy: 0.94\n",
      "Custom model: function_name_and_args_accuracy: 0.74\n",
      "✅ Custom model accuracy scores extracted\n"
     ]
    }
   ],
   "source": [
    "# Extract function name accuracy score\n",
    "# Handle different possible task names and structures (same as base model extraction)\n",
    "result_data = res.json()\n",
    "tasks = result_data.get(\"tasks\", {})\n",
    "\n",
    "# Find the task (could be 'custom-tool-calling' or another name)\n",
    "task_name = None\n",
    "if \"custom-tool-calling\" in tasks:\n",
    "    task_name = \"custom-tool-calling\"\n",
    "elif len(tasks) > 0:\n",
    "    # Use the first task if 'custom-tool-calling' is not found\n",
    "    task_name = list(tasks.keys())[0]\n",
    "    print(f\"⚠️ Note: Using task '{task_name}' instead of 'custom-tool-calling'\")\n",
    "\n",
    "if not task_name or task_name not in tasks:\n",
    "    print(\"❌ Error: Could not find evaluation task in results\")\n",
    "    print(f\"Available tasks: {list(tasks.keys())}\")\n",
    "    print(f\"\\nFull results structure:\")\n",
    "    print(json.dumps(result_data, indent=2))\n",
    "    raise KeyError(f\"Task 'custom-tool-calling' not found. Available tasks: {list(tasks.keys())}\")\n",
    "\n",
    "# Extract metrics\n",
    "task_data = tasks[task_name]\n",
    "metrics = task_data.get(\"metrics\", {})\n",
    "tool_calling_metrics = metrics.get(\"tool-calling-accuracy\", {})\n",
    "scores = tool_calling_metrics.get(\"scores\", {})\n",
    "\n",
    "ft_function_name_accuracy_score = scores.get(\"function_name_accuracy\", {}).get(\"value\")\n",
    "ft_function_name_and_args_accuracy = scores.get(\"function_name_and_args_accuracy\", {}).get(\"value\")\n",
    "\n",
    "if ft_function_name_accuracy_score is None or ft_function_name_and_args_accuracy is None:\n",
    "    print(\"⚠️ Warning: Some accuracy scores are missing\")\n",
    "    print(f\"Available scores: {list(scores.keys())}\")\n",
    "    print(f\"\\nFull metrics structure:\")\n",
    "    print(json.dumps(metrics, indent=2))\n",
    "\n",
    "print(f\"Custom model: function_name_accuracy: {ft_function_name_accuracy_score}\")\n",
    "print(f\"Custom model: function_name_and_args_accuracy: {ft_function_name_and_args_accuracy}\")\n",
    "\n",
    "print_status(\"Custom model accuracy scores extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f568a204-ad01-4a04-8cfa-602816b8937c",
   "metadata": {},
   "source": [
    "A successfully fine-tuned `meta/llama-3.2-1b-instruct` results in a significant increase in tool calling accuracy with \n",
    "\n",
    "In this case you should observe roughly the following improvements -\n",
    "* function_name_accuracy: 12% to 92%\n",
    "* function_name_and_args_accuracy: 8% to 72%\n",
    "\n",
    "Since this evaluation was on a limited number of samples for demonstration purposes, you may choose to increase `tasks.dataset.limit` in your evaluation config `simple_tool_calling_eval_config`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc53b6-677b-4b44-bf6e-bcdadef21a73",
   "metadata": {},
   "source": [
    "## (Optional) Next Steps\n",
    "\n",
    "\n",
    "\n",
    "* You may also run the same evaluation on a base `meta/llama-3.1-70B` model for comparison.\n",
    "For this, first you will need to deploy the corresponding NIM using instructions [here](https://build.nvidia.com/meta/llama-3_1-70b-instruct/deploy). After your NIM is deployed, set that endpoint as your evaluation target like so -\n",
    "\n",
    "``` python\n",
    "# Create an evaluation target\n",
    "NIM_URL = \"http://0.0.0.0:8000\"\n",
    "EVAL_TARGET = {\n",
    "    \"type\": \"model\", \n",
    "    \"model\": {\n",
    "       \"api_endpoint\": {\n",
    "         \"url\": f\"{NIM_URL}/v1/completions\",\n",
    "         \"model_id\": \"meta/llama-3.1-70b-instruct\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Start eval job\n",
    "res = requests.post(\n",
    "    f\"{EVALUATOR_URL}/v1/evaluation/jobs\",\n",
    "    json={\n",
    "        \"config\": simple_tool_calling_eval_config,\n",
    "        \"target\": EVAL_TARGET\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "Running evaluation using the default config in this notebook, you should observe `meta/llama-3.1-70B` performance similar to -\n",
    "* function_name_accuracy: 98%\n",
    "* function_name_and_args_accuracy: 66%\n",
    "\n",
    "Remarkably, a LoRA-tuned `meta/llama-3.2-1B` achieves accuracy that is close to a model 70 times its size, even outperforming it in the combined `function_name_and_args_accuracy` score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a406f95b-4fc5-462a-ad6c-43196b70896d",
   "metadata": {},
   "source": [
    "You can now proceed with the same processes to fine-tune other NIM for LLMs and evaluate the accuracies between the base model and the fine-tuned model. By doing so, you can produce more accurate models for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24397111-1ab2-460f-bcc6-f510002c8ceb",
   "metadata": {},
   "source": [
    "# Part IV. Adding Safety Guardrails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bd80618-8c23-4dd2-b397-28c74294f466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Part IV imports completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from time import sleep, time\n",
    "from openai import OpenAI\n",
    "\n",
    "print_status(\"Part IV imports completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bab1e8-9aae-4cbd-bdf9-d5c4f4f361ee",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-1\"></a>\n",
    "## Step 1: Adding a Guardrails Configuration to the Microservice\n",
    "\n",
    "Start by running the following command which creates a `config.yml` file with the model deployed in the guardrails microservice "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49932b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce022951-1477-48bd-9f53-fc4eaeb43816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"detail\": \"config 'demo-self-check-input-output' already exists.\"\n",
      "}\n",
      "✅ Guardrails configurations listed\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"name\": \"demo-self-check-input-output\",\n",
    "    \"namespace\": \"default\",\n",
    "    \"description\": \"demo streaming self-check input and output\",\n",
    "    \"data\": {\n",
    "        \"prompts\": [\n",
    "            {\n",
    "                \"task\": \"self_check_input\",\n",
    "                \"content\": \"Your task is to check if the user message below contains any explicit content or abusive language\"\n",
    "            },\n",
    "            {\n",
    "                \"task\": \"self_check_output\",\n",
    "                \"content\": \"Your task is to check if the bot message below contains any explicit content or abusive language.\"\n",
    "            }\n",
    "        ],\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"general\",\n",
    "                \"content\": \"Below is a conversation between a user and a bot called the ABC Bot.\\nThe bot is designed to answer employee questions about the ABC Company.\\nThe bot is knowledgeable about the employee handbook and company policies.\\nIf the bot does not know the answer to a question, it truthfully says it does not know.\"\n",
    "            }\n",
    "        ],\n",
    "        \"sample_conversation\": \"user \\\"Hi there. Can you help me with some questions I have about the company?\\\"\\n  express greeting and ask for assistance\\nbot express greeting and confirm and offer assistance\\n  \\\"Hi there! I am here to help answer any questions you may have about the ABC Company. What would you like to know?\\\"\\nuser \\\"What is the company policy on paid time off?\\\"\\n  ask question about benefits\\nbot respond to question about benefits\\n  \\\"The ABC Company provides eligible employees with up to two weeks of paid vacation time per year, as well as five paid sick days per year. Please refer to the employee handbook for more information.\\\"\",\n",
    "        \"models\": [],\n",
    "        \"rails\": {\n",
    "            \"input\": {\n",
    "                \"flows\": [\n",
    "                    \"self check input\"\n",
    "                ]\n",
    "            },\n",
    "            \"output\": {\n",
    "                \"flows\": [\n",
    "                    \"self check output\"\n",
    "                ],\n",
    "                \"streaming\": {\n",
    "                    \"enabled\": \"True\",\n",
    "                    \"chunk_size\": 200,\n",
    "                    \"context_size\": 50,\n",
    "                    \"stream_first\": \"True\"\n",
    "                }\n",
    "            },\n",
    "            \"dialog\": {\n",
    "                \"single_call\": {\n",
    "                    \"enabled\": \"False\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "response = requests.post(f\"{GUARDRAILS_URL}/v1/guardrail/configs\", headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "print_status(\"Guardrails configurations listed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335af47a-21b0-47cb-9c39-1a9883a01758",
   "metadata": {},
   "source": [
    "The following REST API call lists the available guardrails configurations. You should be able to see the `toolcalling` configuration - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0ab0592-2396-4f3e-8e9e-fa056c4e0bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"created_at\": \"2025-11-07T19:22:58.264363\",\n",
      "      \"updated_at\": \"2025-11-07T19:22:58.264366\",\n",
      "      \"name\": \"demo-self-check-input-output\",\n",
      "      \"namespace\": \"default\",\n",
      "      \"description\": \"demo streaming self-check input and output\",\n",
      "      \"data\": {\n",
      "        \"models\": [],\n",
      "        \"instructions\": [\n",
      "          {\n",
      "            \"type\": \"general\",\n",
      "            \"content\": \"Below is a conversation between a user and a bot called the ABC Bot.\\nThe bot is designed to answer employee questions about the ABC Company.\\nThe bot is knowledgeable about the employee handbook and company policies.\\nIf the bot does not know the answer to a question, it truthfully says it does not know.\"\n",
      "          }\n",
      "        ],\n",
      "        \"sample_conversation\": \"user \\\"Hi there. Can you help me with some questions I have about the company?\\\"\\n  express greeting and ask for assistance\\nbot express greeting and confirm and offer assistance\\n  \\\"Hi there! I am here to help answer any questions you may have about the ABC Company. What would you like to know?\\\"\\nuser \\\"What is the company policy on paid time off?\\\"\\n  ask question about benefits\\nbot respond to question about benefits\\n  \\\"The ABC Company provides eligible employees with up to two weeks of paid vacation time per year, as well as five paid sick days per year. Please refer to the employee handbook for more information.\\\"\",\n",
      "        \"prompts\": [\n",
      "          {\n",
      "            \"task\": \"self_check_input\",\n",
      "            \"content\": \"Your task is to check if the user message below contains any explicit content or abusive language\",\n",
      "            \"max_length\": 16000,\n",
      "            \"mode\": \"standard\"\n",
      "          },\n",
      "          {\n",
      "            \"task\": \"self_check_output\",\n",
      "            \"content\": \"Your task is to check if the bot message below contains any explicit content or abusive language.\",\n",
      "            \"max_length\": 16000,\n",
      "            \"mode\": \"standard\"\n",
      "          }\n",
      "        ],\n",
      "        \"prompting_mode\": \"standard\",\n",
      "        \"lowest_temperature\": 0.001,\n",
      "        \"enable_multi_step_generation\": false,\n",
      "        \"colang_version\": \"1.0\",\n",
      "        \"custom_data\": {},\n",
      "        \"rails\": {\n",
      "          \"input\": {\n",
      "            \"parallel\": false,\n",
      "            \"flows\": [\n",
      "              \"self check input\"\n",
      "            ]\n",
      "          },\n",
      "          \"output\": {\n",
      "            \"parallel\": false,\n",
      "            \"flows\": [\n",
      "              \"self check output\"\n",
      "            ],\n",
      "            \"streaming\": {\n",
      "              \"enabled\": true,\n",
      "              \"chunk_size\": 200,\n",
      "              \"context_size\": 50,\n",
      "              \"stream_first\": true\n",
      "            },\n",
      "            \"apply_to_reasoning_traces\": false\n",
      "          },\n",
      "          \"retrieval\": {\n",
      "            \"flows\": []\n",
      "          },\n",
      "          \"dialog\": {\n",
      "            \"single_call\": {\n",
      "              \"enabled\": false,\n",
      "              \"fallback_to_multiple_calls\": true\n",
      "            },\n",
      "            \"user_messages\": {\n",
      "              \"embeddings_only\": false\n",
      "            }\n",
      "          },\n",
      "          \"actions\": {}\n",
      "        },\n",
      "        \"enable_rails_exceptions\": false\n",
      "      },\n",
      "      \"schema_version\": \"1.0\",\n",
      "      \"custom_fields\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"pagination\": {\n",
      "    \"page\": 1,\n",
      "    \"page_size\": 10,\n",
      "    \"current_page_size\": 1,\n",
      "    \"total_pages\": 1,\n",
      "    \"total_results\": 1\n",
      "  },\n",
      "  \"sort\": \"-created_at\"\n",
      "}\n",
      "✅ Guardrails test with unsafe query completed\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(f\"{GUARDRAILS_URL}/v1/guardrail/configs?page=1&page_size=10&sort=-created_at\")\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "print_status(\"Guardrails test with unsafe query completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2adb5ff-9806-4df6-9fca-85c9077c6c1f",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-2\"></a>\n",
    "## Step 2: Evaluate the Safety guardrails\n",
    "\n",
    "With the above guardrails configuration in place, we can now send an example query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38a1fd-022e-40fa-8833-dc988ed1558a",
   "metadata": {},
   "source": [
    "Now Let's try with Guardrails ON. NeMo Guardrail should not respond to the unsafe user query.\n",
    "\n",
    "### 2.2: Unsafe User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "004d1090-033a-497b-96fa-6933fd7d850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9473ae5d-fbbd-424d-87b0-67736da81784\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1762548684,\n",
      "  \"model\": \"-\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"I'm sorry, I can't respond to that.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 0,\n",
      "    \"total_tokens\": 0,\n",
      "    \"completion_tokens\": 0\n",
      "  },\n",
      "  \"guardrails_data\": {\n",
      "    \"config_ids\": [\n",
      "      \"demo-self-check-input-output\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "✅ Guardrails test with unsafe query completed\n"
     ]
    }
   ],
   "source": [
    "url = f\"{GUARDRAILS_URL}/v1/guardrail/chat/completions\"\n",
    "\n",
    "headers = {\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"meta/llama-3.2-1b-instruct\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"You are stupid\"}\n",
    "    ],\n",
    "    \"guardrails\": {\n",
    "        \"config_id\": \"demo-self-check-input-output\",\n",
    "    },\n",
    "    \"top_p\": 1\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "print_status(\"Guardrails test with unsafe query completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c81e5f-17c6-40e9-a23c-9e2536b57fee",
   "metadata": {},
   "source": [
    "Let's try the safe user query. \n",
    "\n",
    "### 2.3: Safe User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "189142fc-8102-4aea-a4e8-49355cbe3a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-3ec0f63b-617f-464f-85d1-118334d5cdff\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1762548685,\n",
      "  \"model\": \"-\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"text\": \"I'm sorry, I can't respond to that.\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 0,\n",
      "    \"total_tokens\": 0,\n",
      "    \"completion_tokens\": 0\n",
      "  },\n",
      "  \"guardrails_data\": {\n",
      "    \"config_ids\": [\n",
      "      \"demo-self-check-input-output\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "✅ Guardrails test with safe query completed\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "url = f\"{GUARDRAILS_URL}/v1/guardrail/completions\"\n",
    "\n",
    "headers = {\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"meta/llama-3.2-1b-instruct\",\n",
    "    \"prompt\": \"Tell me about Cape Hatteras National Seashore in 50 words or less.\",\n",
    "    \"guardrails\": {\n",
    "      \"config_id\": \"demo-self-check-input-output\"\n",
    "    },\n",
    "    \"temperature\": 1,\n",
    "    \"max_tokens\": 100,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "print_status(\"Guardrails test with safe query completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
